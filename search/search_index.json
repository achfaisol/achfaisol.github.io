{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Selamat Datang di Halaman Tugasku \u00b6 My Curiculum Vitae Nama : Ach. Faisol S. Arifin NRP : 180411100073 Jurusan : Teknik Informatika, Universitas Trunojoyo Madura","title":"Selamat Datang di Halaman Tugasku"},{"location":"#selamat-datang-di-halaman-tugasku","text":"My Curiculum Vitae Nama : Ach. Faisol S. Arifin NRP : 180411100073 Jurusan : Teknik Informatika, Universitas Trunojoyo Madura","title":"Selamat Datang di Halaman Tugasku"},{"location":"komnum/","text":"Selamat Datang di Halaman Tugas Komputasi Numerik \u00b6 Nama : Ach. Faisol S. Arifin NRP : 180411100073 Jurusan : Teknik Informatika, Universitas Trunojoyo Madura Kelas : Kumputasi Numerik 4B Dosen Pengampu : MULA'AB, S.Si., M.Kom","title":"Beranda"},{"location":"komnum/#selamat-datang-di-halaman-tugas-komputasi-numerik","text":"Nama : Ach. Faisol S. Arifin NRP : 180411100073 Jurusan : Teknik Informatika, Universitas Trunojoyo Madura Kelas : Kumputasi Numerik 4B Dosen Pengampu : MULA'AB, S.Si., M.Kom","title":"Selamat Datang di Halaman Tugas Komputasi Numerik"},{"location":"komnum/Persamaan non linear/","text":"Mencari Akar Persamaan pada Persamaan Non Linear \u00b6 Pencarian akar pada persamaan dapat dilakukan dengan pendekatan metode numerik, yaitu dengan metode berikut: Metode Bisection Metode Regula Falsi Metode Newton Rapson Motode Secant Metode - metode tersebut dapat di manfaatkan untuk mencari akar dari persamaan non-linear. berikut adalah perhitungan dan implementasi pada bahasa pemrograman python dari algoritma metode numerik tersebut. Metode Bisection \u00b6 Metode biseksi ini membagi range menjadi 2 bagian, dari dua bagian ini dipilih bagian mana yang mengandung akar sedangkan bagian yang tidak mengandung akar akan dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh suatu akar persamaan. Algortima Pada Motode Bisection \u00b6 Definisikan fungsi $ f(x) $ yang akan dicari akarnya Tentukan nilai $ a $ dan $ b $ Tentukan toleransi $ \\epsilon $ dan iterasi maksimum $ N $ Hitung $ f(a) $ dan $ f(b) $ Jika $ f(a).f(b)>0 $ maka proses dihentikan karena tidak ada akar, bila tidak maka dilanjutkan Hitung $ x = (a+b)/2 $ Hitung $ f(x) $ Bila$ f(x).f(a)<0 $ maka $ b = x $ dan $ f(b)=f(x) $, bila tidak maka $ a=x $ dan $ f(a)=f(x) $ Jika $ |b-a| < \\epsilon $ atau iterasi telah mencapai iterasi maks maka proses dihentikan dan didapatkan akar $ x $, bila tidak, ulangi langkah 6 Perhitungan dalam Metode Bisection \u00b6 Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : $ f(x) = x^2 - 5x +6 $ Langkah kedua menentukan Nilai a dan b, mengambil nilai batas awal $ (a) = 1 $ dan nilai batas bawahnya $ (b) = 2.4 $ Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =100 =100 Menghitung f(a) dan f(b), menghitung f(a) bisa kita gunakan pada fungsi f(x) pada langkah pertama.Dimana $ f(a)=1^2-5(1)+6=2$ dan $f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 $ Mengecek dengan kondisi ketika $ f(a).f(b)>0 $ maka proses itu akan diberhentikan, bila f(a).f(b)<0 f(a).f(b)<0 maka akan lanjut ke proses berikutnya. Dimana ketika f(a) f(a) yang didapatkan = 2 = 2 dan f(b) = -0.2400000000000002 f(b) = -0.2400000000000002 maka $ f(a).f(b) = 2 x -0.2400000000000002 = -0.4800000000000004 $ maka sudah dapat diketahui f(a).f(b) < 0 f(a).f(b) < 0 Pada langkah ini menghitung $ x = (a+b)/2 $, dimana a =1 dan b = 2.4 maka $ x = (1+2.4)/2 = 1.7 $ Setelah mendapatkan nilai $ x $ maka menghitung nilai f(x)nya f(x)nya dengan$ x = 1.7$ maka $f(1.7)= (1.7)^2 -5(1.7)+6 = 0.3899999999999997 $, maka didapatkan f(x) = 0.3899999999999997 f(x) = 0.3899999999999997 Melakukan pengecekan bila f(x).f(a)<0 f(x).f(a)<0 maka b = x b = x dan f(b)=f(x) f(b)=f(x) , tapi ketika f(x),f(a) tidak < dari 0 maka a =x dan f(a) = f(x) , dimana f(x) = 0.3899999999999997 dan $f(a) = 2 $ maka $f(x).f(a) = 0.7799999999999994 $ tidak < dari 0 < dari 0 maka a = x a = x , jadi $a = 1,7 dan dan f(a) = 0.3899999999999997 $ Maka Langkah berikutnya mengecek jika |b-a|<e |b-a|<e atau Iterasi sudah mencapai iterasi maksimum maka proses dihentikan dan mendapatkan akar yang dicari. Dengan mengecek hasil dari |b-a|<e |b-a|<e maka |b-a| =| 2.4 - 1.7|=0.7 |b-a| =| 2.4 - 1.7|=0.7 dapat diketahui bahwa |b-a| |b-a| tidak < < dari e maka terus melakukan iterasi sampai dengan iterasi maksimum Implementasi Algoritma Metode Bisection Dengan Python \u00b6 Berikut merupakan hasil implementasi metode bisection untuk mencari akar dari persamaan $ x^2 - 5x + 6 $ dengan batas error maksimal 0.001 . error = 0.001 a = 0 b = 1 def f ( x ): return x ** 2 - 5 * x + 6 def bisection ( a , b ): iteration = True while iteration : if f ( a ) * f ( b ) < 0 : while iteration : x = ( a + b ) / 2 if f ( a ) * f ( x ) < 0 : b = x elif f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : return x iteration = False else : b += 0.1 print ( 'x =' , x ) bisection ( a , b ) Dalam program tersebut di deklarasikan nilai a = 0 dan b = 1, dalam program tersebut akan mancari nilai b dengan sendirinya, dengan menambah b dengan 0.1 error = 0.001 a = 0 b = 1 Kemudian membuat persamaan yang di deklarasikan pada fungsi f(x). def f ( x ): return x ** 2 - 5 * x + 6 Selanjutnya merupakan program utama untuk mencari nilai x dari persamaan yang telah di deklarasikan. program akan berjalan dengan algoritma sebagaimana semestinya dalam metode bisection. saat nilai f(a)f(b) tidak kurang dari 0, maka akan mencarikan nilai b sampai kurang dari 0. def bisection ( a , b ): iteration = True while iteration : if f ( a ) * f ( b ) < 0 : while iteration : x = ( a + b ) / 2 if f ( a ) * f ( x ) < 0 : b = x elif f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : return x iteration = False else : b += 0.1 Saat program tersebut di jalankan maka menghasilkan output seperti berikut dengan nilai x yang di dapat yaitu : 2.000024414062501. x = 1.0500000000000005 x = 1.5750000000000006 x = 1.8375000000000008 x = 1.9687500000000009 x = 2.0343750000000007 x = 2.001562500000001 x = 1.9851562500000008 x = 1.9933593750000007 x = 1.9974609375000008 x = 1.9995117187500009 x = 2.000537109375001 x = 2.000024414062501 akar persamaan ( x ) = 2.000024414062501 Metode Regula Falsi \u00b6 Metode ini adalah metode tertua untuk menemukan akar sebenarnya dari persamaan f (x) = 0. Ia juga dikenal sebagai metode akor atau metode interpolasi linier. Seperti metode pembagian dua bagian, posisi yang salah satu metodenya dimulai dengan dua titik a_0 a_0 dan b_0 b_0 sedemikian rupa sehingga f ( a_0 a_0 ) dan f( b_0 b_0 ) memiliki tanda-tanda yang berlawanan, yang menyiratkan oleh teorema nilai menengah bahwa fungsi f memiliki akar dalam interval [a_0, b_0] [a_0, b_0] , dengan asumsi kesinambungan dari fungsi f. Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position. Metode ini juga merupakan penyempurnan dari metode bisection. Algortima Pada Motode Regula-Falsi \u00b6 1.Definisikan fungsi $ f(x) $ yang akan dicari akarnya 2.Masukkan interval [a,b] [a,b] dimana akar berada, atau bisa dengan menententukan nilai a dan b 3.Tentukan toleransi $ \\epsilon $ dan iterasi maksimum N 4.Hitung $ f(a) $ dan $ f(b) $ 5.Mengecek nilai f(a).f(b) <0 f(a).f(b) <0 bila tidak maka proses nilai $ f(a).f(b)>0 $, akan memberhentikan proses perhitungan (program) 6.Mengkalkulasi x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b)|} x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b)|} 7.Jika $ f(a).f(x)<0 $ maka $ b = x $, ketika tidak jika $ f(x)f(b)<0 $ maka $ a = x $ 8.Jika $ |b-a|< \\epsilon $ , $ \\epsilon $ menjadi akurasi yang ditentukan. Lalu lanjutkan ke Langkah 9 yang lain Langkah 4 9.Cetak nilai $ x $ yang dibutuhkan akar Perhitugan dalam Metode Regula Falsi \u00b6 Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : f(x) = x^2 - 5x +6 f(x) = x^2 - 5x +6 Langkah kedua menentukan Nilai a dan b, mengambil nilai batas awal (a) = 1 dan nilai batas bawahnya (b) = 2.4 . Maka dapat kita ketahui interval [a,b]= [1,2.4] [a,b]= [1,2.4] Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =50 =50 Menghitung f(a) dan f(b), menghitung f(a) bisa kita gunakan pada fungsi f(x) pada langkah pertama.Dimana f(a)=1^2-5(1)+6=2 f(a)=1^2-5(1)+6=2 dan f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 Mengecek dengan kondisi ketika $ f(a).f(b)>0$ maka proses itu akan diberhentikan, bila f(a).f(b)<0 f(a).f(b)<0 maka akan lanjut ke proses berikutnya. Dimana ketika f(a) f(a) yang didapatkan = 2 = 2 dan f(b) = -0.2400000000000002 f(b) = -0.2400000000000002 maka $ f(a).f(b) $= 2 x -0.2400000000000002 = -0.4800000000000004 maka sudah dapat diketahui f(a).f(b) < 0 f(a).f(b) < 0 Mengkalkulus x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} , maka $$ x = {(1|-0.2400000000000002|+2.4|2|) \\over |2| +|-0.2400000000000002|} \\\\ x = {1.2400000000000002 + 4.8 \\over 2+0.2400000000000002} \\\\ x = {6.04 \\over 2.24 } \\\\ x = 2.696428571428571 $$ Pada langkah ini mengecek apakah $ f(a).f(x)<0$ maka b = x b = x , ketika tidak jika f(x)f(b)<0 f(x)f(b)<0 maka a = x a = x . pertama harus menghitung f(x)nya f(x)nya dimana x nya = 2.696428571428571 2.696428571428571 , maka $$ f(x)= x^2 -5x+6, \\quad dimana (x)nya = 2.69642857142857 \\\\ f(x) = (2.69642857142857)^2-5(2.69642857142857)+6 \\\\ f(x) = 7.270727040816318 - 13.482142857142856+6 \\\\ f(x) = -0.2114158163265376 $$ Mengecek apakah f(a).f(x)<0 f(a).f(x)<0 , dimana f(a)=2, f(a)=2, dan f(x)=-0.2114158163265376 f(x)=-0.2114158163265376 , maka $$ f(a).f(x)= 2 \\quad X -0.2114158163265376 = -0.4228316326530752 $$ Dapat diketahui bahwa f(a).f(x)<0 f(a).f(x)<0 maka set b = x, b = 2.696428571428571 b = 2.696428571428571 Mengecek |b-a|< \u03b5 |b-a|< \u03b5 , \u03b5 menjadi akurasi yang ditentukan. Lalu lanjutkan ke Langkah berikutnya yang lain Langkah 4 , maka melakukan pengecekan $$ |b-a|= 2.696428571428571 -2 = 0.6964285714285712 \\\\ |b-a| = 0.6964285714285712 \\quad tidak < 0 , maka mengulang \\quad ke langkah \\quad ke 4 $$ Akan terus melakukan proses iterasi sampai |b-a|<e |b-a|<e ketika proses berhasil maka lanjut ke langkah 9 Mencetak nilai x , itu lah hasil dari nilai akar yang diperoleh Implementasi Algoritma Metode Regula-Falsi Dengan Python \u00b6 Pada Implementasi Algoritma Metode Regulasi-Falsi ini, Pada Langkah pertama ini membuat fungsi f(x) untuk bisa langsung memudahkan dalam perhitungan def f ( x ): return x ** 2 - 5 * x + 6 Pada Langkah Berikutnya membuat variabel kosong seperti variabel a dan b, serta error yang akan digunakan error = 0.0001 a = 1 b = 2.4 Langkah Selanjutnya membuat fungsi , def Regulasi_falsi untuk bisa langsung mengkalkulasi hasil perhitungan pada fungsi yang digunakan diatas dan , memberikan suatu iterasi (looping) ketika ada kondisi yang sudah terpenuhi def regula_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x print ( \"maka b = x , b = \" , x ) if f ( x ) * f ( b ) < 0 : a = x print ( \"maka a = x , a = \" , x ) if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regula_falsi ( a , b ) Dapat kita ketahui pada program diatas dimana memberikan sebuah inisial terlebih dahulu dimana iterasi bervalue True, i = 0, dan iterasi maksimum yang digunakan 50. DImana pada fungsi perulangan pada while iterasi dan i < max_iterasi, ketika kondisi telah terpenuhi maka akan melanjutkan ke kondisi berikutnya dimana pada kondisi ini f(a).f(b)< 0, ketika kondisinya telah tercapai maka melanjutkan ke proses perhitungan x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} . Ketika sudah melakukan proses pencarian x maka melanjutkan ke proses kondisi untuk melakukan swap (perubahan) dengan b =x ketika kondisi f(a).f(x)<0. atau kondisi f(x).f(b)<0 maka akan swap a = x if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x print ( \"maka b = x , b = \" , x ) if f ( x ) * f ( b ) < 0 : a = x print ( \"maka a = x , a = \" , x ) Lanjut melakukan pengecekan pada kondisi ketika nilai dari a-b < error maka iterasi akan bernilai False dan bila kondisi ini tidak terpenuhi maka melakukan proses penambahan i+=1 if abs ( a - b ) < error : iteration = False else : i += 1 Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Berikut Hasil yang diperoleh dari Hasil Program Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Berikut Hasil yang diperoleh dari Hasil Program maka b = x , b = 2.25 maka b = x , b = 2.142857142857143 maka b = x , b = 2.076923076923077 maka b = x , b = 2.0400000000000005 maka b = x , b = 2.020408163265306 maka b = x , b = 2.010309278350516 maka b = x , b = 2.0051813471502595 maka b = x , b = 2.0025974025974027 maka b = x , b = 2.001300390117035 maka b = x , b = 2.0006506180871835 maka b = x , b = 2.000325414904003 maka b = x , b = 2.0001627339300247 maka b = x , b = 2.000081373586134 maka b = x , b = 2.000040688448549 maka b = x , b = 2.0000203446381697 maka b = x , b = 2.000010172422562 maka b = x , b = 2.00000508623715 maka b = x , b = 2.0000025431250426 maka b = x , b = 2.0000012715641384 maka b = x , b = 2.000000635782474 maka b = x , b = 2.0000003178913377 maka b = x , b = 2.000000158945694 maka b = x , b = 2.000000079472853 maka b = x , b = 2.000000039736428 maka b = x , b = 2.0000000198682146 maka b = x , b = 2.0000000099341078 maka b = x , b = 2.0000000049670534 maka b = x , b = 2.000000002483527 maka b = x , b = 2.000000001241763 maka b = x , b = 2.000000000620882 maka b = x , b = 2.0000000003104406 maka b = x , b = 2.0000000001552207 maka b = x , b = 2.00000000007761 maka b = x , b = 2.0000000000388054 maka b = x , b = 2.0000000000194023 maka b = x , b = 2.0000000000097016 maka b = x , b = 2.0000000000048503 maka b = x , b = 2.0000000000024256 maka b = x , b = 2.0000000000012124 maka b = x , b = 2.0000000000006066 maka b = x , b = 2.000000000000303 maka b = x , b = 2.000000000000152 maka b = x , b = 2.0000000000000755 maka b = x , b = 2.000000000000038 maka b = x , b = 2.0000000000000187 maka b = x , b = 2.0000000000000098 maka b = x , b = 2.0000000000000044 maka b = x , b = 2.0000000000000027 x = 2.000000000000001 Metode Newton Raphson \u00b6 Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position. Metode ini juga merupakan penyempurna dari metode bisection. Algortima Pada Motode Newton Raphson \u00b6 1.Definisikan fungsi $ f(x) , f'(x) $ yang akan dicari akarnya 2.Tentukan tebakan awal akar (katakanlah x_0 x_0 ) dan set $ n = 0 $ 3.Tentukan toleransi $ \\epsilon $ dan iterasi maksimum N 4.Hitung x_{n+1}=x_n -[f(x_n)/f'(x)_n] x_{n+1}=x_n -[f(x_n)/f'(x)_n] 5.Jika |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e , di mana \u03b5 adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 7, bila lanjut ke langkah 6 6.Set $ n = n+1 $ dan pergi ke langkah 4 7.Cetak nilai $ x_n$ yang merupakan nilai akar yang diperlukan Perhitungan dalam Metode Newton Raphson \u00b6 Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : f(x) = x^2 - 5x +6 f(x) = x^2 - 5x +6 dan f'(x)= 2x-5 f'(x)= 2x-5 Langkah kedua menentukan Nilai x_0 x_0 dan x_1 x_1 , mengambil nilai batas awal (x_0)= 1 (x_0)= 1 dan nilai batas bawahnya (x_1) = 2.4 (x_1) = 2.4 Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =50 =50 Pada Langkah ini mengecek pada (x_0) = 1 (x_0) = 1 dan (x_1) (x_1) = 2.4. Apakah |x_1 - x_0|<e |x_1 - x_0|<e . Dan dapat kita ketahui bahwa > e maka lanjut ke proses berikutnya Menghitung f(x_1) f(x_1) dan f'(x_1) f'(x_1) , menghitung f(x_1) f(x_1) bisa kita gunakan pada fungsi f(x) dan pada f'(x_1) f'(x_1) bisa kita gunakan pada fungsi f'(x) langkah pertama. Dimana f(x_1)=(2.4)^2-5(2.4)+6= -0.2400000000000002 f(x_1)=(2.4)^2-5(2.4)+6= -0.2400000000000002 dan f'(x_1)=2 x (2.4) -5 =-0.20000000000000018 f'(x_1)=2 x (2.4) -5 =-0.20000000000000018 Mengecek dengan kondisi ketika |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e , di mana \u03b5 adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 7. Maka $$ X_2 = X_1 -{f(x_1) \\over f'(x_1)} \\\\ X_2 = 2.4 -{-0.2400000000000002 \\over -0.20000000000000018} \\\\ X_2 = 2.4 - 1.2 \\\\ X_2 = 1.2 $$ Melakukan Proses pengecekan ketika sudah memperoleh x_2= 1.2 x_2= 1.2 maka apakah |x_2 - x_1|<e. Ketika kondisi tidak terpenuhi mengulang proses iterasi dengan melakukan penambahan n+1 jadi berpindah untuk mencari x_3 x_3 . Bila proses kondisi terpenuhi dengan |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e maka lanjut ke proses langkah ke 7 Cetak nilai $ x_n$ yang merupakan nilai akar yang diperlukan Implementasi Algoritma Metode Newton Raphson Dengan Python \u00b6 Pada Implementasi Algoritma Metode Newton Raphson ini, Pada Langkah pertama ini membuat fungsi f(x) dan fungsi f'(x) untuk bisa langsung memudahkan dalam perhitungan def f ( x ): return x ** 2 - 5 * x + 6 def f_turunan ( x ): return 2 * x - 5 Pada Langkah Berikutnya membuat variabel kosong seperti variabel x0, serta error yang akan digunakan error = 0.0001 xo = 0 Langkah Selanjutnya membuat fungsi , def Newton Raphson untuk bisa langsung mengkalkulasi hasil perhitungan pada fungsi yang digunakan diatas dan memberikan suatu iterasi (looping) ketika ada kondisi yang sudah terpenuhi def newton_raphson ( x0 ): iteration = True n = 0 x_next = x0 print ( \"X_0 =\" , x_next ) while iteration : x_curr = x_next x_next = x_curr - ( f ( x_curr ) / f_turunan ( x_curr )) print ( \"x_(\" , n + 1 , \") = \" , x_next ) if abs ( x_next - x_curr ) < error : iteration = False else : n += 1 print ( \"x = \" , x_next ) newton_raphson ( xo ) Dapat kita ketahui pada program diatas dimana memberikan sebuah inisial terlebih dahulu dimana iterasi (n) = 0 ,dan inisial iterasi bervalue True, dimana n = 0 akan dimulai dari iterasi 0 untuk bisa melakukan sebuah perulangan (looping ) DImana pada fungsi perulangan pada while iteration, ketika kondisi telah terpenuhi maka akan melanjutkan ke perpindahan dan perhitungan setelah melakukan sebuah while iterasi x_curr = x_next x_next = x_curr - ( f ( x_curr ) / f_turunan ( x_curr )) print ( \"x_(\" , n + 1 , \") = \" , x_next ) Lalu melakukan pengecekan apakah |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e bila benar maka iterasi = False dan memberikan nilai x sebagai nilai akar yang dicari, dan bila |x_{n+1} - x_n| |x_{n+1} - x_n| tidak <e <e maka melanjutkan iterasi (looping) dengan n+=1 if abs ( x_next - x_curr ) < error : iteration = False else : n += 1 Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Berikut Hasil yang diperoleh dari Hasil Program X_0 = 0 x_ ( 1 ) = 1.2 x_ ( 2 ) = 1.7538461538461536 x_ ( 3 ) = 1.9593973037272008 x_ ( 4 ) = 1.9984752398055106 x_ ( 5 ) = 1.9999976821746035 x_ ( 6 ) = 1.9999999999946272 x = 1.9999999999946272 Metode Secant \u00b6 Metode secant merupakan perbaikan dari metode regula-falsi dan newton raphson dimana kemiringan dua titik dinyatakan sacara diskrit, dengan mengambil bentuk garis lurus yang melalui satu titik. Metode Newton Raphson memerlukan perhitungan turunan fungsi f\u2019(x). Tidak semua fungsi mudah dicari turunannya terutama fungsi yang bentuknya rumit. Turunan fungsi dapat dihilangkan dengan cara menggantinya dengan bentuk lain yang ekivalen Modifikasi metode Newton Raphson dinamakan metode Secant. Pada Metode Newton-Raphson memerlukan syarat wajib yaitu fungsi f(x) harus memiliki turunan f'(x). Sehingga syarat wajib ini dianggap sulit karena tidak semua fungsi bisa dengan mudah mencari turunannya. Oleh karena itu muncul ide dari yaitu mencari persamaan yang ekivalen dengan rumus turunan fungsi. Ide ini lebih dikenal dengan nama Metode Secant. Ide dari metode ini yaitu menggunakan gradien garis yang melalui titik $ (x_0, f(x_0))$ dan $ (x_1, f(x_1))$. Perhatikan gambar dibawah ini. Algortima Pada dengan Motode Secant \u00b6 Definisikan fungsi $ f(x) $ yang akan dicari akarnya Masukkan interval [a,b] [a,b] dimana akar berada, atau bisa dengan menententukan nilai a dan b Tentukan toleransi $ \\epsilon $ dan iterasi maksimum N Hitung $ f(a) $ dan $ f(b) $ Menghitung x = a - [(b-a)/f(b)-f(a)]f(a) x = a - [(b-a)/f(b)-f(a)]f(a) Jika |a-b|< \\epsilon, \\epsilon |a-b|< \\epsilon, \\epsilon di mana $ \\epsilon $ adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 8, bila tidak lanjut ke langkah 7 Set $ a = b $ , $ b =x $ dan pergi ke langkah ke 4 Cetak nilai $ x $ yang merupakan nilai akar yang dicari. Perhitungan dalam Metode Secant \u00b6 Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : f(x) = x^2 - 5x +6 f(x) = x^2 - 5x +6 Langkah kedua menentukan Nilai a dan b, mengambil nilai batas awal (a) = 1 dan nilai batas bawahnya (b) = 2.4 . Maka dapat kita ketahui interval [a,b]= [1,2.4] [a,b]= [1,2.4] Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =100 =100 Menghitung f(a) dan f(b), menghitung f(a) bisa kita gunakan pada fungsi f(x) pada langkah pertama.Dimana f(a)=1^2-5(1)+6=2 f(a)=1^2-5(1)+6=2 dan f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 Menghitung x = a - [(b-a)/f(b)-f(a)]f(a) x = a - [(b-a)/f(b)-f(a)]f(a) , maka $$ a = 1, b = 2.4,f(a) = 2, f(b)=-0.2400000000000002 \\\\ x = a - [(b-a)/f(b)-f(a)]f(a)\\\\ x = 1 - [(2.4 - 1)/-0.2400000000000002 - 2 ] 2 \\\\ x = 3.25 $$ Pada langkah ini mengecek apakah |a-b|< e, e |a-b|< e, e di mana \u03b5 adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 7, bila tidak lanjut ke langkah 6. Dapat kita ketahui bahwa |a-b|= |1-2.4|=-1.4 |a-b|= |1-2.4|=-1.4 maka tidak bisa melanjutkan ke langkah 8 karena $|a-b|tidak < e $ maka lanjut ke langkah 7 Meng -Set a = b , b =x dan pergi ke langkah ke 4. dimana $$ a = b,maka \\quad a = 2.4, b = 3.25 \\quad dan \\quad lanjut \\quad keLangkah \\quad ke-4 $$ Cetak nilai x yang merupakan nilai akar yang dicari. Implementasi Algoritma Metode Secant Dengan Python \u00b6 Pada Implementasi Algoritma Metode Secant ini, Pada Langkah pertama ini membuat fungsi f(x) untuk bisa langsung memudahkan dalam perhitungan def f ( x ): return x ** 2 - 5 * x + 6 Pada Langkah Berikutnya membuat variabel kosong seperti variabel a dan b, serta error yang akan digunakan error = 0.0001 a = 1 b = 2.4 Langkah Selanjutnya membuat fungsi , def secant untuk bisa langsung mengkalkulasi hasil perhitungan pada fungsi yang digunakan diatas dan memberikan suatu iterasi (looping) ketika ada kondisi yang sudah terpenuhi def secant ( a , b ): iteration = True while iteration : x = a - (( b - a ) / ( f ( b ) - f ( a ))) * f ( a ) print ( 'x = ' , x ) if abs ( a - b ) < error : iteration = False else : a = b b = x print ( 'x =' , x ) secant ( a , b ) Dapat kita ketahui pada program diatas dimana memberikan sebuah inisial terlebih dahulu dimana iterasi bervalue True Dimana pada fungsi perulangan pada while iteration, ketika kondisi telah terpenuhi maka akan melanjutkan ke proses perhitungan x = a - [(b-a)/f(b)-f(a)]f(a) x = a - [(b-a)/f(b)-f(a)]f(a) setelah melakukan sebuah while iterasi while iteration : x = a - (( b - a ) / ( f ( b ) - f ( a ))) * f ( a ) print ( 'x = ' , x ) if abs ( a - b ) < error : iteration = False else : a = b b = x print ( 'x =' , x ) Lanjut melakukan pengecekan pada kondisi ketika nilai dari a-b < error maka iterasi akan bernilai False dan bila kondisi ini tidak terpenuhi . Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Dan ketika (a-b) tidak < error maka akan melakukan proses else : , dimana proses ini melakukan proses perpindahan (meng set a = b dan b = x) if abs ( a - b ) < error : iteration = False else : a = b print ( \"set a = b maka a = \" , b ) b = x print ( \"set b = x maka b = \" , x ) Berikut merupakan hasil saat program dijalankan. a = 1 b = 2.4 x = 2.25 x = 1.7142857142857166 x = 2.068965517241379 x = 2.016194331983806 x = 1.998779185106057 x = 2.0000200708123343 x = 2.0000000244733602 x = 1.999999999999509 x = 1.999999999999509 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 2"},{"location":"komnum/Persamaan non linear/#mencari-akar-persamaan-pada-persamaan-non-linear","text":"Pencarian akar pada persamaan dapat dilakukan dengan pendekatan metode numerik, yaitu dengan metode berikut: Metode Bisection Metode Regula Falsi Metode Newton Rapson Motode Secant Metode - metode tersebut dapat di manfaatkan untuk mencari akar dari persamaan non-linear. berikut adalah perhitungan dan implementasi pada bahasa pemrograman python dari algoritma metode numerik tersebut.","title":"Mencari Akar Persamaan pada Persamaan Non Linear"},{"location":"komnum/Persamaan non linear/#metode-bisection","text":"Metode biseksi ini membagi range menjadi 2 bagian, dari dua bagian ini dipilih bagian mana yang mengandung akar sedangkan bagian yang tidak mengandung akar akan dibuang. Hal ini dilakukan berulang-ulang hingga diperoleh suatu akar persamaan.","title":"Metode Bisection"},{"location":"komnum/Persamaan non linear/#algortima-pada-motode-bisection","text":"Definisikan fungsi $ f(x) $ yang akan dicari akarnya Tentukan nilai $ a $ dan $ b $ Tentukan toleransi $ \\epsilon $ dan iterasi maksimum $ N $ Hitung $ f(a) $ dan $ f(b) $ Jika $ f(a).f(b)>0 $ maka proses dihentikan karena tidak ada akar, bila tidak maka dilanjutkan Hitung $ x = (a+b)/2 $ Hitung $ f(x) $ Bila$ f(x).f(a)<0 $ maka $ b = x $ dan $ f(b)=f(x) $, bila tidak maka $ a=x $ dan $ f(a)=f(x) $ Jika $ |b-a| < \\epsilon $ atau iterasi telah mencapai iterasi maks maka proses dihentikan dan didapatkan akar $ x $, bila tidak, ulangi langkah 6","title":"Algortima Pada Motode Bisection"},{"location":"komnum/Persamaan non linear/#perhitungan-dalam-metode-bisection","text":"Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : $ f(x) = x^2 - 5x +6 $ Langkah kedua menentukan Nilai a dan b, mengambil nilai batas awal $ (a) = 1 $ dan nilai batas bawahnya $ (b) = 2.4 $ Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =100 =100 Menghitung f(a) dan f(b), menghitung f(a) bisa kita gunakan pada fungsi f(x) pada langkah pertama.Dimana $ f(a)=1^2-5(1)+6=2$ dan $f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 $ Mengecek dengan kondisi ketika $ f(a).f(b)>0 $ maka proses itu akan diberhentikan, bila f(a).f(b)<0 f(a).f(b)<0 maka akan lanjut ke proses berikutnya. Dimana ketika f(a) f(a) yang didapatkan = 2 = 2 dan f(b) = -0.2400000000000002 f(b) = -0.2400000000000002 maka $ f(a).f(b) = 2 x -0.2400000000000002 = -0.4800000000000004 $ maka sudah dapat diketahui f(a).f(b) < 0 f(a).f(b) < 0 Pada langkah ini menghitung $ x = (a+b)/2 $, dimana a =1 dan b = 2.4 maka $ x = (1+2.4)/2 = 1.7 $ Setelah mendapatkan nilai $ x $ maka menghitung nilai f(x)nya f(x)nya dengan$ x = 1.7$ maka $f(1.7)= (1.7)^2 -5(1.7)+6 = 0.3899999999999997 $, maka didapatkan f(x) = 0.3899999999999997 f(x) = 0.3899999999999997 Melakukan pengecekan bila f(x).f(a)<0 f(x).f(a)<0 maka b = x b = x dan f(b)=f(x) f(b)=f(x) , tapi ketika f(x),f(a) tidak < dari 0 maka a =x dan f(a) = f(x) , dimana f(x) = 0.3899999999999997 dan $f(a) = 2 $ maka $f(x).f(a) = 0.7799999999999994 $ tidak < dari 0 < dari 0 maka a = x a = x , jadi $a = 1,7 dan dan f(a) = 0.3899999999999997 $ Maka Langkah berikutnya mengecek jika |b-a|<e |b-a|<e atau Iterasi sudah mencapai iterasi maksimum maka proses dihentikan dan mendapatkan akar yang dicari. Dengan mengecek hasil dari |b-a|<e |b-a|<e maka |b-a| =| 2.4 - 1.7|=0.7 |b-a| =| 2.4 - 1.7|=0.7 dapat diketahui bahwa |b-a| |b-a| tidak < < dari e maka terus melakukan iterasi sampai dengan iterasi maksimum","title":"Perhitungan dalam Metode Bisection"},{"location":"komnum/Persamaan non linear/#implementasi-algoritma-metode-bisection-dengan-python","text":"Berikut merupakan hasil implementasi metode bisection untuk mencari akar dari persamaan $ x^2 - 5x + 6 $ dengan batas error maksimal 0.001 . error = 0.001 a = 0 b = 1 def f ( x ): return x ** 2 - 5 * x + 6 def bisection ( a , b ): iteration = True while iteration : if f ( a ) * f ( b ) < 0 : while iteration : x = ( a + b ) / 2 if f ( a ) * f ( x ) < 0 : b = x elif f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : return x iteration = False else : b += 0.1 print ( 'x =' , x ) bisection ( a , b ) Dalam program tersebut di deklarasikan nilai a = 0 dan b = 1, dalam program tersebut akan mancari nilai b dengan sendirinya, dengan menambah b dengan 0.1 error = 0.001 a = 0 b = 1 Kemudian membuat persamaan yang di deklarasikan pada fungsi f(x). def f ( x ): return x ** 2 - 5 * x + 6 Selanjutnya merupakan program utama untuk mencari nilai x dari persamaan yang telah di deklarasikan. program akan berjalan dengan algoritma sebagaimana semestinya dalam metode bisection. saat nilai f(a)f(b) tidak kurang dari 0, maka akan mencarikan nilai b sampai kurang dari 0. def bisection ( a , b ): iteration = True while iteration : if f ( a ) * f ( b ) < 0 : while iteration : x = ( a + b ) / 2 if f ( a ) * f ( x ) < 0 : b = x elif f ( x ) * f ( b ) < 0 : a = x if abs ( a - b ) < error : return x iteration = False else : b += 0.1 Saat program tersebut di jalankan maka menghasilkan output seperti berikut dengan nilai x yang di dapat yaitu : 2.000024414062501. x = 1.0500000000000005 x = 1.5750000000000006 x = 1.8375000000000008 x = 1.9687500000000009 x = 2.0343750000000007 x = 2.001562500000001 x = 1.9851562500000008 x = 1.9933593750000007 x = 1.9974609375000008 x = 1.9995117187500009 x = 2.000537109375001 x = 2.000024414062501 akar persamaan ( x ) = 2.000024414062501","title":"Implementasi Algoritma Metode Bisection Dengan Python"},{"location":"komnum/Persamaan non linear/#metode-regula-falsi","text":"Metode ini adalah metode tertua untuk menemukan akar sebenarnya dari persamaan f (x) = 0. Ia juga dikenal sebagai metode akor atau metode interpolasi linier. Seperti metode pembagian dua bagian, posisi yang salah satu metodenya dimulai dengan dua titik a_0 a_0 dan b_0 b_0 sedemikian rupa sehingga f ( a_0 a_0 ) dan f( b_0 b_0 ) memiliki tanda-tanda yang berlawanan, yang menyiratkan oleh teorema nilai menengah bahwa fungsi f memiliki akar dalam interval [a_0, b_0] [a_0, b_0] , dengan asumsi kesinambungan dari fungsi f. Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position. Metode ini juga merupakan penyempurnan dari metode bisection.","title":"Metode Regula Falsi"},{"location":"komnum/Persamaan non linear/#algortima-pada-motode-regula-falsi","text":"1.Definisikan fungsi $ f(x) $ yang akan dicari akarnya 2.Masukkan interval [a,b] [a,b] dimana akar berada, atau bisa dengan menententukan nilai a dan b 3.Tentukan toleransi $ \\epsilon $ dan iterasi maksimum N 4.Hitung $ f(a) $ dan $ f(b) $ 5.Mengecek nilai f(a).f(b) <0 f(a).f(b) <0 bila tidak maka proses nilai $ f(a).f(b)>0 $, akan memberhentikan proses perhitungan (program) 6.Mengkalkulasi x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b)|} x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b)|} 7.Jika $ f(a).f(x)<0 $ maka $ b = x $, ketika tidak jika $ f(x)f(b)<0 $ maka $ a = x $ 8.Jika $ |b-a|< \\epsilon $ , $ \\epsilon $ menjadi akurasi yang ditentukan. Lalu lanjutkan ke Langkah 9 yang lain Langkah 4 9.Cetak nilai $ x $ yang dibutuhkan akar","title":"Algortima Pada Motode Regula-Falsi"},{"location":"komnum/Persamaan non linear/#perhitugan-dalam-metode-regula-falsi","text":"Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : f(x) = x^2 - 5x +6 f(x) = x^2 - 5x +6 Langkah kedua menentukan Nilai a dan b, mengambil nilai batas awal (a) = 1 dan nilai batas bawahnya (b) = 2.4 . Maka dapat kita ketahui interval [a,b]= [1,2.4] [a,b]= [1,2.4] Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =50 =50 Menghitung f(a) dan f(b), menghitung f(a) bisa kita gunakan pada fungsi f(x) pada langkah pertama.Dimana f(a)=1^2-5(1)+6=2 f(a)=1^2-5(1)+6=2 dan f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 Mengecek dengan kondisi ketika $ f(a).f(b)>0$ maka proses itu akan diberhentikan, bila f(a).f(b)<0 f(a).f(b)<0 maka akan lanjut ke proses berikutnya. Dimana ketika f(a) f(a) yang didapatkan = 2 = 2 dan f(b) = -0.2400000000000002 f(b) = -0.2400000000000002 maka $ f(a).f(b) $= 2 x -0.2400000000000002 = -0.4800000000000004 maka sudah dapat diketahui f(a).f(b) < 0 f(a).f(b) < 0 Mengkalkulus x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} , maka $$ x = {(1|-0.2400000000000002|+2.4|2|) \\over |2| +|-0.2400000000000002|} \\\\ x = {1.2400000000000002 + 4.8 \\over 2+0.2400000000000002} \\\\ x = {6.04 \\over 2.24 } \\\\ x = 2.696428571428571 $$ Pada langkah ini mengecek apakah $ f(a).f(x)<0$ maka b = x b = x , ketika tidak jika f(x)f(b)<0 f(x)f(b)<0 maka a = x a = x . pertama harus menghitung f(x)nya f(x)nya dimana x nya = 2.696428571428571 2.696428571428571 , maka $$ f(x)= x^2 -5x+6, \\quad dimana (x)nya = 2.69642857142857 \\\\ f(x) = (2.69642857142857)^2-5(2.69642857142857)+6 \\\\ f(x) = 7.270727040816318 - 13.482142857142856+6 \\\\ f(x) = -0.2114158163265376 $$ Mengecek apakah f(a).f(x)<0 f(a).f(x)<0 , dimana f(a)=2, f(a)=2, dan f(x)=-0.2114158163265376 f(x)=-0.2114158163265376 , maka $$ f(a).f(x)= 2 \\quad X -0.2114158163265376 = -0.4228316326530752 $$ Dapat diketahui bahwa f(a).f(x)<0 f(a).f(x)<0 maka set b = x, b = 2.696428571428571 b = 2.696428571428571 Mengecek |b-a|< \u03b5 |b-a|< \u03b5 , \u03b5 menjadi akurasi yang ditentukan. Lalu lanjutkan ke Langkah berikutnya yang lain Langkah 4 , maka melakukan pengecekan $$ |b-a|= 2.696428571428571 -2 = 0.6964285714285712 \\\\ |b-a| = 0.6964285714285712 \\quad tidak < 0 , maka mengulang \\quad ke langkah \\quad ke 4 $$ Akan terus melakukan proses iterasi sampai |b-a|<e |b-a|<e ketika proses berhasil maka lanjut ke langkah 9 Mencetak nilai x , itu lah hasil dari nilai akar yang diperoleh","title":"Perhitugan dalam Metode Regula Falsi"},{"location":"komnum/Persamaan non linear/#implementasi-algoritma-metode-regula-falsi-dengan-python","text":"Pada Implementasi Algoritma Metode Regulasi-Falsi ini, Pada Langkah pertama ini membuat fungsi f(x) untuk bisa langsung memudahkan dalam perhitungan def f ( x ): return x ** 2 - 5 * x + 6 Pada Langkah Berikutnya membuat variabel kosong seperti variabel a dan b, serta error yang akan digunakan error = 0.0001 a = 1 b = 2.4 Langkah Selanjutnya membuat fungsi , def Regulasi_falsi untuk bisa langsung mengkalkulasi hasil perhitungan pada fungsi yang digunakan diatas dan , memberikan suatu iterasi (looping) ketika ada kondisi yang sudah terpenuhi def regula_falsi ( a , b ): i = 0 max_iter = 50 iteration = True while iteration and i < max_iter : if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x print ( \"maka b = x , b = \" , x ) if f ( x ) * f ( b ) < 0 : a = x print ( \"maka a = x , a = \" , x ) if abs ( a - b ) < error : iteration = False else : i += 1 else : print ( 'tidak di temukan akar' ) print ( 'x =' , x ) regula_falsi ( a , b ) Dapat kita ketahui pada program diatas dimana memberikan sebuah inisial terlebih dahulu dimana iterasi bervalue True, i = 0, dan iterasi maksimum yang digunakan 50. DImana pada fungsi perulangan pada while iterasi dan i < max_iterasi, ketika kondisi telah terpenuhi maka akan melanjutkan ke kondisi berikutnya dimana pada kondisi ini f(a).f(b)< 0, ketika kondisinya telah tercapai maka melanjutkan ke proses perhitungan x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} x = {(a|f(b)|+b|f(a)|) \\over |f(a)| +|f(b|} . Ketika sudah melakukan proses pencarian x maka melanjutkan ke proses kondisi untuk melakukan swap (perubahan) dengan b =x ketika kondisi f(a).f(x)<0. atau kondisi f(x).f(b)<0 maka akan swap a = x if f ( a ) * f ( b ) < 0 : x = ( a * abs ( f ( b )) + b * abs ( f ( a ))) / ( abs ( f ( a )) + abs ( f ( b ))) if f ( a ) * f ( x ) < 0 : b = x print ( \"maka b = x , b = \" , x ) if f ( x ) * f ( b ) < 0 : a = x print ( \"maka a = x , a = \" , x ) Lanjut melakukan pengecekan pada kondisi ketika nilai dari a-b < error maka iterasi akan bernilai False dan bila kondisi ini tidak terpenuhi maka melakukan proses penambahan i+=1 if abs ( a - b ) < error : iteration = False else : i += 1 Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Berikut Hasil yang diperoleh dari Hasil Program Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Berikut Hasil yang diperoleh dari Hasil Program maka b = x , b = 2.25 maka b = x , b = 2.142857142857143 maka b = x , b = 2.076923076923077 maka b = x , b = 2.0400000000000005 maka b = x , b = 2.020408163265306 maka b = x , b = 2.010309278350516 maka b = x , b = 2.0051813471502595 maka b = x , b = 2.0025974025974027 maka b = x , b = 2.001300390117035 maka b = x , b = 2.0006506180871835 maka b = x , b = 2.000325414904003 maka b = x , b = 2.0001627339300247 maka b = x , b = 2.000081373586134 maka b = x , b = 2.000040688448549 maka b = x , b = 2.0000203446381697 maka b = x , b = 2.000010172422562 maka b = x , b = 2.00000508623715 maka b = x , b = 2.0000025431250426 maka b = x , b = 2.0000012715641384 maka b = x , b = 2.000000635782474 maka b = x , b = 2.0000003178913377 maka b = x , b = 2.000000158945694 maka b = x , b = 2.000000079472853 maka b = x , b = 2.000000039736428 maka b = x , b = 2.0000000198682146 maka b = x , b = 2.0000000099341078 maka b = x , b = 2.0000000049670534 maka b = x , b = 2.000000002483527 maka b = x , b = 2.000000001241763 maka b = x , b = 2.000000000620882 maka b = x , b = 2.0000000003104406 maka b = x , b = 2.0000000001552207 maka b = x , b = 2.00000000007761 maka b = x , b = 2.0000000000388054 maka b = x , b = 2.0000000000194023 maka b = x , b = 2.0000000000097016 maka b = x , b = 2.0000000000048503 maka b = x , b = 2.0000000000024256 maka b = x , b = 2.0000000000012124 maka b = x , b = 2.0000000000006066 maka b = x , b = 2.000000000000303 maka b = x , b = 2.000000000000152 maka b = x , b = 2.0000000000000755 maka b = x , b = 2.000000000000038 maka b = x , b = 2.0000000000000187 maka b = x , b = 2.0000000000000098 maka b = x , b = 2.0000000000000044 maka b = x , b = 2.0000000000000027 x = 2.000000000000001","title":"Implementasi Algoritma Metode Regula-Falsi Dengan Python"},{"location":"komnum/Persamaan non linear/#metode-newton-raphson","text":"Metode pencarian akar persamaan dengan memanfaatkan kemiringan dan selisih tinggi dari dua titik batas range. Dua titik a dan b pada fungsi f(x) digunakan untuk mengestimasi posisi c dari akar interpolasi linier. Dikenal dengan metode False Position. Metode ini juga merupakan penyempurna dari metode bisection.","title":"Metode Newton Raphson"},{"location":"komnum/Persamaan non linear/#algortima-pada-motode-newton-raphson","text":"1.Definisikan fungsi $ f(x) , f'(x) $ yang akan dicari akarnya 2.Tentukan tebakan awal akar (katakanlah x_0 x_0 ) dan set $ n = 0 $ 3.Tentukan toleransi $ \\epsilon $ dan iterasi maksimum N 4.Hitung x_{n+1}=x_n -[f(x_n)/f'(x)_n] x_{n+1}=x_n -[f(x_n)/f'(x)_n] 5.Jika |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e , di mana \u03b5 adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 7, bila lanjut ke langkah 6 6.Set $ n = n+1 $ dan pergi ke langkah 4 7.Cetak nilai $ x_n$ yang merupakan nilai akar yang diperlukan","title":"Algortima Pada Motode Newton Raphson"},{"location":"komnum/Persamaan non linear/#perhitungan-dalam-metode-newton-raphson","text":"Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : f(x) = x^2 - 5x +6 f(x) = x^2 - 5x +6 dan f'(x)= 2x-5 f'(x)= 2x-5 Langkah kedua menentukan Nilai x_0 x_0 dan x_1 x_1 , mengambil nilai batas awal (x_0)= 1 (x_0)= 1 dan nilai batas bawahnya (x_1) = 2.4 (x_1) = 2.4 Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =50 =50 Pada Langkah ini mengecek pada (x_0) = 1 (x_0) = 1 dan (x_1) (x_1) = 2.4. Apakah |x_1 - x_0|<e |x_1 - x_0|<e . Dan dapat kita ketahui bahwa > e maka lanjut ke proses berikutnya Menghitung f(x_1) f(x_1) dan f'(x_1) f'(x_1) , menghitung f(x_1) f(x_1) bisa kita gunakan pada fungsi f(x) dan pada f'(x_1) f'(x_1) bisa kita gunakan pada fungsi f'(x) langkah pertama. Dimana f(x_1)=(2.4)^2-5(2.4)+6= -0.2400000000000002 f(x_1)=(2.4)^2-5(2.4)+6= -0.2400000000000002 dan f'(x_1)=2 x (2.4) -5 =-0.20000000000000018 f'(x_1)=2 x (2.4) -5 =-0.20000000000000018 Mengecek dengan kondisi ketika |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e , di mana \u03b5 adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 7. Maka $$ X_2 = X_1 -{f(x_1) \\over f'(x_1)} \\\\ X_2 = 2.4 -{-0.2400000000000002 \\over -0.20000000000000018} \\\\ X_2 = 2.4 - 1.2 \\\\ X_2 = 1.2 $$ Melakukan Proses pengecekan ketika sudah memperoleh x_2= 1.2 x_2= 1.2 maka apakah |x_2 - x_1|<e. Ketika kondisi tidak terpenuhi mengulang proses iterasi dengan melakukan penambahan n+1 jadi berpindah untuk mencari x_3 x_3 . Bila proses kondisi terpenuhi dengan |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e maka lanjut ke proses langkah ke 7 Cetak nilai $ x_n$ yang merupakan nilai akar yang diperlukan","title":"Perhitungan dalam Metode Newton Raphson"},{"location":"komnum/Persamaan non linear/#implementasi-algoritma-metode-newton-raphson-dengan-python","text":"Pada Implementasi Algoritma Metode Newton Raphson ini, Pada Langkah pertama ini membuat fungsi f(x) dan fungsi f'(x) untuk bisa langsung memudahkan dalam perhitungan def f ( x ): return x ** 2 - 5 * x + 6 def f_turunan ( x ): return 2 * x - 5 Pada Langkah Berikutnya membuat variabel kosong seperti variabel x0, serta error yang akan digunakan error = 0.0001 xo = 0 Langkah Selanjutnya membuat fungsi , def Newton Raphson untuk bisa langsung mengkalkulasi hasil perhitungan pada fungsi yang digunakan diatas dan memberikan suatu iterasi (looping) ketika ada kondisi yang sudah terpenuhi def newton_raphson ( x0 ): iteration = True n = 0 x_next = x0 print ( \"X_0 =\" , x_next ) while iteration : x_curr = x_next x_next = x_curr - ( f ( x_curr ) / f_turunan ( x_curr )) print ( \"x_(\" , n + 1 , \") = \" , x_next ) if abs ( x_next - x_curr ) < error : iteration = False else : n += 1 print ( \"x = \" , x_next ) newton_raphson ( xo ) Dapat kita ketahui pada program diatas dimana memberikan sebuah inisial terlebih dahulu dimana iterasi (n) = 0 ,dan inisial iterasi bervalue True, dimana n = 0 akan dimulai dari iterasi 0 untuk bisa melakukan sebuah perulangan (looping ) DImana pada fungsi perulangan pada while iteration, ketika kondisi telah terpenuhi maka akan melanjutkan ke perpindahan dan perhitungan setelah melakukan sebuah while iterasi x_curr = x_next x_next = x_curr - ( f ( x_curr ) / f_turunan ( x_curr )) print ( \"x_(\" , n + 1 , \") = \" , x_next ) Lalu melakukan pengecekan apakah |x_{n+1} - x_n|<e |x_{n+1} - x_n|<e bila benar maka iterasi = False dan memberikan nilai x sebagai nilai akar yang dicari, dan bila |x_{n+1} - x_n| |x_{n+1} - x_n| tidak <e <e maka melanjutkan iterasi (looping) dengan n+=1 if abs ( x_next - x_curr ) < error : iteration = False else : n += 1 Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Berikut Hasil yang diperoleh dari Hasil Program X_0 = 0 x_ ( 1 ) = 1.2 x_ ( 2 ) = 1.7538461538461536 x_ ( 3 ) = 1.9593973037272008 x_ ( 4 ) = 1.9984752398055106 x_ ( 5 ) = 1.9999976821746035 x_ ( 6 ) = 1.9999999999946272 x = 1.9999999999946272","title":"Implementasi Algoritma Metode Newton Raphson Dengan Python"},{"location":"komnum/Persamaan non linear/#metode-secant","text":"Metode secant merupakan perbaikan dari metode regula-falsi dan newton raphson dimana kemiringan dua titik dinyatakan sacara diskrit, dengan mengambil bentuk garis lurus yang melalui satu titik. Metode Newton Raphson memerlukan perhitungan turunan fungsi f\u2019(x). Tidak semua fungsi mudah dicari turunannya terutama fungsi yang bentuknya rumit. Turunan fungsi dapat dihilangkan dengan cara menggantinya dengan bentuk lain yang ekivalen Modifikasi metode Newton Raphson dinamakan metode Secant. Pada Metode Newton-Raphson memerlukan syarat wajib yaitu fungsi f(x) harus memiliki turunan f'(x). Sehingga syarat wajib ini dianggap sulit karena tidak semua fungsi bisa dengan mudah mencari turunannya. Oleh karena itu muncul ide dari yaitu mencari persamaan yang ekivalen dengan rumus turunan fungsi. Ide ini lebih dikenal dengan nama Metode Secant. Ide dari metode ini yaitu menggunakan gradien garis yang melalui titik $ (x_0, f(x_0))$ dan $ (x_1, f(x_1))$. Perhatikan gambar dibawah ini.","title":"Metode Secant"},{"location":"komnum/Persamaan non linear/#algortima-pada-dengan-motode-secant","text":"Definisikan fungsi $ f(x) $ yang akan dicari akarnya Masukkan interval [a,b] [a,b] dimana akar berada, atau bisa dengan menententukan nilai a dan b Tentukan toleransi $ \\epsilon $ dan iterasi maksimum N Hitung $ f(a) $ dan $ f(b) $ Menghitung x = a - [(b-a)/f(b)-f(a)]f(a) x = a - [(b-a)/f(b)-f(a)]f(a) Jika |a-b|< \\epsilon, \\epsilon |a-b|< \\epsilon, \\epsilon di mana $ \\epsilon $ adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 8, bila tidak lanjut ke langkah 7 Set $ a = b $ , $ b =x $ dan pergi ke langkah ke 4 Cetak nilai $ x $ yang merupakan nilai akar yang dicari.","title":"Algortima Pada dengan Motode Secant"},{"location":"komnum/Persamaan non linear/#perhitungan-dalam-metode-secant","text":"Pada Langkah Awal Mendifinisikan sebuah fungsi f(x), dimana f(x) yang akan digunakan adalah : f(x) = x^2 - 5x +6 f(x) = x^2 - 5x +6 Langkah kedua menentukan Nilai a dan b, mengambil nilai batas awal (a) = 1 dan nilai batas bawahnya (b) = 2.4 . Maka dapat kita ketahui interval [a,b]= [1,2.4] [a,b]= [1,2.4] Langkah ketiga menentukan toleransi tingkat error dan iterasi maksimum (N), pada langkah ini tolerasi tingkat error yang akan digunakan =0,0001 =0,0001 dan iterasi maksimum yang digunakan =100 =100 Menghitung f(a) dan f(b), menghitung f(a) bisa kita gunakan pada fungsi f(x) pada langkah pertama.Dimana f(a)=1^2-5(1)+6=2 f(a)=1^2-5(1)+6=2 dan f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 f(b)=(2.4)^2-5(2.4)+6=-0.2400000000000002 Menghitung x = a - [(b-a)/f(b)-f(a)]f(a) x = a - [(b-a)/f(b)-f(a)]f(a) , maka $$ a = 1, b = 2.4,f(a) = 2, f(b)=-0.2400000000000002 \\\\ x = a - [(b-a)/f(b)-f(a)]f(a)\\\\ x = 1 - [(2.4 - 1)/-0.2400000000000002 - 2 ] 2 \\\\ x = 3.25 $$ Pada langkah ini mengecek apakah |a-b|< e, e |a-b|< e, e di mana \u03b5 adalah akurasi yang ditentukan, lalu lanjutkan ke Langkah 7, bila tidak lanjut ke langkah 6. Dapat kita ketahui bahwa |a-b|= |1-2.4|=-1.4 |a-b|= |1-2.4|=-1.4 maka tidak bisa melanjutkan ke langkah 8 karena $|a-b|tidak < e $ maka lanjut ke langkah 7 Meng -Set a = b , b =x dan pergi ke langkah ke 4. dimana $$ a = b,maka \\quad a = 2.4, b = 3.25 \\quad dan \\quad lanjut \\quad keLangkah \\quad ke-4 $$ Cetak nilai x yang merupakan nilai akar yang dicari.","title":"Perhitungan dalam Metode Secant"},{"location":"komnum/Persamaan non linear/#implementasi-algoritma-metode-secant-dengan-python","text":"Pada Implementasi Algoritma Metode Secant ini, Pada Langkah pertama ini membuat fungsi f(x) untuk bisa langsung memudahkan dalam perhitungan def f ( x ): return x ** 2 - 5 * x + 6 Pada Langkah Berikutnya membuat variabel kosong seperti variabel a dan b, serta error yang akan digunakan error = 0.0001 a = 1 b = 2.4 Langkah Selanjutnya membuat fungsi , def secant untuk bisa langsung mengkalkulasi hasil perhitungan pada fungsi yang digunakan diatas dan memberikan suatu iterasi (looping) ketika ada kondisi yang sudah terpenuhi def secant ( a , b ): iteration = True while iteration : x = a - (( b - a ) / ( f ( b ) - f ( a ))) * f ( a ) print ( 'x = ' , x ) if abs ( a - b ) < error : iteration = False else : a = b b = x print ( 'x =' , x ) secant ( a , b ) Dapat kita ketahui pada program diatas dimana memberikan sebuah inisial terlebih dahulu dimana iterasi bervalue True Dimana pada fungsi perulangan pada while iteration, ketika kondisi telah terpenuhi maka akan melanjutkan ke proses perhitungan x = a - [(b-a)/f(b)-f(a)]f(a) x = a - [(b-a)/f(b)-f(a)]f(a) setelah melakukan sebuah while iterasi while iteration : x = a - (( b - a ) / ( f ( b ) - f ( a ))) * f ( a ) print ( 'x = ' , x ) if abs ( a - b ) < error : iteration = False else : a = b b = x print ( 'x =' , x ) Lanjut melakukan pengecekan pada kondisi ketika nilai dari a-b < error maka iterasi akan bernilai False dan bila kondisi ini tidak terpenuhi . Maka ketika proses sudah berhasil terpenuhi maka iterasi akan False dan memprint hasil dari nilai akar yang di peroleh . Dan ketika (a-b) tidak < error maka akan melakukan proses else : , dimana proses ini melakukan proses perpindahan (meng set a = b dan b = x) if abs ( a - b ) < error : iteration = False else : a = b print ( \"set a = b maka a = \" , b ) b = x print ( \"set b = x maka b = \" , x ) Berikut merupakan hasil saat program dijalankan. a = 1 b = 2.4 x = 2.25 x = 1.7142857142857166 x = 2.068965517241379 x = 2.016194331983806 x = 1.998779185106057 x = 2.0000200708123343 x = 2.0000000244733602 x = 1.999999999999509 x = 1.999999999999509 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Implementasi Algoritma Metode Secant Dengan Python"},{"location":"komnum/aproxrimasi error/","text":"Menghitung Nilai $ e^x $ dengan Pendekatan Deret MacLaurin \u00b6 Deret Taylor dan Deret MacLaurin \u00b6 Sebuah fungsi $ f(x) $ yang memiliki turunan $ f^1(x) $, $ f^2(x) $, $ f^3(x) $, dan seterusnya yang kontinyu dalam interval $ I $ dan $ a, x I $ maka untuk $ x $ disekitar $ a $ yaitu $ |x \u2013 a| $ < , $ f(x) $ dapat diekspansi kedalam Deret Taylor. Deret Taylor didefinisikan seperti berikut. f(x) = f(a) + {f^1(a) (x-a) \\over 1!} + {f^2(a) (x-a)^2 \\over 2!} + {f^3(a) (x-a)^3 \\over 3!} ... {f^n(a) (x-a)^n \\over n!} f(x) = f(a) + {f^1(a) (x-a) \\over 1!} + {f^2(a) (x-a)^2 \\over 2!} + {f^3(a) (x-a)^3 \\over 3!} ... {f^n(a) (x-a)^n \\over n!} Deret MacLaurin hampir sama dengan dengan Deret Taylor, hanya saja dalam deret maclaurin nilai a=0, sehingga persamaannya adalah seperti berikut. f(x) = f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^3(0)x^3 \\over 3!} ... {f^n(0)x^n \\over n!} f(x) = f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^3(0)x^3 \\over 3!} ... {f^n(0)x^n \\over n!} Deret MacLaurin biasa disebut sebagai deret Taylor baku, kerena deret maclaurin merupakan standar atau dasar yang berlaku dengan a=0. Atau persamaan Deret MacLaurin diatas dapat ditulis seperti berikut f(x) = \\sum \\limits_{i=0}^{n} {f^i(0)x^i \\over i!} f(x) = \\sum \\limits_{i=0}^{n} {f^i(0)x^i \\over i!} Dalam deret MacLaurin yaitu menjumlahkan tiap-tiap suku sampai batas yang ditentukan, sehingga akan menghasilkan nilai yang mendekati nilai sebenarnya. Deret Maclaurin ini dimanfaatkan dalam metode numerik untuk menghitung atau menghampiri nilai fungsi yang susung dihitung secara menual, seperti halnya kita ingin mencari nilai dari $ sin x $, $ cos x $, $ e^x $, $ log x $, atau $ ln(x+1) $. Kita membutuhkan alat khusus, seperti kalkulator atau tabel khusus untuk mencari nilai-nilai dari dari fungsi tersebut. Dalam kasus ini akan dihitung nilai dari $ e^x $ secara menual dengan x=1, serta menerapkannya dalam bahasa pemrograman python untuk menghitung $ e^{3x} $. Perhitung nilai $ e^x $ dengan $ x=1 $ \u00b6 Perhitungan nilai $ e^x $ memiliki fungsi, yaitu $ f(x)=e^x $ dengan turunan berpola seperti berikut. f(x) = e^x \\\\ f^1(x) = e^x \\\\ f^2(x) = e^x \\\\ . \\\\ . \\\\. \\\\ f^n(x) = e^x f(x) = e^x \\\\ f^1(x) = e^x \\\\ f^2(x) = e^x \\\\ . \\\\ . \\\\. \\\\ f^n(x) = e^x Ketika $ e^{3x} $ maka polanya adalah { } f(x) = e^x \\\\ f^1(x) = 3e^{3x} \\\\ f^2(x) = 9e^{3x} \\\\ f^3(x) = 27e^{3x} \\\\ . \\\\ . \\\\ . { } f(x) = e^x \\\\ f^1(x) = 3e^{3x} \\\\ f^2(x) = 9e^{3x} \\\\ f^3(x) = 27e^{3x} \\\\ . \\\\ . \\\\ . yang artinya turunannya adalah koefisien dipangkat turunan ke i. Kemudian kita dapat menghitung dengan deret MacLaurin f(x) \\approx f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^1(0)x^3 \\over 3!} + {f^4(0)x \\over 4!} + {f^5(0)x^5 \\over 5!} ... \\\\ f(1) \\approx 1 + 1 + {1 \\over 2} + {1 \\over 6} + {1 \\over 24} + {1 \\over 120} ... \\\\ f(1) \\approx 2.7166666666666663 f(x) \\approx f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^1(0)x^3 \\over 3!} + {f^4(0)x \\over 4!} + {f^5(0)x^5 \\over 5!} ... \\\\ f(1) \\approx 1 + 1 + {1 \\over 2} + {1 \\over 6} + {1 \\over 24} + {1 \\over 120} ... \\\\ f(1) \\approx 2.7166666666666663 dengan menghitung menggunakan 5 suku pada deret maclaurin, maka menghasilkan selisih yang cukup jauh dengan nilai sebernarnya. nilai ( True Value ) dari $ e^x $ dengan $ x=1 $ adalah 2.718281828459045 ( yang di dapat dari module math.e di python ), dan nilai perkiraan yang dihasilkan dari perhitungan diatas, yaitu 2.7166666666666663 dengan x=1. Karena kita mengetahui nilai sebenarnya dari $ e^x $, maka kita dapat telah menghitung True Error dari perkiraan tersebut. {E_t = True Value - Approximate Vallue} \\\\ {E_t = 2.7166666666666663 - 2.718281828459045} \\\\ {E_t = 0.0016151617923787498} {E_t = True Value - Approximate Vallue} \\\\ {E_t = 2.7166666666666663 - 2.718281828459045} \\\\ {E_t = 0.0016151617923787498} Maka didapatkan nilai True Error, yaitu 0.0016151617923787498. Implementasi Deret MacLaurin pada Python \u00b6 Pada implementasi deret MacLaurin dengan bahasa pemrograman python, kita akan mencoba untuk menghitung nilai dari $ e^{3x} $ dengan batas error/threshold 0,001. import math error = 0.001 def percent ( angka ): return str ( round ( angka * 100 , 4 )) + '%' def f ( x ): f_turunan = 1 current = i = 0 iteration = True while iteration : old = current current += ( f_turunan * ( x ** i )) / math . factorial ( i ) #\u03a3f(0)x^i / i! print ( 'f ke-' , i , '=' , f_turunan , ' {e^3x=' , current , '} {Ea=' , current - old , '} {|\u03f5a|%=' , ( current - old ) / current , '|' , percent (( current - old ) / current ), '}' ) if current - old < error : iteration = False else : f_turunan *= 3 i += 1 f ( 1 ) Pada program tersebut ditetapkan error yaitu 0,001, di program tersebut tersebut terdapat fungsi percent(args) yang nantinya akan digunakan untuk untuk menkonversi nilai menjadi persen pada relative aproksimasi error. def percent ( angka ): return str ( round ( angka * 100 , 4 )) + '%' Dan fungsi utama perhitungan deret MacLaurin terdapat pada fungsi f(args) . fungsi tersebut akan beriterasi dari 0 sampai hasil perhitungan kurang dari batas error yang ditetapkan. hasil perhitungan ditampung pada variabel old untuk nilai aproksimasi sebelumnya, dan variabel current untuk menampung nilai aproksimasi saat ini, dari hasil perhitungan $ f(x) = \\sum \\limits_{i=1}^{n} {f^i(0)x^i \\over i!} $ yang terus dijumlahkan setiap iterasi. def f ( x ): f_turunan = 1 current = i = 0 iteration = True while iteration : old = current current += ( f_turunan * ( x ** i )) / math . factorial ( i ) #\u03a3f(0)x^i / i! if current - old < error : iteration = False else : f_turunan *= 3 i += 1 Saat nilai aproksimasi saat ini dikurangi nilai aproksimasi sebelumnya kurang dari batas error maka iterasi akan dihentikan, sebaliknya program akan terus beriterasi ke suku selanjutnya dan turunan dibawahnya. Hasil program saat di jalankan: f ke- 0 = 1 {e^3x= 1.0 } {Ea= 1.0 } {|\u03f5a|%= 1.0 | 100.0% } f ke- 1 = 3 {e^3x= 4.0 } {Ea= 3.0 } {|\u03f5a|%= 0.75 | 75.0% } f ke- 2 = 9 {e^3x= 8.5 } {Ea= 4.5 } {|\u03f5a|%= 0.5294117647058824 | 52.9412% } f ke- 3 = 27 {e^3x= 13.0 } {Ea= 4.5 } {|\u03f5a|%= 0.34615384615384615 | 34.6154% } f ke- 4 = 81 {e^3x= 16.375 } {Ea= 3.375 } {|\u03f5a|%= 0.20610687022900764 | 20.6107% } f ke- 5 = 243 {e^3x= 18.4 } {Ea= 2.0249999999999986 } {|\u03f5a|%= 0.11005434782608689 | 11.0054% } f ke- 6 = 729 {e^3x= 19.412499999999998 } {Ea= 1.0124999999999993 } {|\u03f5a|%= 0.05215711526078554 | 5.2157% } f ke- 7 = 2187 {e^3x= 19.846428571428568 } {Ea= 0.4339285714285701 } {|\u03f5a|%= 0.02186431527802765 | 2.1864% } f ke- 8 = 6561 {e^3x= 20.009151785714284 } {Ea= 0.162723214285716 } {|\u03f5a|%= 0.008132439397150944 | 0.8132% } f ke- 9 = 19683 {e^3x= 20.063392857142855 } {Ea= 0.05424107142857082 } {|\u03f5a|%= 0.0027034844911218605 | 0.2703% } f ke- 10 = 59049 {e^3x= 20.079665178571425 } {Ea= 0.016272321428569825 } {|\u03f5a|%= 0.0008103880858499218 | 0.081% } f ke- 11 = 177147 {e^3x= 20.08410308441558 } {Ea= 0.004437905844156376 } {|\u03f5a|%= 0.00022096609569784593 | 0.0221% } f ke- 12 = 531441 {e^3x= 20.08521256087662 } {Ea= 0.001109476461039094 } {|\u03f5a|%= 5.523847246706314e-05 | 0.0055% } f ke- 13 = 1594323 {e^3x= 20.08546859390609 } {Ea= 0.0002560330294691937 } {|\u03f5a|%= 1.2747177307422833e-05 | 0.0013% } #nilai sebenarnya dari f(x)=e^3x dengan nilai x=1 yaitu : 20.085536923187664, yang diambil dari module math.e di python Setelah program tersebut bejalan, dan berhenti dengan 13 kali iterasi, program tersebut menghasilkan nilai akhir, yaitu $ e^x = 20.08546859390609 $ dengan aproksimasi error sebesar $ E_a = 0.0002560330294691937 $. dan nilai sebenarnya dari $ e^{3x} $ dengan x=1 adalah 20.085536923187664 ( yang didapat dari module math.e di python ). Setelah kita ketahui nilai sebenarnya, maka kita dapat menghitung True Error dari perkiraan tersebut. {E_t = True Value - Approximate Vallue} \\\\ {E_t = 20.085536923187664 - 20.08546859390609} \\\\ {E_t = 6.832928157507467e-05} {E_t = True Value - Approximate Vallue} \\\\ {E_t = 20.085536923187664 - 20.08546859390609} \\\\ {E_t = 6.832928157507467e-05} Maka di dapatkan True Value = 6.832928157507467e-05. Dapat disimpulkan semakin kecil batasan error yang diberikan, maka selisih antara nilai sebenarnya dengan nilai perkiraan tidak akan jauh atau tingkat akurasi nilai yang dihasilkan semakin bagus. Berikut merupakan hasil visualisasi dalam bentuk tabel, hasil dari perhitungan $ e^{3x} $ dengan x=1. n $ e^{3x} $ $ E_a $ $ | \\epsilon_a | \\% $ 0 1.0 1.0 1.0 | 100% 1 4.0 3.0 0.75 | 75.0% 2 8.5 4.5 0.5294117647058824 | 52.9412% 3 13.0 4.5 0.34615384615384615 | 34.6154% 4 16.375 3.375 0.20610687022900764 | 20.6107% 5 18.4 2.0249999999999986 0.11005434782608689 | 11.0054% 6 19.412499999999998 1.0124999999999993 0.05215711526078554 | 5.2157% 7 19.846428571428568 0.4339285714285701 0.02186431527802765 | 2.1864% 8 20.009151785714284 0.162723214285716 0.008132439397150944 | 0.8132% 9 20.063392857142855 0.05424107142857082 0.0027034844911218605 | 0.2703% 10 20.079665178571425 0.016272321428569825 0.0008103880858499218 | 0.081% 11 20.08410308441558 0.004437905844156376 0.00022096609569784593 | 0.0221% 12 20.08521256087662 0.001109476461039094 5.523847246706314e-05 | 0.0055% 13 20.08546859390609 0.0002560330294691937 1.2747177307422833e-05 | 0.0013% Keterangan : n = iterasi / suku $ e^x $ = nilai yang dicari $ E_a $ = aproksimasi error $ |\\epsilon_a| \\% $ = relatif aproksimasi error MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Tugas 1"},{"location":"komnum/aproxrimasi error/#menghitung-nilai-ex-dengan-pendekatan-deret-maclaurin","text":"","title":"Menghitung Nilai $ e^x $ dengan Pendekatan Deret MacLaurin"},{"location":"komnum/aproxrimasi error/#deret-taylor-dan-deret-maclaurin","text":"Sebuah fungsi $ f(x) $ yang memiliki turunan $ f^1(x) $, $ f^2(x) $, $ f^3(x) $, dan seterusnya yang kontinyu dalam interval $ I $ dan $ a, x I $ maka untuk $ x $ disekitar $ a $ yaitu $ |x \u2013 a| $ < , $ f(x) $ dapat diekspansi kedalam Deret Taylor. Deret Taylor didefinisikan seperti berikut. f(x) = f(a) + {f^1(a) (x-a) \\over 1!} + {f^2(a) (x-a)^2 \\over 2!} + {f^3(a) (x-a)^3 \\over 3!} ... {f^n(a) (x-a)^n \\over n!} f(x) = f(a) + {f^1(a) (x-a) \\over 1!} + {f^2(a) (x-a)^2 \\over 2!} + {f^3(a) (x-a)^3 \\over 3!} ... {f^n(a) (x-a)^n \\over n!} Deret MacLaurin hampir sama dengan dengan Deret Taylor, hanya saja dalam deret maclaurin nilai a=0, sehingga persamaannya adalah seperti berikut. f(x) = f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^3(0)x^3 \\over 3!} ... {f^n(0)x^n \\over n!} f(x) = f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^3(0)x^3 \\over 3!} ... {f^n(0)x^n \\over n!} Deret MacLaurin biasa disebut sebagai deret Taylor baku, kerena deret maclaurin merupakan standar atau dasar yang berlaku dengan a=0. Atau persamaan Deret MacLaurin diatas dapat ditulis seperti berikut f(x) = \\sum \\limits_{i=0}^{n} {f^i(0)x^i \\over i!} f(x) = \\sum \\limits_{i=0}^{n} {f^i(0)x^i \\over i!} Dalam deret MacLaurin yaitu menjumlahkan tiap-tiap suku sampai batas yang ditentukan, sehingga akan menghasilkan nilai yang mendekati nilai sebenarnya. Deret Maclaurin ini dimanfaatkan dalam metode numerik untuk menghitung atau menghampiri nilai fungsi yang susung dihitung secara menual, seperti halnya kita ingin mencari nilai dari $ sin x $, $ cos x $, $ e^x $, $ log x $, atau $ ln(x+1) $. Kita membutuhkan alat khusus, seperti kalkulator atau tabel khusus untuk mencari nilai-nilai dari dari fungsi tersebut. Dalam kasus ini akan dihitung nilai dari $ e^x $ secara menual dengan x=1, serta menerapkannya dalam bahasa pemrograman python untuk menghitung $ e^{3x} $.","title":"Deret Taylor dan Deret MacLaurin"},{"location":"komnum/aproxrimasi error/#perhitung-nilai-ex-dengan-x1","text":"Perhitungan nilai $ e^x $ memiliki fungsi, yaitu $ f(x)=e^x $ dengan turunan berpola seperti berikut. f(x) = e^x \\\\ f^1(x) = e^x \\\\ f^2(x) = e^x \\\\ . \\\\ . \\\\. \\\\ f^n(x) = e^x f(x) = e^x \\\\ f^1(x) = e^x \\\\ f^2(x) = e^x \\\\ . \\\\ . \\\\. \\\\ f^n(x) = e^x Ketika $ e^{3x} $ maka polanya adalah { } f(x) = e^x \\\\ f^1(x) = 3e^{3x} \\\\ f^2(x) = 9e^{3x} \\\\ f^3(x) = 27e^{3x} \\\\ . \\\\ . \\\\ . { } f(x) = e^x \\\\ f^1(x) = 3e^{3x} \\\\ f^2(x) = 9e^{3x} \\\\ f^3(x) = 27e^{3x} \\\\ . \\\\ . \\\\ . yang artinya turunannya adalah koefisien dipangkat turunan ke i. Kemudian kita dapat menghitung dengan deret MacLaurin f(x) \\approx f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^1(0)x^3 \\over 3!} + {f^4(0)x \\over 4!} + {f^5(0)x^5 \\over 5!} ... \\\\ f(1) \\approx 1 + 1 + {1 \\over 2} + {1 \\over 6} + {1 \\over 24} + {1 \\over 120} ... \\\\ f(1) \\approx 2.7166666666666663 f(x) \\approx f(0) + {f^1(0)x \\over 1!} + {f^2(0)x^2 \\over 2!} + {f^1(0)x^3 \\over 3!} + {f^4(0)x \\over 4!} + {f^5(0)x^5 \\over 5!} ... \\\\ f(1) \\approx 1 + 1 + {1 \\over 2} + {1 \\over 6} + {1 \\over 24} + {1 \\over 120} ... \\\\ f(1) \\approx 2.7166666666666663 dengan menghitung menggunakan 5 suku pada deret maclaurin, maka menghasilkan selisih yang cukup jauh dengan nilai sebernarnya. nilai ( True Value ) dari $ e^x $ dengan $ x=1 $ adalah 2.718281828459045 ( yang di dapat dari module math.e di python ), dan nilai perkiraan yang dihasilkan dari perhitungan diatas, yaitu 2.7166666666666663 dengan x=1. Karena kita mengetahui nilai sebenarnya dari $ e^x $, maka kita dapat telah menghitung True Error dari perkiraan tersebut. {E_t = True Value - Approximate Vallue} \\\\ {E_t = 2.7166666666666663 - 2.718281828459045} \\\\ {E_t = 0.0016151617923787498} {E_t = True Value - Approximate Vallue} \\\\ {E_t = 2.7166666666666663 - 2.718281828459045} \\\\ {E_t = 0.0016151617923787498} Maka didapatkan nilai True Error, yaitu 0.0016151617923787498.","title":"Perhitung nilai $ e^x $ dengan $ x=1 $"},{"location":"komnum/aproxrimasi error/#implementasi-deret-maclaurin-pada-python","text":"Pada implementasi deret MacLaurin dengan bahasa pemrograman python, kita akan mencoba untuk menghitung nilai dari $ e^{3x} $ dengan batas error/threshold 0,001. import math error = 0.001 def percent ( angka ): return str ( round ( angka * 100 , 4 )) + '%' def f ( x ): f_turunan = 1 current = i = 0 iteration = True while iteration : old = current current += ( f_turunan * ( x ** i )) / math . factorial ( i ) #\u03a3f(0)x^i / i! print ( 'f ke-' , i , '=' , f_turunan , ' {e^3x=' , current , '} {Ea=' , current - old , '} {|\u03f5a|%=' , ( current - old ) / current , '|' , percent (( current - old ) / current ), '}' ) if current - old < error : iteration = False else : f_turunan *= 3 i += 1 f ( 1 ) Pada program tersebut ditetapkan error yaitu 0,001, di program tersebut tersebut terdapat fungsi percent(args) yang nantinya akan digunakan untuk untuk menkonversi nilai menjadi persen pada relative aproksimasi error. def percent ( angka ): return str ( round ( angka * 100 , 4 )) + '%' Dan fungsi utama perhitungan deret MacLaurin terdapat pada fungsi f(args) . fungsi tersebut akan beriterasi dari 0 sampai hasil perhitungan kurang dari batas error yang ditetapkan. hasil perhitungan ditampung pada variabel old untuk nilai aproksimasi sebelumnya, dan variabel current untuk menampung nilai aproksimasi saat ini, dari hasil perhitungan $ f(x) = \\sum \\limits_{i=1}^{n} {f^i(0)x^i \\over i!} $ yang terus dijumlahkan setiap iterasi. def f ( x ): f_turunan = 1 current = i = 0 iteration = True while iteration : old = current current += ( f_turunan * ( x ** i )) / math . factorial ( i ) #\u03a3f(0)x^i / i! if current - old < error : iteration = False else : f_turunan *= 3 i += 1 Saat nilai aproksimasi saat ini dikurangi nilai aproksimasi sebelumnya kurang dari batas error maka iterasi akan dihentikan, sebaliknya program akan terus beriterasi ke suku selanjutnya dan turunan dibawahnya. Hasil program saat di jalankan: f ke- 0 = 1 {e^3x= 1.0 } {Ea= 1.0 } {|\u03f5a|%= 1.0 | 100.0% } f ke- 1 = 3 {e^3x= 4.0 } {Ea= 3.0 } {|\u03f5a|%= 0.75 | 75.0% } f ke- 2 = 9 {e^3x= 8.5 } {Ea= 4.5 } {|\u03f5a|%= 0.5294117647058824 | 52.9412% } f ke- 3 = 27 {e^3x= 13.0 } {Ea= 4.5 } {|\u03f5a|%= 0.34615384615384615 | 34.6154% } f ke- 4 = 81 {e^3x= 16.375 } {Ea= 3.375 } {|\u03f5a|%= 0.20610687022900764 | 20.6107% } f ke- 5 = 243 {e^3x= 18.4 } {Ea= 2.0249999999999986 } {|\u03f5a|%= 0.11005434782608689 | 11.0054% } f ke- 6 = 729 {e^3x= 19.412499999999998 } {Ea= 1.0124999999999993 } {|\u03f5a|%= 0.05215711526078554 | 5.2157% } f ke- 7 = 2187 {e^3x= 19.846428571428568 } {Ea= 0.4339285714285701 } {|\u03f5a|%= 0.02186431527802765 | 2.1864% } f ke- 8 = 6561 {e^3x= 20.009151785714284 } {Ea= 0.162723214285716 } {|\u03f5a|%= 0.008132439397150944 | 0.8132% } f ke- 9 = 19683 {e^3x= 20.063392857142855 } {Ea= 0.05424107142857082 } {|\u03f5a|%= 0.0027034844911218605 | 0.2703% } f ke- 10 = 59049 {e^3x= 20.079665178571425 } {Ea= 0.016272321428569825 } {|\u03f5a|%= 0.0008103880858499218 | 0.081% } f ke- 11 = 177147 {e^3x= 20.08410308441558 } {Ea= 0.004437905844156376 } {|\u03f5a|%= 0.00022096609569784593 | 0.0221% } f ke- 12 = 531441 {e^3x= 20.08521256087662 } {Ea= 0.001109476461039094 } {|\u03f5a|%= 5.523847246706314e-05 | 0.0055% } f ke- 13 = 1594323 {e^3x= 20.08546859390609 } {Ea= 0.0002560330294691937 } {|\u03f5a|%= 1.2747177307422833e-05 | 0.0013% } #nilai sebenarnya dari f(x)=e^3x dengan nilai x=1 yaitu : 20.085536923187664, yang diambil dari module math.e di python Setelah program tersebut bejalan, dan berhenti dengan 13 kali iterasi, program tersebut menghasilkan nilai akhir, yaitu $ e^x = 20.08546859390609 $ dengan aproksimasi error sebesar $ E_a = 0.0002560330294691937 $. dan nilai sebenarnya dari $ e^{3x} $ dengan x=1 adalah 20.085536923187664 ( yang didapat dari module math.e di python ). Setelah kita ketahui nilai sebenarnya, maka kita dapat menghitung True Error dari perkiraan tersebut. {E_t = True Value - Approximate Vallue} \\\\ {E_t = 20.085536923187664 - 20.08546859390609} \\\\ {E_t = 6.832928157507467e-05} {E_t = True Value - Approximate Vallue} \\\\ {E_t = 20.085536923187664 - 20.08546859390609} \\\\ {E_t = 6.832928157507467e-05} Maka di dapatkan True Value = 6.832928157507467e-05. Dapat disimpulkan semakin kecil batasan error yang diberikan, maka selisih antara nilai sebenarnya dengan nilai perkiraan tidak akan jauh atau tingkat akurasi nilai yang dihasilkan semakin bagus. Berikut merupakan hasil visualisasi dalam bentuk tabel, hasil dari perhitungan $ e^{3x} $ dengan x=1. n $ e^{3x} $ $ E_a $ $ | \\epsilon_a | \\% $ 0 1.0 1.0 1.0 | 100% 1 4.0 3.0 0.75 | 75.0% 2 8.5 4.5 0.5294117647058824 | 52.9412% 3 13.0 4.5 0.34615384615384615 | 34.6154% 4 16.375 3.375 0.20610687022900764 | 20.6107% 5 18.4 2.0249999999999986 0.11005434782608689 | 11.0054% 6 19.412499999999998 1.0124999999999993 0.05215711526078554 | 5.2157% 7 19.846428571428568 0.4339285714285701 0.02186431527802765 | 2.1864% 8 20.009151785714284 0.162723214285716 0.008132439397150944 | 0.8132% 9 20.063392857142855 0.05424107142857082 0.0027034844911218605 | 0.2703% 10 20.079665178571425 0.016272321428569825 0.0008103880858499218 | 0.081% 11 20.08410308441558 0.004437905844156376 0.00022096609569784593 | 0.0221% 12 20.08521256087662 0.001109476461039094 5.523847246706314e-05 | 0.0055% 13 20.08546859390609 0.0002560330294691937 1.2747177307422833e-05 | 0.0013% Keterangan : n = iterasi / suku $ e^x $ = nilai yang dicari $ E_a $ = aproksimasi error $ |\\epsilon_a| \\% $ = relatif aproksimasi error MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Implementasi Deret MacLaurin pada Python"},{"location":"komnum/integrasi metode romberg/","text":"Penyelesaian Integral Menggunakan Metode Romberg \u00b6 Metode Romberg \u00b6 Metode integrasi Romberg didasarkan pada perlusaan ekstrapolasi Richardson untuk memperoleh nilai integrasi yang semakin baik. Sebagai catatan, setiap penerapan ekstrapolasi Richardson akan menaikkan order galat pada hasil solusinya sebesar dua. $$ O(h^{2N}) \\rightarrow O(h^{2N+2}) $$ Misalnya,bila $ I(h) $ dan $ I(2h) $ dihitung dengan kaidah trapesium yang berorde galat $ O(h 2) $, maka ekstrapolasi Richardson menghaslkan kaidah Simpson \u2153 yang berorde $ O(h 4) $. Selanjutnya, bila $ I(h) $ dan $ I(2h) $ dihitung dengan kaidah Simpson \u2153, ekstrapolasi Richardson menghaslkan kaidah Boole yang berorde $ O(h 6) $ Dalam hal ini $$ h = {b -a \\over n} $$ Dan $ A_k $ = Perkiraan nilai integrasi dengan kaidah trapesium dan jumlah pias $ n= 2^k $ Orde galat A_k adalah $ O(h^2) $ Sebagai contoh, interval [a,b] dibagi menjadi 64 buah pias/upselang. $$ n=64= 2^6 \\rightarrow k = (0,1,2,3,4,5,6) $$ k = 0 adalah $ n =2^0 =1$ pias, $h_0 = {b-a \\over 1} \\rightarrow A_0 = h_0/2 [f_0 + f_64] $ k = 1 adalah $ n =2^1 =2$ pias, $h_1 = {b-a \\over 2} \\rightarrow A_0 = h_\u00bd [f_0 + f_32 + f_64] $ dan seterusnya... Arti dari setiap $ A_k $ adalah A_0 A_0 adalah taksiran nilai integrasi $ I = \\int_a^b f(x)dx $ dengan menggunakan kaidah trapesium dengan pembagian daerah integrasi n=2^0=1 n=2^0=1 buah pias. A_1 A_1 adalah taksiran nilai integrasi $ I = \\int_a^b f(x)dx $ dengan menggunakan kaidah trapesium dengan pembagian daerah integrasi n=2^1=2 n=2^1=2 buah pias. A_2 A_2 adalah taksiran nilai integrasi $ I = \\int_a^b f(x)dx $ dengan menggunakan kaidah trapesium dengan pembagian daerah integrasi n=2^2=4 n=2^2=4 buah pias. dan begitu seterusnya. Untuk mendapatkan nilai B_k B_k kita dapat menggunakan persamaan ekstrapolasi Richardson dengan memanfaatkan $ A_0, A_1, ... A_k$ yang didapatkan. $$ B_k = A_k + {A_k-A_{k-1} \\over 2^2 - 1} $$ Dan begitu seterusnya untuk mendapatkan nilai $ C_k, D_k, E_k ... $. Sehingga kita dapat menghasilkan nilai yang dapat ditransformasikan pada bentuk tabel yang dinamakan Tabel Romberg. $ O(h^2) $ $ O(h^4) $ $ O(h^6) $ $ O(h^8) $ $ O(h^10) $ A_0 A_0 A_1 A_1 B_1 B_1 A_2 A_2 B_2 B_2 C_2 C_2 A_3 A_3 B_3 B_3 C_3 C_3 D_3 D_3 A_4 A_4 B_4 B_4 C_4 C_4 D_4 D_4 E_4 E_4 Dan E_4 E_4 merupakan nilai integrasi yang terbaik. Menghitung Integral dengan Metode Romberg \u00b6 Misalkan terdapat integral $$ \\int_0^1 {1 \\over 1+ x} dx $$ $ n =8, \\ a=0, b=1 $ $ x_r = {b - a \\over n} $ $ f_r $ = fungsi integral tersebut. Tabel titik-titik dalam selang interval [a,b] $ r $ x_r x_r f_r f_r 0 0 1,00000 1 0,125 0,88889 2 0,250 0,80000 3 0,375 0,72727 4 0,500 0,66667 5 0,625 0,61538 6 0,750 0,57143 7 0,875 0,53333 8 1,000 0,50000 Selanjutnya dilanjutkan untuk menghitung $ O(h^q) $ A_0 = h_0/2[f_0+f_8] = 1/2 [1 + 0.50000] = 0.75000 \\\\ A_1 = h_1/2[f_0 + 2f_4+f_8] = 0.5 [1 + 2(0.66667) 0.50000] = 0.70833 \\\\ A_3 = h_2/2[f_0 + 2f_2 + 2f_4 + 2f_6 + f_8] = 0.250/2[1 + 2(0.80000) + 2(0.66667) + 2(0.57143) +0.50000] = 0.69702 \\\\ A_4 = h_3/2[f_1 + f_2 + f_3+f_4+f_5+f_6+f_7+f_8] = 0.125/2[1+2.088889 + ... +2(0.53333)+0.50000] = 0.69421 A_0 = h_0/2[f_0+f_8] = 1/2 [1 + 0.50000] = 0.75000 \\\\ A_1 = h_1/2[f_0 + 2f_4+f_8] = 0.5 [1 + 2(0.66667) 0.50000] = 0.70833 \\\\ A_3 = h_2/2[f_0 + 2f_2 + 2f_4 + 2f_6 + f_8] = 0.250/2[1 + 2(0.80000) + 2(0.66667) + 2(0.57143) +0.50000] = 0.69702 \\\\ A_4 = h_3/2[f_1 + f_2 + f_3+f_4+f_5+f_6+f_7+f_8] = 0.125/2[1+2.088889 + ... +2(0.53333)+0.50000] = 0.69421 B_1 = A_1 + {A_1 - A_0 \\over 2^2 -1} = 0.69445 \\\\ B_2 = A_2 + {A_2 - A_1 \\over 2^2 -1} = 0.69325 \\\\ B_3 = A_3 + {A_2 - A_1 \\over 2^2 - 1} = 0.69315 \\\\ C_2 = B_2 + {B_2 - B_1 \\over 2_4 - 1} = 0.69317 \\\\ C_3 = B_3 + {B_3 - B_2 \\over 2_4 - 1} = 0.69314 \\\\ D_3 C_3 + {C_3 - C_3 \\over 2_6 - 1} = 0.69314 B_1 = A_1 + {A_1 - A_0 \\over 2^2 -1} = 0.69445 \\\\ B_2 = A_2 + {A_2 - A_1 \\over 2^2 -1} = 0.69325 \\\\ B_3 = A_3 + {A_2 - A_1 \\over 2^2 - 1} = 0.69315 \\\\ C_2 = B_2 + {B_2 - B_1 \\over 2_4 - 1} = 0.69317 \\\\ C_3 = B_3 + {B_3 - B_2 \\over 2_4 - 1} = 0.69314 \\\\ D_3 C_3 + {C_3 - C_3 \\over 2_6 - 1} = 0.69314 Setelah menyelesaikan proses perhitungan kemudian didapatkan nilai yang ditampung pada tabel Romberg berikut. k O(h^2) O(h^2) O(h^2) O(h^2) O(h^4) O(h^4) O(h^6) O(h^6) 0 0.75000 1 0.70833 0.69445 2 0.69702 0.69325 0.69317 3 0.69412 0.69315 0.69314 0.69314 Jadi hasil dari $ \\int_0^1 {1 \\over 1+ x} dx \\approx 0.69314 $ Implementasi Metode Romberg dengan Python \u00b6 from numpy import zeros def trapezoid_recursive ( f , a , b , n ): h = ( b - a ) / n x = a In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 def romberg ( f , a , b , n ): R = zeros (( n , n )) print ( 'Tabel Romberg' ) for k in range ( 0 , n ): R [ k , 0 ] = trapezoid_recursive ( f , a , b , 2 ** k ) for j in range ( 0 , k ): R [ k , j + 1 ] = ( 4 ** ( j + 1 ) * R [ k , j ] - R [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( R [ k , 0 : k + 1 ]) return R print ( ' 1/' ) print ( ' / 1/(1+x)' ) print ( '/0 \\n ' ) a = 0 b = 1 n = 4 def f ( x ): return 1 / ( 1 + x ) hasil = romberg ( f , a , b , n )[ n - 1 , n - 1 ] print ( 'hasil penyelesaian :' , round ( hasil , 5 )) Pada program diatas terdapat fungsi trapezoid_recursive(f, a, b, n), yang merupakan implementasi dari rumus berikut. $ h = {b-a \\over 2^n} \\\\ R(n,0) = {1 \\over 2}R(n-1,0) + h \\left [ \\sum _{k=1}^{2(n-1)}f(a+(2k-1)h) \\right] $ def trapezoid_recursive ( f , a , b , n ): h = ( b - a ) / n x = a In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 Kemudian terdapat fungsi romberg(f, a, b, n), yang merupakan implementasi dari rumus R(n,m) = {1 \\over 4^m - 1} \\left[ 4^m \\times R(n,m-1)-R(n-,m-1) \\right], n \\le 1, m \\leq 1 R(n,m) = {1 \\over 4^m - 1} \\left[ 4^m \\times R(n,m-1)-R(n-,m-1) \\right], n \\le 1, m \\leq 1 def romberg ( f , a , b , n ): R = zeros (( n , n )) print ( 'Tabel Romberg' ) for k in range ( 0 , n ): R [ k , 0 ] = trapezoid_recursive ( f , a , b , 2 ** k ) for j in range ( 0 , k ): R [ k , j + 1 ] = ( 4 ** ( j + 1 ) * R [ k , j ] - R [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( R [ k , 0 : k + 1 ]) return R Semua nilai dari proses perhitugan program diatas kemudia dimassukan ke dalam larik yang merupakan bantuan dari libarary numpy. Program tersebut di jalankan dengan melakukan proses penyelesaian integrasi pada integral $ \\int_0^1 {1 \\over 1+ x} dx $. Saat program tersebut dijalankan maka menghasilkan output seperti berikut. 1 / / 1 / ( 1 + x ) / 0 Tabel Romberg [ 0.75 ] [ 0.70833333 0.69444444 ] [ 0.69702381 0.69325397 0.6931746 ] [ 0.69412185 0.69315453 0.6931479 0.69314748 ] hasil penyelesaian : 0.69315 Sekian terimakasih :) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 4"},{"location":"komnum/integrasi metode romberg/#penyelesaian-integral-menggunakan-metode-romberg","text":"","title":"Penyelesaian Integral Menggunakan Metode Romberg"},{"location":"komnum/integrasi metode romberg/#metode-romberg","text":"Metode integrasi Romberg didasarkan pada perlusaan ekstrapolasi Richardson untuk memperoleh nilai integrasi yang semakin baik. Sebagai catatan, setiap penerapan ekstrapolasi Richardson akan menaikkan order galat pada hasil solusinya sebesar dua. $$ O(h^{2N}) \\rightarrow O(h^{2N+2}) $$ Misalnya,bila $ I(h) $ dan $ I(2h) $ dihitung dengan kaidah trapesium yang berorde galat $ O(h 2) $, maka ekstrapolasi Richardson menghaslkan kaidah Simpson \u2153 yang berorde $ O(h 4) $. Selanjutnya, bila $ I(h) $ dan $ I(2h) $ dihitung dengan kaidah Simpson \u2153, ekstrapolasi Richardson menghaslkan kaidah Boole yang berorde $ O(h 6) $ Dalam hal ini $$ h = {b -a \\over n} $$ Dan $ A_k $ = Perkiraan nilai integrasi dengan kaidah trapesium dan jumlah pias $ n= 2^k $ Orde galat A_k adalah $ O(h^2) $ Sebagai contoh, interval [a,b] dibagi menjadi 64 buah pias/upselang. $$ n=64= 2^6 \\rightarrow k = (0,1,2,3,4,5,6) $$ k = 0 adalah $ n =2^0 =1$ pias, $h_0 = {b-a \\over 1} \\rightarrow A_0 = h_0/2 [f_0 + f_64] $ k = 1 adalah $ n =2^1 =2$ pias, $h_1 = {b-a \\over 2} \\rightarrow A_0 = h_\u00bd [f_0 + f_32 + f_64] $ dan seterusnya... Arti dari setiap $ A_k $ adalah A_0 A_0 adalah taksiran nilai integrasi $ I = \\int_a^b f(x)dx $ dengan menggunakan kaidah trapesium dengan pembagian daerah integrasi n=2^0=1 n=2^0=1 buah pias. A_1 A_1 adalah taksiran nilai integrasi $ I = \\int_a^b f(x)dx $ dengan menggunakan kaidah trapesium dengan pembagian daerah integrasi n=2^1=2 n=2^1=2 buah pias. A_2 A_2 adalah taksiran nilai integrasi $ I = \\int_a^b f(x)dx $ dengan menggunakan kaidah trapesium dengan pembagian daerah integrasi n=2^2=4 n=2^2=4 buah pias. dan begitu seterusnya. Untuk mendapatkan nilai B_k B_k kita dapat menggunakan persamaan ekstrapolasi Richardson dengan memanfaatkan $ A_0, A_1, ... A_k$ yang didapatkan. $$ B_k = A_k + {A_k-A_{k-1} \\over 2^2 - 1} $$ Dan begitu seterusnya untuk mendapatkan nilai $ C_k, D_k, E_k ... $. Sehingga kita dapat menghasilkan nilai yang dapat ditransformasikan pada bentuk tabel yang dinamakan Tabel Romberg. $ O(h^2) $ $ O(h^4) $ $ O(h^6) $ $ O(h^8) $ $ O(h^10) $ A_0 A_0 A_1 A_1 B_1 B_1 A_2 A_2 B_2 B_2 C_2 C_2 A_3 A_3 B_3 B_3 C_3 C_3 D_3 D_3 A_4 A_4 B_4 B_4 C_4 C_4 D_4 D_4 E_4 E_4 Dan E_4 E_4 merupakan nilai integrasi yang terbaik.","title":"Metode Romberg"},{"location":"komnum/integrasi metode romberg/#menghitung-integral-dengan-metode-romberg","text":"Misalkan terdapat integral $$ \\int_0^1 {1 \\over 1+ x} dx $$ $ n =8, \\ a=0, b=1 $ $ x_r = {b - a \\over n} $ $ f_r $ = fungsi integral tersebut. Tabel titik-titik dalam selang interval [a,b] $ r $ x_r x_r f_r f_r 0 0 1,00000 1 0,125 0,88889 2 0,250 0,80000 3 0,375 0,72727 4 0,500 0,66667 5 0,625 0,61538 6 0,750 0,57143 7 0,875 0,53333 8 1,000 0,50000 Selanjutnya dilanjutkan untuk menghitung $ O(h^q) $ A_0 = h_0/2[f_0+f_8] = 1/2 [1 + 0.50000] = 0.75000 \\\\ A_1 = h_1/2[f_0 + 2f_4+f_8] = 0.5 [1 + 2(0.66667) 0.50000] = 0.70833 \\\\ A_3 = h_2/2[f_0 + 2f_2 + 2f_4 + 2f_6 + f_8] = 0.250/2[1 + 2(0.80000) + 2(0.66667) + 2(0.57143) +0.50000] = 0.69702 \\\\ A_4 = h_3/2[f_1 + f_2 + f_3+f_4+f_5+f_6+f_7+f_8] = 0.125/2[1+2.088889 + ... +2(0.53333)+0.50000] = 0.69421 A_0 = h_0/2[f_0+f_8] = 1/2 [1 + 0.50000] = 0.75000 \\\\ A_1 = h_1/2[f_0 + 2f_4+f_8] = 0.5 [1 + 2(0.66667) 0.50000] = 0.70833 \\\\ A_3 = h_2/2[f_0 + 2f_2 + 2f_4 + 2f_6 + f_8] = 0.250/2[1 + 2(0.80000) + 2(0.66667) + 2(0.57143) +0.50000] = 0.69702 \\\\ A_4 = h_3/2[f_1 + f_2 + f_3+f_4+f_5+f_6+f_7+f_8] = 0.125/2[1+2.088889 + ... +2(0.53333)+0.50000] = 0.69421 B_1 = A_1 + {A_1 - A_0 \\over 2^2 -1} = 0.69445 \\\\ B_2 = A_2 + {A_2 - A_1 \\over 2^2 -1} = 0.69325 \\\\ B_3 = A_3 + {A_2 - A_1 \\over 2^2 - 1} = 0.69315 \\\\ C_2 = B_2 + {B_2 - B_1 \\over 2_4 - 1} = 0.69317 \\\\ C_3 = B_3 + {B_3 - B_2 \\over 2_4 - 1} = 0.69314 \\\\ D_3 C_3 + {C_3 - C_3 \\over 2_6 - 1} = 0.69314 B_1 = A_1 + {A_1 - A_0 \\over 2^2 -1} = 0.69445 \\\\ B_2 = A_2 + {A_2 - A_1 \\over 2^2 -1} = 0.69325 \\\\ B_3 = A_3 + {A_2 - A_1 \\over 2^2 - 1} = 0.69315 \\\\ C_2 = B_2 + {B_2 - B_1 \\over 2_4 - 1} = 0.69317 \\\\ C_3 = B_3 + {B_3 - B_2 \\over 2_4 - 1} = 0.69314 \\\\ D_3 C_3 + {C_3 - C_3 \\over 2_6 - 1} = 0.69314 Setelah menyelesaikan proses perhitungan kemudian didapatkan nilai yang ditampung pada tabel Romberg berikut. k O(h^2) O(h^2) O(h^2) O(h^2) O(h^4) O(h^4) O(h^6) O(h^6) 0 0.75000 1 0.70833 0.69445 2 0.69702 0.69325 0.69317 3 0.69412 0.69315 0.69314 0.69314 Jadi hasil dari $ \\int_0^1 {1 \\over 1+ x} dx \\approx 0.69314 $","title":"Menghitung Integral dengan Metode Romberg"},{"location":"komnum/integrasi metode romberg/#implementasi-metode-romberg-dengan-python","text":"from numpy import zeros def trapezoid_recursive ( f , a , b , n ): h = ( b - a ) / n x = a In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 def romberg ( f , a , b , n ): R = zeros (( n , n )) print ( 'Tabel Romberg' ) for k in range ( 0 , n ): R [ k , 0 ] = trapezoid_recursive ( f , a , b , 2 ** k ) for j in range ( 0 , k ): R [ k , j + 1 ] = ( 4 ** ( j + 1 ) * R [ k , j ] - R [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( R [ k , 0 : k + 1 ]) return R print ( ' 1/' ) print ( ' / 1/(1+x)' ) print ( '/0 \\n ' ) a = 0 b = 1 n = 4 def f ( x ): return 1 / ( 1 + x ) hasil = romberg ( f , a , b , n )[ n - 1 , n - 1 ] print ( 'hasil penyelesaian :' , round ( hasil , 5 )) Pada program diatas terdapat fungsi trapezoid_recursive(f, a, b, n), yang merupakan implementasi dari rumus berikut. $ h = {b-a \\over 2^n} \\\\ R(n,0) = {1 \\over 2}R(n-1,0) + h \\left [ \\sum _{k=1}^{2(n-1)}f(a+(2k-1)h) \\right] $ def trapezoid_recursive ( f , a , b , n ): h = ( b - a ) / n x = a In = f ( a ) for k in range ( 1 , n ): x = x + h In += 2 * f ( x ) return ( In + f ( b )) * h * 0.5 Kemudian terdapat fungsi romberg(f, a, b, n), yang merupakan implementasi dari rumus R(n,m) = {1 \\over 4^m - 1} \\left[ 4^m \\times R(n,m-1)-R(n-,m-1) \\right], n \\le 1, m \\leq 1 R(n,m) = {1 \\over 4^m - 1} \\left[ 4^m \\times R(n,m-1)-R(n-,m-1) \\right], n \\le 1, m \\leq 1 def romberg ( f , a , b , n ): R = zeros (( n , n )) print ( 'Tabel Romberg' ) for k in range ( 0 , n ): R [ k , 0 ] = trapezoid_recursive ( f , a , b , 2 ** k ) for j in range ( 0 , k ): R [ k , j + 1 ] = ( 4 ** ( j + 1 ) * R [ k , j ] - R [ k - 1 , j ]) / ( 4 ** ( j + 1 ) - 1 ) print ( R [ k , 0 : k + 1 ]) return R Semua nilai dari proses perhitugan program diatas kemudia dimassukan ke dalam larik yang merupakan bantuan dari libarary numpy. Program tersebut di jalankan dengan melakukan proses penyelesaian integrasi pada integral $ \\int_0^1 {1 \\over 1+ x} dx $. Saat program tersebut dijalankan maka menghasilkan output seperti berikut. 1 / / 1 / ( 1 + x ) / 0 Tabel Romberg [ 0.75 ] [ 0.70833333 0.69444444 ] [ 0.69702381 0.69325397 0.6931746 ] [ 0.69412185 0.69315453 0.6931479 0.69314748 ] hasil penyelesaian : 0.69315 Sekian terimakasih :) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Implementasi Metode Romberg dengan Python"},{"location":"komnum/metode euler/","text":"Penyelesaian Persamaan Differensial Biasa dengan Metode Euler \u00b6 Metode Euler \u00b6 Dalam metode numerik, metode Euler adalah salah satu prosedur numerik orde pertama untuk menyelesaikan diferensial biasa, dalam artian metode Euler disebut juga metode deret Taylor orde pertama. $$ y(x_0+h)=y(x_0) +h{dy \\over dx}\\Bigr|_{y=y_0}^{x=x_0} + O(h^2) $$ {dy \\over dx}\\Bigr|_{y=y_0}^{x=x_0} = f(x_i, y_i) {dy \\over dx}\\Bigr|_{y=y_0}^{x=x_0} = f(x_i, y_i) x_n = x_0 + h, \\space \\space \\space \\space y_n = y(x_n) x_n = x_0 + h, \\space \\space \\space \\space y_n = y(x_n) PDB orde satu yaitu : y(x) = f(x, y) y(x) = f(x, y) , dengan kondisi awal y_0 = y(x_0) y_0 = y(x_0) Metode Euler : $ y_{i+1} = y_i + h f(x,y) $, dan i yaitu 1,2,3,...n Algoritma Metode Euler \u00b6 Terdapat langkah-langkah harus dikerjaan untuk menyelesaikan persamaan differensial biasa yaitu sebagai berikut: Mulai Tetapkan nilai x_0 x_0 , y_0 y_0 , h h , x x Definisikan sebuah fungsi $ f(x,y) $ Hitung $ n = (x - x_0) / h $ sebagai banyaknya iterasi lakukan perulangan dari i sampai ke n, untuk menghitung x_i = x_0 + i * h x_i = x_0 + i * h , $y_{i+1} = y_i + f(x_i, y_i) $ kemudian tampilkan nilai dari $ y_i $ Berhenti Perhitungan Metode Euler \u00b6 Berikut merupakan proses perhitungan metode Euler untuk PDB $ {dy \\over dx} = 1+x^2, \\space \\space \\space y(1) = -4 $ $$ f(x,y) = 1 + x^2, \\space \\space \\space x_0 = 1, \\space \\space \\space y_0 = -4, \\space \\space \\space h = 0.01 $$ Iterasi 1 : y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -4 + 0.01 \\times 2 \\\\ = -3,98 \\\\ x_1 = x_0 + h \\\\ = 1 + 0.01 \\\\ = 1.01 y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -4 + 0.01 \\times 2 \\\\ = -3,98 \\\\ x_1 = x_0 + h \\\\ = 1 + 0.01 \\\\ = 1.01 Iterasi 2 : y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,98 + 0.01 \\times 2.02 \\\\ = -3,9598 \\\\ x_1 = x_0 + h \\\\ = 1.01 + 0.01 \\\\ = 1.02 y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,98 + 0.01 \\times 2.02 \\\\ = -3,9598 \\\\ x_1 = x_0 + h \\\\ = 1.01 + 0.01 \\\\ = 1.02 Iterasi 3 : y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,9598 + 0.01 \\times 2.0404 \\\\ = -3,9394 \\\\ x_1 = x_0 + h \\\\ = 1.02 + 0.01 \\\\ = 1.03 y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,9598 + 0.01 \\times 2.0404 \\\\ = -3,9394 \\\\ x_1 = x_0 + h \\\\ = 1.02 + 0.01 \\\\ = 1.03 i i x_i x_i y_i y_i 0 1 -4 1 1,01 -3,98 2 1,02 -3,9598 3 1,03 -3,9394 Implementasi Metode Euler dengan Python \u00b6 Dalam kasus ini akan diselesaikan sebuah persamaan differensial biasa dengan bahasa pemrograman Python dengan PDB sebagai berikut : $$ {dy \\over dx} = 1+x^2, \\space \\space \\space \\space \\space \\space y(1) = -4 $$ Dari persamaan tersebut akan dicari nilai aproksimasi dari y(1.01), \\space y(1.02), \\space y(1.03) y(1.01), \\space y(1.02), \\space y(1.03) . Berikut merupakan program dari meode Euler: x0 = 1 y0 = - 4 h = 0.01 x = 1.1 def f ( x , y ): return 1 + x ** 2 def metode_euler ( x0 , y , h , x ): y = y0 i = 0 n = ( x - x0 ) / h print ( str ( '-' * 57 ) + ' \\n | \\t i \\t | \\t xi \\t | \\t yi \\t\\t | \\n ' + str ( '-' * 57 )) while i < n : print ( '| \\t ' , i , ' \\t | \\t ' , round ( x0 , 4 ), ' \\t | \\t ' , round ( y , 4 ), ' \\t |' ) y = y + h * f ( x0 , y ) x0 = x0 + h i += 1 metode_euler ( x0 , y0 , h , x ) Penjelasan program : Seperti halnya algoritma metode Euler diatas, pertama program tersebut menginisialisasi nilai dari $x0, y0, h, $ dan $ x $, dimana x merupakan batas perkiraan. x0 = 1 y0 = - 4 h = 0.01 x = 1.1 Kemudian program tersebut mendefinisikan sebuah fungsi, seperti persamaan differensial diatas, yaitu f(x,y) = 1 + x^2 f(x,y) = 1 + x^2 def f ( x , y ): return 1 + x ** 2 Kemudian program tersebut terdapat fungsi metode_euler(x0,y0,h,x) , dimana dalam fungsi tersebut tedapat variabel y sebagai penampung sementara nilai dari y0, variabel i sebagai iterasi yang dimulai dari 0, dan n yang merupakan variabel yang nantinya berisi nilai untuk batas iterasi, yang didapat dari (x-x_0) / h (x-x_0) / h . Selanjutnya dilakukan iterasi sebanyak n untuk menghitung nilai y, yaitu y = y sebelumnya + h x fungsi PDB. Dan x = x sebelumnya + h. def metode_euler ( x0 , y0 , h , x ): y = y0 i = 0 n = ( x - x0 ) / h print ( str ( '-' * 57 ) + ' \\n | \\t i \\t | \\t xi \\t | \\t yi \\t\\t | \\n ' + str ( '-' * 57 )) while i < n : print ( '| \\t ' , i , ' \\t | \\t ' , round ( x0 , 4 ), ' \\t | \\t ' , round ( y , 4 ), ' \\t |' ) y = y + h * f ( x0 , y ) x0 = x0 + h i += 1 Setelah program tersebut dijalankan maka dihasilkan output seperti berikut: ------------------------------------- | i | xi | yi | ------------------------------------- | 0 | 1 | - 4 | | 1 | 1.01 | - 3.98 | | 2 | 1.02 | - 3.9598 | | 3 | 1.03 | - 3.9394 | | 4 | 1.04 | - 3.9188 | | 5 | 1.05 | - 3.898 | | 6 | 1.06 | - 3.8769 | | 7 | 1.07 | - 3.8557 | | 8 | 1.08 | - 3.8343 | | 9 | 1.09 | - 3.8126 | | 10 | 1.1 | - 3.7907 | Dari program yang dijalankan tersebut maka ditemukan nilai dari $y(1.01) = -3.98 $, y(1.02) = -3.9598 y(1.02) = -3.9598 , dan $y(1.03)= -3.9394 $. Sekian terimakasih. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Tugas 6"},{"location":"komnum/metode euler/#penyelesaian-persamaan-differensial-biasa-dengan-metode-euler","text":"","title":"Penyelesaian Persamaan Differensial Biasa dengan Metode Euler"},{"location":"komnum/metode euler/#metode-euler","text":"Dalam metode numerik, metode Euler adalah salah satu prosedur numerik orde pertama untuk menyelesaikan diferensial biasa, dalam artian metode Euler disebut juga metode deret Taylor orde pertama. $$ y(x_0+h)=y(x_0) +h{dy \\over dx}\\Bigr|_{y=y_0}^{x=x_0} + O(h^2) $$ {dy \\over dx}\\Bigr|_{y=y_0}^{x=x_0} = f(x_i, y_i) {dy \\over dx}\\Bigr|_{y=y_0}^{x=x_0} = f(x_i, y_i) x_n = x_0 + h, \\space \\space \\space \\space y_n = y(x_n) x_n = x_0 + h, \\space \\space \\space \\space y_n = y(x_n) PDB orde satu yaitu : y(x) = f(x, y) y(x) = f(x, y) , dengan kondisi awal y_0 = y(x_0) y_0 = y(x_0) Metode Euler : $ y_{i+1} = y_i + h f(x,y) $, dan i yaitu 1,2,3,...n","title":"Metode Euler"},{"location":"komnum/metode euler/#algoritma-metode-euler","text":"Terdapat langkah-langkah harus dikerjaan untuk menyelesaikan persamaan differensial biasa yaitu sebagai berikut: Mulai Tetapkan nilai x_0 x_0 , y_0 y_0 , h h , x x Definisikan sebuah fungsi $ f(x,y) $ Hitung $ n = (x - x_0) / h $ sebagai banyaknya iterasi lakukan perulangan dari i sampai ke n, untuk menghitung x_i = x_0 + i * h x_i = x_0 + i * h , $y_{i+1} = y_i + f(x_i, y_i) $ kemudian tampilkan nilai dari $ y_i $ Berhenti","title":"Algoritma Metode Euler"},{"location":"komnum/metode euler/#perhitungan-metode-euler","text":"Berikut merupakan proses perhitungan metode Euler untuk PDB $ {dy \\over dx} = 1+x^2, \\space \\space \\space y(1) = -4 $ $$ f(x,y) = 1 + x^2, \\space \\space \\space x_0 = 1, \\space \\space \\space y_0 = -4, \\space \\space \\space h = 0.01 $$ Iterasi 1 : y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -4 + 0.01 \\times 2 \\\\ = -3,98 \\\\ x_1 = x_0 + h \\\\ = 1 + 0.01 \\\\ = 1.01 y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -4 + 0.01 \\times 2 \\\\ = -3,98 \\\\ x_1 = x_0 + h \\\\ = 1 + 0.01 \\\\ = 1.01 Iterasi 2 : y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,98 + 0.01 \\times 2.02 \\\\ = -3,9598 \\\\ x_1 = x_0 + h \\\\ = 1.01 + 0.01 \\\\ = 1.02 y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,98 + 0.01 \\times 2.02 \\\\ = -3,9598 \\\\ x_1 = x_0 + h \\\\ = 1.01 + 0.01 \\\\ = 1.02 Iterasi 3 : y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,9598 + 0.01 \\times 2.0404 \\\\ = -3,9394 \\\\ x_1 = x_0 + h \\\\ = 1.02 + 0.01 \\\\ = 1.03 y_1 = y_0 + h \\times f(x_0, y_0) \\\\ = -3,9598 + 0.01 \\times 2.0404 \\\\ = -3,9394 \\\\ x_1 = x_0 + h \\\\ = 1.02 + 0.01 \\\\ = 1.03 i i x_i x_i y_i y_i 0 1 -4 1 1,01 -3,98 2 1,02 -3,9598 3 1,03 -3,9394","title":"Perhitungan Metode Euler"},{"location":"komnum/metode euler/#implementasi-metode-euler-dengan-python","text":"Dalam kasus ini akan diselesaikan sebuah persamaan differensial biasa dengan bahasa pemrograman Python dengan PDB sebagai berikut : $$ {dy \\over dx} = 1+x^2, \\space \\space \\space \\space \\space \\space y(1) = -4 $$ Dari persamaan tersebut akan dicari nilai aproksimasi dari y(1.01), \\space y(1.02), \\space y(1.03) y(1.01), \\space y(1.02), \\space y(1.03) . Berikut merupakan program dari meode Euler: x0 = 1 y0 = - 4 h = 0.01 x = 1.1 def f ( x , y ): return 1 + x ** 2 def metode_euler ( x0 , y , h , x ): y = y0 i = 0 n = ( x - x0 ) / h print ( str ( '-' * 57 ) + ' \\n | \\t i \\t | \\t xi \\t | \\t yi \\t\\t | \\n ' + str ( '-' * 57 )) while i < n : print ( '| \\t ' , i , ' \\t | \\t ' , round ( x0 , 4 ), ' \\t | \\t ' , round ( y , 4 ), ' \\t |' ) y = y + h * f ( x0 , y ) x0 = x0 + h i += 1 metode_euler ( x0 , y0 , h , x ) Penjelasan program : Seperti halnya algoritma metode Euler diatas, pertama program tersebut menginisialisasi nilai dari $x0, y0, h, $ dan $ x $, dimana x merupakan batas perkiraan. x0 = 1 y0 = - 4 h = 0.01 x = 1.1 Kemudian program tersebut mendefinisikan sebuah fungsi, seperti persamaan differensial diatas, yaitu f(x,y) = 1 + x^2 f(x,y) = 1 + x^2 def f ( x , y ): return 1 + x ** 2 Kemudian program tersebut terdapat fungsi metode_euler(x0,y0,h,x) , dimana dalam fungsi tersebut tedapat variabel y sebagai penampung sementara nilai dari y0, variabel i sebagai iterasi yang dimulai dari 0, dan n yang merupakan variabel yang nantinya berisi nilai untuk batas iterasi, yang didapat dari (x-x_0) / h (x-x_0) / h . Selanjutnya dilakukan iterasi sebanyak n untuk menghitung nilai y, yaitu y = y sebelumnya + h x fungsi PDB. Dan x = x sebelumnya + h. def metode_euler ( x0 , y0 , h , x ): y = y0 i = 0 n = ( x - x0 ) / h print ( str ( '-' * 57 ) + ' \\n | \\t i \\t | \\t xi \\t | \\t yi \\t\\t | \\n ' + str ( '-' * 57 )) while i < n : print ( '| \\t ' , i , ' \\t | \\t ' , round ( x0 , 4 ), ' \\t | \\t ' , round ( y , 4 ), ' \\t |' ) y = y + h * f ( x0 , y ) x0 = x0 + h i += 1 Setelah program tersebut dijalankan maka dihasilkan output seperti berikut: ------------------------------------- | i | xi | yi | ------------------------------------- | 0 | 1 | - 4 | | 1 | 1.01 | - 3.98 | | 2 | 1.02 | - 3.9598 | | 3 | 1.03 | - 3.9394 | | 4 | 1.04 | - 3.9188 | | 5 | 1.05 | - 3.898 | | 6 | 1.06 | - 3.8769 | | 7 | 1.07 | - 3.8557 | | 8 | 1.08 | - 3.8343 | | 9 | 1.09 | - 3.8126 | | 10 | 1.1 | - 3.7907 | Dari program yang dijalankan tersebut maka ditemukan nilai dari $y(1.01) = -3.98 $, y(1.02) = -3.9598 y(1.02) = -3.9598 , dan $y(1.03)= -3.9394 $. Sekian terimakasih. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Implementasi Metode Euler dengan Python"},{"location":"komnum/monte carlo/","text":"Mengestimasi Integral dengan Monte Carlo Method \u00b6 Metode Monte Carlo \u00b6 Monte Carlo merupakan salah satu metode komputasi dengan mengandalkan pengambilan sampel acak secara berulang untuk mendapatkan hasil numerik yang mendekati nilai sebenarnya. Konsep yang mendasari dari metode ini dengan menggunakan nilai acak untuk memecahkan masalah deterministik dalam prinsipnya. Metode Monte Carlo sering digunakan dalam memecahkan masalah matematika dan fisika dan peling berguna ketika sulit atau tidak mungkin untuk menggunakan pendekatan lain. Dalam perkiraan integral dengan dengan motode Monte Carlo untuk memperkirakan area dan volume. Kita gunakan $$ \\int_{0}^1 f(x)dx \\approx {1 \\over n} \\sum_{i=0}^{n} f(x_i) $$ \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} f(x,y,z)dx \\space dy \\space dz \\approx {1 \\over n} \\sum_{i=0}^{n} f(x_i, y_i, z_i) \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} f(x,y,z)dx \\space dy \\space dz \\approx {1 \\over n} \\sum_{i=0}^{n} f(x_i, y_i, z_i) dimana $ x_i $ merupakan urutan angka acak dalam rentang satuan dan $ (x_i, y_i, z_i) $ merupakan urutan acak unit N point cube. Namun pada umumnya $ \\int_{0}^{1} f \\approx$ (ukuran A) $ \\times $ (rata-rata f lebih dari n poin acak dalam A). Tugas Programming \u00b6 Write program to verify numerically that $ \\pi = \\int_{0}^{2} (4 - x^2)^{1/2} $. Use the Monte Carlo method and 2500 random numbers. Use the Monte Carlo method to approximate the integral. $ \\int_{-1}^{1} \\int_{-1}^{1} \\int_{-1}^{1} (x^2 + y^2 + z^2) dx \\space dy \\space dz $ Berikut merupakan program untuk mengestimasi integral menggunakan Monte Carlo method dengan bahasa pemrograman python. Program berikut untuk melakukan pengujian bahwa $ \\pi = \\int_{0}^{2} (4 - x^2)^{1/2} $, dengan angka acak sebanyak 2500. import random as r analitik = 3.14159 count = 2500 x0 = 0 ; x1 = 2 def monte_carlo ( f , count , x0 , x1 ): in_area = 0.0 for i in range ( count ): x_ = r . uniform ( x0 , x1 ); if x0 <= x_ <= x1 : in_area += f ( x_ ) area_box = ( x1 - x0 ) return (( in_area / count ) * area_box ) def f ( x ): return (( 4 - x ** 2 ) ** ( 1 / 2 )) hasil = monte_carlo ( f , count , x0 , x1 ) print ( 'N =' , count ) print ( 'Hasil aproksimasi:' , hasil ) print ( 'Relative true error:' , ( analitik - hasil ) / analitik , '|' , str ( round ((( analitik - hasil ) / analitik ) * 100 , 2 )) + '%' ) Dalam program tersebut, terdapat library random untuk mendapatkan nilai acak. program tersebut terdapat variabel analitik yang berisi nilai perhitungan secara analitik/nilai sebernarnya. Kemudian terdapat variabel count sebagai N (banyaknya perulangan), variabel x0 untuk batas bawah dan x1 untuk batas atas integral. Didalam fungsi monte_carlo(param1,param2..) tersebut, terdapat paramater f untuk fungsi integral yang akan digunakan, count, x0, dan x1. Kemudian dalam fungsi tersebut terdapat variable in_area , dimana variabel tersebut akan digunakan untuk menampung nilai acak yang dihasilkan pada area dari persamaan tersebut. kemudian terdapat looping yang akan mengulang sebanyak N. Dalam perulangan tersebut, tedapat variabel x_ untuk nilai acak dalam rentang x0 dan x1. Kemudan akan akan dilakukan pengecekan kembali apabila nilai dari x_ dalam rentang x0 dan x1, maka akan menjumlah terus menerus nilai dari perhitungan f(x) , dimana ilustrasinya nilai tersebut merupakan titik dalam bentang persamaan yang didefinisikan. Setelah melakukan looping sebanyak N, maka akan mencari nilai dari area_box, area_box merupakan area dalam interval x0 dan x1 yang berbentuk kotak. Kemudian fungsi tersebut akan mengembalikan nilai dari perhitungan rata-rata dari in_area dikali dengan area_box. Berikut merupakan ilustrasi dari program tersebut dengan persamaan $ f(x) = (4 - x^2)^{1/2} $. Berikut merupakan hasil running program, dalam running program tersebut digunakan N sebanyak 2500 untuk running pertama dengan hasil perkiraan, yaitu 3.1169340168166424 dengan relative true error sebesar 0,78%. Kemudian dalam running kedua digunakan N sebanya 5000 dengan hasil perkiraan 3.1415150955638516. Nilai perkiraan yang dihasilkan akan dinamis setiap program dijalankan, terkadang error lebih besar atau lebih kecil. Namun, dengan memberikan nilai N yang lebih besar error yang dihasilkan dominan lebih kecil. N = 2500 Hasil aproksimasi : 3.1169340168166424 Relative true error : 0.007848249829977014 | 0.78 % N = 5000 Hasil aproksimasi : 3.1415150955638516 Relative true error : 2.3842842684222457e-05 | 0.0 % Selanjutnya program kedua untuk mengaproksimasi nilai integral $ \\int_{-1}^{1} \\int_{-1}^{1} \\int_{-1}^{1} (x^2 + y^2 + z^2) dx \\space dy \\space dz $ import random as r analitik = 8.0 count = 1000 x0 = - 1 ; x1 = 1 ; y0 = - 1 ; y1 = 1 ; z0 = - 1 ; z1 = 1 def monte_carlo ( f , count , x0 , x1 , y0 , y1 , z0 , z1 ): in_area = 0.0 for i in range ( count ): x_ = r . uniform ( x0 , x1 ); y_ = r . uniform ( x0 , x1 ); z_ = r . uniform ( z0 , z1 ); if ( x0 <= x_ <= x1 ) and ( y0 <= y_ <= y1 ) and ( z0 <= z_ <= z1 ): in_area += f ( x_ , y_ , z_ ) area = ( x1 - x0 ) * ( y1 - y0 ) * ( z1 - z0 ) return ( in_area / count ) * area def f ( x , y , z ): return ( x ** 2 + y ** 2 + z ** 2 ) hasil = monte_carlo ( f , count , x0 , x1 , y0 , y1 , z0 , z1 ) print ( 'N =' , count ) print ( 'Hasil aproksimasi:' , hasil ) print ( 'Relative true error:' , ( analitik - hasil ) / analitik , '|' , str ( round ((( analitik - hasil ) / analitik ) * 100 , 2 )) + '%' ) Dalam program tersebut hampir sama dengan program pertama, hanya saja dalam program tersebut untuk mengaproksimasi integral lapis 3. Kemudian x0 dan x1 untuk integral pertama, y0 dan y1 untuk integral kedua, dan z0 dan z1 untuk integral ketiga. Proses perhitungan dan penyelesaian yang dilakukan hampir sama dengan program pertama, yaitu dengan menggunakan angka random dalam rentang yang ditentukan, dan titiknya juga berada pada dimensi yang berbeda. Berikut merupakan hasil running program, dalam running program pertama digunakan N sebanyak 1000, maka dihasilkan nilai aproksimasi, yaitu 7.918782014912802 dengan relative true error sebesar 1.02%. Kemudian dalam running yang kedua menggunakan N sebanyak 5000, maka hasil aproksimasi yaitu 7.974525782192673 dengan relative true error sebesar 0.32%. Nilai perkiraan yang dihasilkan akan dinamis setiap program dijalankan, terkadang error lebih besar atau lebih kecil. Namun, dengan memberikan nilai N yang lebih besar error yang dihasilkan dominan lebih kecil. N = 1000 Hasil aproksimasi : 7.918782014912802 Relative true error : 0.010152248135899766 | 1.02 % N = 5000 Hasil aproksimasi : 7.974525782192673 Relative true error : 0.0031842772259158547 | 0.32 % Berikut merupakan proses analitiks dari integral tersebut, dimana hasil analitiksnya yaitu 8. $$ I = \\int_{-1}^{1} \\int_{-1}^{1} \\int_{-1}^{1} (x^2 + y^2 + z^3) dx \\space dy \\space dz \\\\ I = \\int_{-1}^{1} \\int_{-1}^{1} \\left[ {1 \\over 3}x^3 + y^2 + z^2 \\right]_{-1}^{1} dy \\space dz \\\\ I = \\int_{-1}^{1} \\int_{-1}^{1} \\left[ {1 \\over 3}(1)x^3 + (1)y^2 + (1)z^2 \\right] - \\left[ {1 \\over 3}(-1)x^3 + (-1)y^2 + (-1)z^2 \\right] \\\\ I = \\int_{-1}^{1} \\int_{-1}^{1} \\left({2 \\over 3} + 2y^2 + 2z^2 \\right) dy \\space dz \\\\ I = \\int_{-1}^{1} \\left[ {2 \\over 3}y + {2 \\over 3}y^3 + 2z^2y \\right]_{-1}^{1} dz \\\\ I = \\int_{-1}^{1} \\left[ {2 \\over 3}(1) + {2 \\over 3}(1)^3 + 2z^2(1) \\right] - \\left[ {2 \\over 3}(-1) + {2 \\over 3}(-1)^3 + 2z^2(-1) \\right] \\\\ I = \\int_{-1}^{1} \\left({8 \\over 3} + 4z \\right) dz \\\\ I = \\left[{8 \\over 3}z + {4 \\over 3}z^3 \\right]_{-1}^{1} \\\\ =\\left[ {8 \\over 3}(1) + {4 \\over 3}(1)^3 \\right] - \\left[ {8 \\over 3}(-1) + {4 \\over 3}(-1)^3 \\right] \\\\ = {24 \\over 3} \\\\ = 8 $$ Sekian Terimakasih. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Tugas 7"},{"location":"komnum/monte carlo/#mengestimasi-integral-dengan-monte-carlo-method","text":"","title":"Mengestimasi Integral dengan Monte Carlo Method"},{"location":"komnum/monte carlo/#metode-monte-carlo","text":"Monte Carlo merupakan salah satu metode komputasi dengan mengandalkan pengambilan sampel acak secara berulang untuk mendapatkan hasil numerik yang mendekati nilai sebenarnya. Konsep yang mendasari dari metode ini dengan menggunakan nilai acak untuk memecahkan masalah deterministik dalam prinsipnya. Metode Monte Carlo sering digunakan dalam memecahkan masalah matematika dan fisika dan peling berguna ketika sulit atau tidak mungkin untuk menggunakan pendekatan lain. Dalam perkiraan integral dengan dengan motode Monte Carlo untuk memperkirakan area dan volume. Kita gunakan $$ \\int_{0}^1 f(x)dx \\approx {1 \\over n} \\sum_{i=0}^{n} f(x_i) $$ \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} f(x,y,z)dx \\space dy \\space dz \\approx {1 \\over n} \\sum_{i=0}^{n} f(x_i, y_i, z_i) \\int_{0}^{1} \\int_{0}^{1} \\int_{0}^{1} f(x,y,z)dx \\space dy \\space dz \\approx {1 \\over n} \\sum_{i=0}^{n} f(x_i, y_i, z_i) dimana $ x_i $ merupakan urutan angka acak dalam rentang satuan dan $ (x_i, y_i, z_i) $ merupakan urutan acak unit N point cube. Namun pada umumnya $ \\int_{0}^{1} f \\approx$ (ukuran A) $ \\times $ (rata-rata f lebih dari n poin acak dalam A).","title":"Metode Monte Carlo"},{"location":"komnum/monte carlo/#tugas-programming","text":"Write program to verify numerically that $ \\pi = \\int_{0}^{2} (4 - x^2)^{1/2} $. Use the Monte Carlo method and 2500 random numbers. Use the Monte Carlo method to approximate the integral. $ \\int_{-1}^{1} \\int_{-1}^{1} \\int_{-1}^{1} (x^2 + y^2 + z^2) dx \\space dy \\space dz $ Berikut merupakan program untuk mengestimasi integral menggunakan Monte Carlo method dengan bahasa pemrograman python. Program berikut untuk melakukan pengujian bahwa $ \\pi = \\int_{0}^{2} (4 - x^2)^{1/2} $, dengan angka acak sebanyak 2500. import random as r analitik = 3.14159 count = 2500 x0 = 0 ; x1 = 2 def monte_carlo ( f , count , x0 , x1 ): in_area = 0.0 for i in range ( count ): x_ = r . uniform ( x0 , x1 ); if x0 <= x_ <= x1 : in_area += f ( x_ ) area_box = ( x1 - x0 ) return (( in_area / count ) * area_box ) def f ( x ): return (( 4 - x ** 2 ) ** ( 1 / 2 )) hasil = monte_carlo ( f , count , x0 , x1 ) print ( 'N =' , count ) print ( 'Hasil aproksimasi:' , hasil ) print ( 'Relative true error:' , ( analitik - hasil ) / analitik , '|' , str ( round ((( analitik - hasil ) / analitik ) * 100 , 2 )) + '%' ) Dalam program tersebut, terdapat library random untuk mendapatkan nilai acak. program tersebut terdapat variabel analitik yang berisi nilai perhitungan secara analitik/nilai sebernarnya. Kemudian terdapat variabel count sebagai N (banyaknya perulangan), variabel x0 untuk batas bawah dan x1 untuk batas atas integral. Didalam fungsi monte_carlo(param1,param2..) tersebut, terdapat paramater f untuk fungsi integral yang akan digunakan, count, x0, dan x1. Kemudian dalam fungsi tersebut terdapat variable in_area , dimana variabel tersebut akan digunakan untuk menampung nilai acak yang dihasilkan pada area dari persamaan tersebut. kemudian terdapat looping yang akan mengulang sebanyak N. Dalam perulangan tersebut, tedapat variabel x_ untuk nilai acak dalam rentang x0 dan x1. Kemudan akan akan dilakukan pengecekan kembali apabila nilai dari x_ dalam rentang x0 dan x1, maka akan menjumlah terus menerus nilai dari perhitungan f(x) , dimana ilustrasinya nilai tersebut merupakan titik dalam bentang persamaan yang didefinisikan. Setelah melakukan looping sebanyak N, maka akan mencari nilai dari area_box, area_box merupakan area dalam interval x0 dan x1 yang berbentuk kotak. Kemudian fungsi tersebut akan mengembalikan nilai dari perhitungan rata-rata dari in_area dikali dengan area_box. Berikut merupakan ilustrasi dari program tersebut dengan persamaan $ f(x) = (4 - x^2)^{1/2} $. Berikut merupakan hasil running program, dalam running program tersebut digunakan N sebanyak 2500 untuk running pertama dengan hasil perkiraan, yaitu 3.1169340168166424 dengan relative true error sebesar 0,78%. Kemudian dalam running kedua digunakan N sebanya 5000 dengan hasil perkiraan 3.1415150955638516. Nilai perkiraan yang dihasilkan akan dinamis setiap program dijalankan, terkadang error lebih besar atau lebih kecil. Namun, dengan memberikan nilai N yang lebih besar error yang dihasilkan dominan lebih kecil. N = 2500 Hasil aproksimasi : 3.1169340168166424 Relative true error : 0.007848249829977014 | 0.78 % N = 5000 Hasil aproksimasi : 3.1415150955638516 Relative true error : 2.3842842684222457e-05 | 0.0 % Selanjutnya program kedua untuk mengaproksimasi nilai integral $ \\int_{-1}^{1} \\int_{-1}^{1} \\int_{-1}^{1} (x^2 + y^2 + z^2) dx \\space dy \\space dz $ import random as r analitik = 8.0 count = 1000 x0 = - 1 ; x1 = 1 ; y0 = - 1 ; y1 = 1 ; z0 = - 1 ; z1 = 1 def monte_carlo ( f , count , x0 , x1 , y0 , y1 , z0 , z1 ): in_area = 0.0 for i in range ( count ): x_ = r . uniform ( x0 , x1 ); y_ = r . uniform ( x0 , x1 ); z_ = r . uniform ( z0 , z1 ); if ( x0 <= x_ <= x1 ) and ( y0 <= y_ <= y1 ) and ( z0 <= z_ <= z1 ): in_area += f ( x_ , y_ , z_ ) area = ( x1 - x0 ) * ( y1 - y0 ) * ( z1 - z0 ) return ( in_area / count ) * area def f ( x , y , z ): return ( x ** 2 + y ** 2 + z ** 2 ) hasil = monte_carlo ( f , count , x0 , x1 , y0 , y1 , z0 , z1 ) print ( 'N =' , count ) print ( 'Hasil aproksimasi:' , hasil ) print ( 'Relative true error:' , ( analitik - hasil ) / analitik , '|' , str ( round ((( analitik - hasil ) / analitik ) * 100 , 2 )) + '%' ) Dalam program tersebut hampir sama dengan program pertama, hanya saja dalam program tersebut untuk mengaproksimasi integral lapis 3. Kemudian x0 dan x1 untuk integral pertama, y0 dan y1 untuk integral kedua, dan z0 dan z1 untuk integral ketiga. Proses perhitungan dan penyelesaian yang dilakukan hampir sama dengan program pertama, yaitu dengan menggunakan angka random dalam rentang yang ditentukan, dan titiknya juga berada pada dimensi yang berbeda. Berikut merupakan hasil running program, dalam running program pertama digunakan N sebanyak 1000, maka dihasilkan nilai aproksimasi, yaitu 7.918782014912802 dengan relative true error sebesar 1.02%. Kemudian dalam running yang kedua menggunakan N sebanyak 5000, maka hasil aproksimasi yaitu 7.974525782192673 dengan relative true error sebesar 0.32%. Nilai perkiraan yang dihasilkan akan dinamis setiap program dijalankan, terkadang error lebih besar atau lebih kecil. Namun, dengan memberikan nilai N yang lebih besar error yang dihasilkan dominan lebih kecil. N = 1000 Hasil aproksimasi : 7.918782014912802 Relative true error : 0.010152248135899766 | 1.02 % N = 5000 Hasil aproksimasi : 7.974525782192673 Relative true error : 0.0031842772259158547 | 0.32 % Berikut merupakan proses analitiks dari integral tersebut, dimana hasil analitiksnya yaitu 8. $$ I = \\int_{-1}^{1} \\int_{-1}^{1} \\int_{-1}^{1} (x^2 + y^2 + z^3) dx \\space dy \\space dz \\\\ I = \\int_{-1}^{1} \\int_{-1}^{1} \\left[ {1 \\over 3}x^3 + y^2 + z^2 \\right]_{-1}^{1} dy \\space dz \\\\ I = \\int_{-1}^{1} \\int_{-1}^{1} \\left[ {1 \\over 3}(1)x^3 + (1)y^2 + (1)z^2 \\right] - \\left[ {1 \\over 3}(-1)x^3 + (-1)y^2 + (-1)z^2 \\right] \\\\ I = \\int_{-1}^{1} \\int_{-1}^{1} \\left({2 \\over 3} + 2y^2 + 2z^2 \\right) dy \\space dz \\\\ I = \\int_{-1}^{1} \\left[ {2 \\over 3}y + {2 \\over 3}y^3 + 2z^2y \\right]_{-1}^{1} dz \\\\ I = \\int_{-1}^{1} \\left[ {2 \\over 3}(1) + {2 \\over 3}(1)^3 + 2z^2(1) \\right] - \\left[ {2 \\over 3}(-1) + {2 \\over 3}(-1)^3 + 2z^2(-1) \\right] \\\\ I = \\int_{-1}^{1} \\left({8 \\over 3} + 4z \\right) dz \\\\ I = \\left[{8 \\over 3}z + {4 \\over 3}z^3 \\right]_{-1}^{1} \\\\ =\\left[ {8 \\over 3}(1) + {4 \\over 3}(1)^3 \\right] - \\left[ {8 \\over 3}(-1) + {4 \\over 3}(-1)^3 \\right] \\\\ = {24 \\over 3} \\\\ = 8 $$ Sekian Terimakasih. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Tugas Programming"},{"location":"komnum/sistem persamaan linear/","text":"Penerapan Metode Gauss, Gauss Jacobi, Gauss Seidel untuk Sistem Persamaan Linear \u00b6 Eliminasi Gauss \u00b6 Eliminasi gauss merupakan salah satu metode eliminasi yang ditemukan oleh Carl Friedrich Gauss yang merupakan seorang matematikawan yang berkebangsaan Jerman. Metede gauss dimanfaatkan untuk memecahkan sebuah sistem persamaan linear dengan merepresentasikan persamaan kedalam bentuk matriks. Dalam eliminasi gauss terdiri dari 2 langkah yaitu, Eliminasi Maju ( forward elimination ), dan Subsitusi Mundur ( backword subsitution ). Eliminasi maju merupakan langkah untuk menjadikan matriks $ A $ ke dalam bentuk matriks segitigas atas ( upper tringular form ), menggunakan Operasi baris elementer (OBE). Dan Subsitutusi mundur merupakan langkah untuk penyelesaian variabel akhir. Sebuah sistem persamaan linear memiliki sebuah representasi, yaitu $ Ax = B $. dimana $ A $ merupakan reperesentasi koefisien dalam bentuk matriks, $ x $ sebagai representasi dari variabel dalam bentuk matriks, dan $ B $ sebagai representasi nilai dari persamaan dalam bentuk matriks. -3x + y = -3 \\\\ x + y = 5 -3x + y = -3 \\\\ x + y = 5 Ax = B \\\\ \\begin{bmatrix} -3 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\begin{bmatrix} -3 \\\\ 5 \\end{bmatrix} Ax = B \\\\ \\begin{bmatrix} -3 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\begin{bmatrix} -3 \\\\ 5 \\end{bmatrix} Contoh Eliminasi dengan Gauss \u00b6 Ketika terdapat Sistem Persamaan Linear seperti berikut 6x_1 - 2x_2 + 2x_3 + 4x_4 = 16 \\\\ 12x_1 -8x_2 + 6x_3 + 10x_4 = 16 \\\\ 3x_1 -12x_2 + 9x_3 + 3x_4 = -19 \\\\ -6x_1 + 6x_2 + x_3 -18x_4 = -34 6x_1 - 2x_2 + 2x_3 + 4x_4 = 16 \\\\ 12x_1 -8x_2 + 6x_3 + 10x_4 = 16 \\\\ 3x_1 -12x_2 + 9x_3 + 3x_4 = -19 \\\\ -6x_1 + 6x_2 + x_3 -18x_4 = -34 Kita dapat mengeliminasi dengan metode Gauss dengan membentuk menjadi persamaan $ Ax = B $ \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 12 & -8 & 6 & 10 \\\\ 3 & -13 & 9 & 3 \\\\ -6 & 4 & 1 & -18 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ 26 \\\\ -19 \\\\ -34 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 12 & -8 & 6 & 10 \\\\ 3 & -13 & 9 & 3 \\\\ -6 & 4 & 1 & -18 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ 26 \\\\ -19 \\\\ -34 \\end{bmatrix} Selanjutnya kita dapat melakukan Eliminasi Maju ( forward elimination ) untuk menjadi matriks A menjadi matriks segitiga atas, dengan menjadi nilai dibawah diagonal matriks A menjadi 0. Untuk melakukan eliminasi maju kita dapat menggunakan rumus berikut. Forward Elimination \u00b6 x_k = {\\left.\\begin{aligned} A_{ij} \\leftarrow A_{ij} - \\left ( {A_{ik} \\over A_{kk}} \\right)A_{kj} &; (k \\leq j \\leq n)\\\\ b_i \\leftarrow b_i - \\left ( {A_{ik} \\over A_{kk}} \\right)b_{k} &; \\end{aligned}\\right\\rbrace {k+1 \\leq i \\leq n}} x_k = {\\left.\\begin{aligned} A_{ij} \\leftarrow A_{ij} - \\left ( {A_{ik} \\over A_{kk}} \\right)A_{kj} &; (k \\leq j \\leq n)\\\\ b_i \\leftarrow b_i - \\left ( {A_{ik} \\over A_{kk}} \\right)b_{k} &; \\end{aligned}\\right\\rbrace {k+1 \\leq i \\leq n}} Untuk menjadikan 0 pada matriks A baris 2 kolom ke 1 menggunakan rumus diatas, yaitu seperti berikut. A_{21} = A_{21} - \\left ({A_{21} \\over A_{11}}\\right ) \\times A_{11} \\\\ A_{21} = 12- \\left ({12 \\over 6} \\right) \\times 6 A_{21} = A_{21} - \\left ({A_{21} \\over A_{11}}\\right ) \\times A_{11} \\\\ A_{21} = 12- \\left ({12 \\over 6} \\right) \\times 6 Eliminasi dilakukan sampai $ x_{n-1} $. Kemudian akan mengasilkan seperti berikut. \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & -12 & 8 & 1\\\\ 0 & 2& 3& -14 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -27\\\\ -18 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & -12 & 8 & 1\\\\ 0 & 2& 3& -14 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -27\\\\ -18 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0& 4& -13 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -21 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0& 4& -13 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -21 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0 & 0 & -3 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -3 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0 & 0 & -3 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -3 \\end{bmatrix} Setelah menyelesaikan eliminasi sampai $ x_{n-1} $, kita dapat melakukan Subsitusi Mundur ( Backward Subsitution ) untuk mencari nilai $ x_1 $ sampai $ x_n $ . Backward Subsitution \u00b6 x_n = {b_n \\over a_{nn}} \\\\ x_i = {b_i \\sum _{j=i+1}^{n} a_{ij}x_j \\over a_{ii} } x_n = {b_n \\over a_{nn}} \\\\ x_i = {b_i \\sum _{j=i+1}^{n} a_{ij}x_j \\over a_{ii} } Menggunakan rumus diatas kita dapat mencari nilai x tersebut. x_4 = {-3 \\over -3} = 1 \\\\ x_3 = {-9 + 5 \\over 2} = -2 \\\\ x_2 = {-6-2(-2)-2(1) \\over -4} = 1 \\\\ x_1 = {16 + 2(1) - 2(-2) + 4(1) \\over 6} = 3 x_4 = {-3 \\over -3} = 1 \\\\ x_3 = {-9 + 5 \\over 2} = -2 \\\\ x_2 = {-6-2(-2)-2(1) \\over -4} = 1 \\\\ x_1 = {16 + 2(1) - 2(-2) + 4(1) \\over 6} = 3 Setelah melakukan subsitusi mundur, maka ditemukan nilai x_1 = 3 x_1 = 3 , x_2 = 1 x_2 = 1 , x_3 = -2 x_3 = -2 , $x_4 = 1 $ Implementasi Eliminasi Gauss dengan Python \u00b6 from numpy import linalg ##A = [[6, -2, 2, 4], [12, -8, 6, 10], [3, -13, 9, 3], [-6, 4, 1, -18]] ##B = [16, 26, -19, -34] A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) X = [ 0 ] * len ( A ) def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B ) print () if linalg . det ( A ) != 0 : #forward elimination for k in range ( len ( A ) - 1 ): for i in range ( k + 1 , len ( A )): factor = A [ i ][ k ] / A [ k ][ k ] for j in range ( k , len ( A )): A [ i ][ j ] = A [ i ][ j ] - factor * A [ k ][ j ] B [ i ] = B [ i ] - factor * B [ k ] #backward elimination X [ len ( A ) - 1 ] = B [ len ( A ) - 1 ] / A [ len ( A ) - 1 ][ len ( A [ 0 ]) - 1 ] for i in range ( len ( A ) - 1 , - 1 , - 1 ): isum = B [ i ] for j in range ( i + 1 , len ( A )): isum = isum - A [ i ][ j ] * X [ j ] X [ i ] = isum / A [ i ][ i ] else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) print ( 'hasil eliminasi gauss' ) print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B , ' \\n ' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) Dari program diatas, kita menginisialisasikan matriks A, B, dan X sebagai list, dan membuat inputan yang memita banyaknya persamaan. Dari inputan tersebut kemudian dilakukan looping untuk memberikan inputan yang meminta koefisien dari tiap persamaan dan hasil dari persamaan yang kemudian akan di masukkan pada list masing -masing, sehingga list akan menjadi list 2 dimensi untuk list A. A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) X = [ 0 ] * len ( A ) Kemudian terdapat fungsi tampil_matriks(matriks), yang nantinya digunakan untuk menampilkan list 2 dimensi, agar tampil seperti matrik yang memiliki baris dan kolom def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () Dan pada program tersebut terdapat kondisi untuk mengecek determinan matriks A. Ketika determinan matriks A tidak sama dengan 0 maka program akan melakukan proses forward elimination dan backward subsitution. untuk mencari determinan menggunakan fungsi det() yang merupakan fungsi bawaan modul numpy. if linalg . det ( A ) != 0 : #forward elimination #bacward subsition else : else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) Selanjutnya pada program tersebut terdapat metode forward elimination, yang melakukan komputasi dari rumus berikut $ A_{ij} \\leftarrow A_{ij} - \\left ( {A_{ik} \\over A_{kk}} \\right)A_{kj}, b_i \\leftarrow b_i - \\left ( {A_{ik} \\over A_{kk}} \\right)b_{k} $ #forward elimination for k in range ( len ( A ) - 1 ): for i in range ( k + 1 , len ( A )): factor = A [ i ][ k ] / A [ k ][ k ] for j in range ( k , len ( A )): A [ i ][ j ] = A [ i ][ j ] - factor * A [ k ][ j ] B [ i ] = B [ i ] - factor * B [ k ] Dan bacward subsitution yang merupakan komputasi dari rumus $ x_n = {b_n \\over a_{nn}} \\\\ x_i = {b_i \\sum _{j=i+1}^{n} a_{ij}x_j \\over a_{ii} } $ #backward elimination X [ len ( A ) - 1 ] = B [ len ( A ) - 1 ] / A [ len ( A ) - 1 ][ len ( A [ 0 ]) - 1 ] for i in range ( len ( A ) - 1 , - 1 , - 1 ): isum = B [ i ] for j in range ( i + 1 , len ( A )): isum = isum - A [ i ][ j ] * X [ j ] X [ i ] = isum / A [ i ][ i ] Saat program tersebut dijalankan maka menghasilkan output seperti berikut. Matrix A | 6 - 2 2 4 | | 12 - 8 6 10 | | 3 - 13 9 3 | | - 6 4 1 - 18 | Matrix B [ 16 , 26 , - 19 , - 34 ] hasil eliminasi gauss Matrix A | 6 - 2 2 4 | | 0.0 - 4.0 2.0 2.0 | | 0.0 0.0 2.0 - 5.0 | | 0.0 0.0 0.0 - 3.0 | Matrix B [ 16 , - 6.0 , - 9.0 , - 3.0 ] X1 : 3.0 X2 : 1.0 X3 : - 2.0 X4 : 1.0 Metode Gauss Jacobi \u00b6 Gauss Jacobi adalah metode iteratif untuk menyelesaikan sebuah sistem persamaan linear dengan ukuran n x n dengan memperbaharui nilai x yang diperoleh setiap iterasi. nilai x merupakan variabel dari persamaan yang akan dicari nilainya. Iterasi pada metode jacobi secara umum di definisikan sebagai berikut. \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} Perhitungan Gauss Jacobi \u00b6 Tedapat sistem persamaan linear seperti berikut, kita akan mencari nilai x dengan metode Gauss Jacobi. 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 Pertama kita dapat menginisialisasi nilai x, dalam contoh ini semua nilai x di inisialisasi dengan 0. x_1=0, x_2=0, x_3=0, x_4=0 x_1=0, x_2=0, x_3=0, x_4=0 Kemudian kita dapat mulai menghitung nilai x menggunakan rumus iteratif metode gauss jacobi diatas yang dimulai dari iterasi pertama, atau k=1 x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0 + 0 -3(0) + 25 \\over 11} = 2,2727 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0) + 0 + 0 +11 \\over 10} = -1,1000 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(0) + 0 + 15 \\over -8} = 1.8750 x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0 + 0 -3(0) + 25 \\over 11} = 2,2727 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0) + 0 + 0 +11 \\over 10} = -1,1000 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(0) + 0 + 15 \\over -8} = 1.8750 Dengan menghitung menggunakan metode Gauss Jacobi satu iterasi, maka ditmukan nilai x_1=0,6000 x_1=0,6000 , x_2=2,2727 x_2=2,2727 , x_3=1,1000 x_3=1,1000 , x_4=1.9570 x_4=1.9570 . Implementasi Gauss Jacobi dengan Python \u00b6 import math import copy from numpy import linalg ##A = [[10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8]] ##B = [6, 25, -11, 15] A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) error = float ( input ( 'masukkan batas error : ' )) max_iterasi = int ( input ( 'masukkan maksimal iterasi : ' )) X = [ 0 ] * len ( A ) X_temp = copy . copy ( X ) def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B ) print () e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X_temp [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_temp [ i ]) ** 2 X_temp = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) Pada program tersebut di deklarasikan error ( treshold ) dan maksimal program untuk melakukan iterasi. Dalam kasus ini akan di selesaikan sistem persamaan berikut untuk menguji program metode gauss jacobi. error = 0.001 max_iterasi = 100 A = [[ 10 , - 1 , 2 , 0 ], [ - 1 , 11 , - 1 , 3 ], [ 2 , - 1 , 10 , - 1 ], [ 0 , 3 , - 1 , 8 ]] B = [ 6 , 25 , - 11 , 15 ] X = [ 0 ] * len ( A ) X_temp = copy . copy ( X ) Letak komputasi utama terdapat pada listing berikut. Program tersebut akan berhenti saat nilai dari $ \\sqrt { \\sum _{i=1}^{n} (x_i - x_{i-1})^2 } $ kurang dari error yang ditetapkan, atau iterasi telah mencapai batas yang ditentukan e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : ##Gauss Jacobi Method print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_temp [ i ]) ** 2 X_temp = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) Dalam listing berikut melakukan komputasi dari motode Gauss Jacobi, yaitu $ \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} $ for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X_temp [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) Setelah program tersebut dijalankan maka menghasilkan output seperti berikut. Matrix A | 10 - 1 2 0 | | - 1 11 - 1 3 | | 2 - 1 10 - 1 | | 0 3 - 1 8 | Matrix B [ 6 , 25 , - 11 , 15 ] k - 1 X = [ 0.6 , 2.2727 , - 1.1 , 1.875 ] k - 2 X = [ 1.0473 , 1.7159 , - 0.8052 , 0.8852 ] k - 3 X = [ 0.9326 , 2.0533 , - 1.0494 , 1.1309 ] k - 4 X = [ 1.0152 , 1.9537 , - 0.9681 , 0.9738 ] k - 5 X = [ 0.989 , 2.0114 , - 1.0103 , 1.0213 ] k - 6 X = [ 1.0032 , 1.9923 , - 0.9945 , 0.9944 ] k - 7 X = [ 0.9981 , 2.0023 , - 1.002 , 1.0036 ] k - 8 X = [ 1.0006 , 1.9987 , - 0.999 , 0.9989 ] k - 9 X = [ 0.9997 , 2.0004 , - 1.0004 , 1.0006 ] k - 10 X = [ 1.0001 , 1.9998 , - 0.9998 , 0.9998 ] k - 11 X = [ 0.9999 , 2.0001 , - 1.0001 , 1.0001 ] X1 : 0.9999 X2 : 2.0001 X3 : - 1.0001 X4 : 1.0001 Metode Gauss Seidel \u00b6 Gauss Seidel adalah salah satu metode iteratif yang menggunakan proses iterasi hingga diperoleh nilai-nilai yang berubah-ubah dan akhirnya relatif konstan. Metode iterasi Gauss-Seidel dikembangkan dari gagasan metode iterasi pada solusi persamaan tak linier. Secara umum iterasi gauss seidel di definisikan sebagai berikut. \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} Perhitungan Gauss Seidel \u00b6 Sebagai contoh, terdapat sistem persamaan linear berikut. Kita dapat mencari nilai x tersebut menggunakan metode Gauss Seidel. 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 Pertama kita dapat menginisialisasi nilai x, dalam contoh ini semua nilai x di inisialisasi dengan 0. x_1=0, x_2=0, x_3=0, x_4=0 x_1=0, x_2=0, x_3=0, x_4=0 Sama halnya dengan perhitungan metode Gauss Jacobi, hanya saja dalam perhitungan metode Gauss Seidel menggunakan nilai x terbaru setiap mencari nilai x berikutnya. x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0,6 + 0 -3(0) + 25 \\over 11} = 2,3273 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0,6) + 2,3273 + 0 +11 \\over 10} = -0,9873 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(2,3273) + (-0,9873) + 15 \\over -8} = 0,8789 x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0,6 + 0 -3(0) + 25 \\over 11} = 2,3273 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0,6) + 2,3273 + 0 +11 \\over 10} = -0,9873 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(2,3273) + (-0,9873) + 15 \\over -8} = 0,8789 Setelah menyelesaikan satu iterasi dari metode Gauss Seidel maka ditemukan nilai x_1=0,6000 x_1=0,6000 , x_2=2,3273 x_2=2,3273 , x_3=-0,9873 x_3=-0,9873 , dan x_4=0,8789 x_4=0,8789 . Implementasi Gauss Seidel dengan Python \u00b6 import math import copy from numpy import linalg ##A = [[10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8]] ##B = [6, 25, -11, 15] A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) error = float ( input ( 'masukkan batas error : ' )) max_iterasi = int ( input ( 'masukkan maksimal iterasi : ' )) X = [ 0 ] * len ( A ) X_prev = copy . copy ( X ) def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B ) print () e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_prev [ i ]) ** 2 X_prev = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) Berikut merupakan listing utama dari program tersebut. listing tersebut merupakan tempat komputasi dari metode Gauss Seidel. Program tersebut akan berjalan dan berhenti dalam kondisi seperti program Gauss Jacobi, hanya saja perbedaannya terletak pada proses perhitungan. e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : ### Gauss Seidel Method print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_prev [ i ]) ** 2 X_prev = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) Dalam listing berikut melakukan komputasi dari motode Gauss Seidel, yaitu $ \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} $ for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) Setelah program tersebut dijalankan maka menghasilkan output seperti berikut. Matrix A | 10 - 1 2 0 | | - 1 11 - 1 3 | | 2 - 1 10 - 1 | | 0 3 - 1 8 | Matrix B [ 6 , 25 , - 11 , 15 ] k - 1 X = [ 0.6 , 2.3273 , - 0.9873 , 0.8788 ] k - 2 X = [ 1.0302 , 2.037 , - 1.0145 , 0.9843 ] k - 3 X = [ 1.0066 , 2.0036 , - 1.0025 , 0.9983 ] k - 4 X = [ 1.0009 , 2.0003 , - 1.0003 , 0.9998 ] k - 5 X = [ 1.0001 , 2.0 , - 1.0 , 1.0 ] X1 : 1.0001 X2 : 2.0 X3 : - 1.0 X4 : 1.0 Sekian terimakasih :) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 3"},{"location":"komnum/sistem persamaan linear/#penerapan-metode-gauss-gauss-jacobi-gauss-seidel-untuk-sistem-persamaan-linear","text":"","title":"Penerapan Metode Gauss, Gauss Jacobi, Gauss Seidel untuk Sistem Persamaan Linear"},{"location":"komnum/sistem persamaan linear/#eliminasi-gauss","text":"Eliminasi gauss merupakan salah satu metode eliminasi yang ditemukan oleh Carl Friedrich Gauss yang merupakan seorang matematikawan yang berkebangsaan Jerman. Metede gauss dimanfaatkan untuk memecahkan sebuah sistem persamaan linear dengan merepresentasikan persamaan kedalam bentuk matriks. Dalam eliminasi gauss terdiri dari 2 langkah yaitu, Eliminasi Maju ( forward elimination ), dan Subsitusi Mundur ( backword subsitution ). Eliminasi maju merupakan langkah untuk menjadikan matriks $ A $ ke dalam bentuk matriks segitigas atas ( upper tringular form ), menggunakan Operasi baris elementer (OBE). Dan Subsitutusi mundur merupakan langkah untuk penyelesaian variabel akhir. Sebuah sistem persamaan linear memiliki sebuah representasi, yaitu $ Ax = B $. dimana $ A $ merupakan reperesentasi koefisien dalam bentuk matriks, $ x $ sebagai representasi dari variabel dalam bentuk matriks, dan $ B $ sebagai representasi nilai dari persamaan dalam bentuk matriks. -3x + y = -3 \\\\ x + y = 5 -3x + y = -3 \\\\ x + y = 5 Ax = B \\\\ \\begin{bmatrix} -3 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\begin{bmatrix} -3 \\\\ 5 \\end{bmatrix} Ax = B \\\\ \\begin{bmatrix} -3 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\begin{bmatrix} -3 \\\\ 5 \\end{bmatrix}","title":"Eliminasi Gauss"},{"location":"komnum/sistem persamaan linear/#contoh-eliminasi-dengan-gauss","text":"Ketika terdapat Sistem Persamaan Linear seperti berikut 6x_1 - 2x_2 + 2x_3 + 4x_4 = 16 \\\\ 12x_1 -8x_2 + 6x_3 + 10x_4 = 16 \\\\ 3x_1 -12x_2 + 9x_3 + 3x_4 = -19 \\\\ -6x_1 + 6x_2 + x_3 -18x_4 = -34 6x_1 - 2x_2 + 2x_3 + 4x_4 = 16 \\\\ 12x_1 -8x_2 + 6x_3 + 10x_4 = 16 \\\\ 3x_1 -12x_2 + 9x_3 + 3x_4 = -19 \\\\ -6x_1 + 6x_2 + x_3 -18x_4 = -34 Kita dapat mengeliminasi dengan metode Gauss dengan membentuk menjadi persamaan $ Ax = B $ \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 12 & -8 & 6 & 10 \\\\ 3 & -13 & 9 & 3 \\\\ -6 & 4 & 1 & -18 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ 26 \\\\ -19 \\\\ -34 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 12 & -8 & 6 & 10 \\\\ 3 & -13 & 9 & 3 \\\\ -6 & 4 & 1 & -18 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ 26 \\\\ -19 \\\\ -34 \\end{bmatrix} Selanjutnya kita dapat melakukan Eliminasi Maju ( forward elimination ) untuk menjadi matriks A menjadi matriks segitiga atas, dengan menjadi nilai dibawah diagonal matriks A menjadi 0. Untuk melakukan eliminasi maju kita dapat menggunakan rumus berikut.","title":"Contoh Eliminasi dengan Gauss"},{"location":"komnum/sistem persamaan linear/#forward-elimination","text":"x_k = {\\left.\\begin{aligned} A_{ij} \\leftarrow A_{ij} - \\left ( {A_{ik} \\over A_{kk}} \\right)A_{kj} &; (k \\leq j \\leq n)\\\\ b_i \\leftarrow b_i - \\left ( {A_{ik} \\over A_{kk}} \\right)b_{k} &; \\end{aligned}\\right\\rbrace {k+1 \\leq i \\leq n}} x_k = {\\left.\\begin{aligned} A_{ij} \\leftarrow A_{ij} - \\left ( {A_{ik} \\over A_{kk}} \\right)A_{kj} &; (k \\leq j \\leq n)\\\\ b_i \\leftarrow b_i - \\left ( {A_{ik} \\over A_{kk}} \\right)b_{k} &; \\end{aligned}\\right\\rbrace {k+1 \\leq i \\leq n}} Untuk menjadikan 0 pada matriks A baris 2 kolom ke 1 menggunakan rumus diatas, yaitu seperti berikut. A_{21} = A_{21} - \\left ({A_{21} \\over A_{11}}\\right ) \\times A_{11} \\\\ A_{21} = 12- \\left ({12 \\over 6} \\right) \\times 6 A_{21} = A_{21} - \\left ({A_{21} \\over A_{11}}\\right ) \\times A_{11} \\\\ A_{21} = 12- \\left ({12 \\over 6} \\right) \\times 6 Eliminasi dilakukan sampai $ x_{n-1} $. Kemudian akan mengasilkan seperti berikut. \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & -12 & 8 & 1\\\\ 0 & 2& 3& -14 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -27\\\\ -18 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & -12 & 8 & 1\\\\ 0 & 2& 3& -14 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -27\\\\ -18 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0& 4& -13 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -21 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0& 4& -13 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -21 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0 & 0 & -3 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -3 \\end{bmatrix} \\begin{bmatrix} 6 & -2 & 2 & 4 \\\\ 0 & -4 & 2 & 2 \\\\ 0 & 0 & 2 & -5\\\\ 0 & 0 & 0 & -3 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4 \\end{bmatrix} \\begin{bmatrix} 16 \\\\ -6 \\\\ -9\\\\ -3 \\end{bmatrix} Setelah menyelesaikan eliminasi sampai $ x_{n-1} $, kita dapat melakukan Subsitusi Mundur ( Backward Subsitution ) untuk mencari nilai $ x_1 $ sampai $ x_n $ .","title":"Forward Elimination"},{"location":"komnum/sistem persamaan linear/#backward-subsitution","text":"x_n = {b_n \\over a_{nn}} \\\\ x_i = {b_i \\sum _{j=i+1}^{n} a_{ij}x_j \\over a_{ii} } x_n = {b_n \\over a_{nn}} \\\\ x_i = {b_i \\sum _{j=i+1}^{n} a_{ij}x_j \\over a_{ii} } Menggunakan rumus diatas kita dapat mencari nilai x tersebut. x_4 = {-3 \\over -3} = 1 \\\\ x_3 = {-9 + 5 \\over 2} = -2 \\\\ x_2 = {-6-2(-2)-2(1) \\over -4} = 1 \\\\ x_1 = {16 + 2(1) - 2(-2) + 4(1) \\over 6} = 3 x_4 = {-3 \\over -3} = 1 \\\\ x_3 = {-9 + 5 \\over 2} = -2 \\\\ x_2 = {-6-2(-2)-2(1) \\over -4} = 1 \\\\ x_1 = {16 + 2(1) - 2(-2) + 4(1) \\over 6} = 3 Setelah melakukan subsitusi mundur, maka ditemukan nilai x_1 = 3 x_1 = 3 , x_2 = 1 x_2 = 1 , x_3 = -2 x_3 = -2 , $x_4 = 1 $","title":"Backward Subsitution"},{"location":"komnum/sistem persamaan linear/#implementasi-eliminasi-gauss-dengan-python","text":"from numpy import linalg ##A = [[6, -2, 2, 4], [12, -8, 6, 10], [3, -13, 9, 3], [-6, 4, 1, -18]] ##B = [16, 26, -19, -34] A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) X = [ 0 ] * len ( A ) def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B ) print () if linalg . det ( A ) != 0 : #forward elimination for k in range ( len ( A ) - 1 ): for i in range ( k + 1 , len ( A )): factor = A [ i ][ k ] / A [ k ][ k ] for j in range ( k , len ( A )): A [ i ][ j ] = A [ i ][ j ] - factor * A [ k ][ j ] B [ i ] = B [ i ] - factor * B [ k ] #backward elimination X [ len ( A ) - 1 ] = B [ len ( A ) - 1 ] / A [ len ( A ) - 1 ][ len ( A [ 0 ]) - 1 ] for i in range ( len ( A ) - 1 , - 1 , - 1 ): isum = B [ i ] for j in range ( i + 1 , len ( A )): isum = isum - A [ i ][ j ] * X [ j ] X [ i ] = isum / A [ i ][ i ] else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) print ( 'hasil eliminasi gauss' ) print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B , ' \\n ' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) Dari program diatas, kita menginisialisasikan matriks A, B, dan X sebagai list, dan membuat inputan yang memita banyaknya persamaan. Dari inputan tersebut kemudian dilakukan looping untuk memberikan inputan yang meminta koefisien dari tiap persamaan dan hasil dari persamaan yang kemudian akan di masukkan pada list masing -masing, sehingga list akan menjadi list 2 dimensi untuk list A. A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) X = [ 0 ] * len ( A ) Kemudian terdapat fungsi tampil_matriks(matriks), yang nantinya digunakan untuk menampilkan list 2 dimensi, agar tampil seperti matrik yang memiliki baris dan kolom def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () Dan pada program tersebut terdapat kondisi untuk mengecek determinan matriks A. Ketika determinan matriks A tidak sama dengan 0 maka program akan melakukan proses forward elimination dan backward subsitution. untuk mencari determinan menggunakan fungsi det() yang merupakan fungsi bawaan modul numpy. if linalg . det ( A ) != 0 : #forward elimination #bacward subsition else : else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) Selanjutnya pada program tersebut terdapat metode forward elimination, yang melakukan komputasi dari rumus berikut $ A_{ij} \\leftarrow A_{ij} - \\left ( {A_{ik} \\over A_{kk}} \\right)A_{kj}, b_i \\leftarrow b_i - \\left ( {A_{ik} \\over A_{kk}} \\right)b_{k} $ #forward elimination for k in range ( len ( A ) - 1 ): for i in range ( k + 1 , len ( A )): factor = A [ i ][ k ] / A [ k ][ k ] for j in range ( k , len ( A )): A [ i ][ j ] = A [ i ][ j ] - factor * A [ k ][ j ] B [ i ] = B [ i ] - factor * B [ k ] Dan bacward subsitution yang merupakan komputasi dari rumus $ x_n = {b_n \\over a_{nn}} \\\\ x_i = {b_i \\sum _{j=i+1}^{n} a_{ij}x_j \\over a_{ii} } $ #backward elimination X [ len ( A ) - 1 ] = B [ len ( A ) - 1 ] / A [ len ( A ) - 1 ][ len ( A [ 0 ]) - 1 ] for i in range ( len ( A ) - 1 , - 1 , - 1 ): isum = B [ i ] for j in range ( i + 1 , len ( A )): isum = isum - A [ i ][ j ] * X [ j ] X [ i ] = isum / A [ i ][ i ] Saat program tersebut dijalankan maka menghasilkan output seperti berikut. Matrix A | 6 - 2 2 4 | | 12 - 8 6 10 | | 3 - 13 9 3 | | - 6 4 1 - 18 | Matrix B [ 16 , 26 , - 19 , - 34 ] hasil eliminasi gauss Matrix A | 6 - 2 2 4 | | 0.0 - 4.0 2.0 2.0 | | 0.0 0.0 2.0 - 5.0 | | 0.0 0.0 0.0 - 3.0 | Matrix B [ 16 , - 6.0 , - 9.0 , - 3.0 ] X1 : 3.0 X2 : 1.0 X3 : - 2.0 X4 : 1.0","title":"Implementasi Eliminasi Gauss dengan Python"},{"location":"komnum/sistem persamaan linear/#metode-gauss-jacobi","text":"Gauss Jacobi adalah metode iteratif untuk menyelesaikan sebuah sistem persamaan linear dengan ukuran n x n dengan memperbaharui nilai x yang diperoleh setiap iterasi. nilai x merupakan variabel dari persamaan yang akan dicari nilainya. Iterasi pada metode jacobi secara umum di definisikan sebagai berikut. \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}}","title":"Metode Gauss Jacobi"},{"location":"komnum/sistem persamaan linear/#perhitungan-gauss-jacobi","text":"Tedapat sistem persamaan linear seperti berikut, kita akan mencari nilai x dengan metode Gauss Jacobi. 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 Pertama kita dapat menginisialisasi nilai x, dalam contoh ini semua nilai x di inisialisasi dengan 0. x_1=0, x_2=0, x_3=0, x_4=0 x_1=0, x_2=0, x_3=0, x_4=0 Kemudian kita dapat mulai menghitung nilai x menggunakan rumus iteratif metode gauss jacobi diatas yang dimulai dari iterasi pertama, atau k=1 x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0 + 0 -3(0) + 25 \\over 11} = 2,2727 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0) + 0 + 0 +11 \\over 10} = -1,1000 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(0) + 0 + 15 \\over -8} = 1.8750 x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0 + 0 -3(0) + 25 \\over 11} = 2,2727 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0) + 0 + 0 +11 \\over 10} = -1,1000 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(0) + 0 + 15 \\over -8} = 1.8750 Dengan menghitung menggunakan metode Gauss Jacobi satu iterasi, maka ditmukan nilai x_1=0,6000 x_1=0,6000 , x_2=2,2727 x_2=2,2727 , x_3=1,1000 x_3=1,1000 , x_4=1.9570 x_4=1.9570 .","title":"Perhitungan Gauss Jacobi"},{"location":"komnum/sistem persamaan linear/#implementasi-gauss-jacobi-dengan-python","text":"import math import copy from numpy import linalg ##A = [[10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8]] ##B = [6, 25, -11, 15] A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) error = float ( input ( 'masukkan batas error : ' )) max_iterasi = int ( input ( 'masukkan maksimal iterasi : ' )) X = [ 0 ] * len ( A ) X_temp = copy . copy ( X ) def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B ) print () e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X_temp [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_temp [ i ]) ** 2 X_temp = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) Pada program tersebut di deklarasikan error ( treshold ) dan maksimal program untuk melakukan iterasi. Dalam kasus ini akan di selesaikan sistem persamaan berikut untuk menguji program metode gauss jacobi. error = 0.001 max_iterasi = 100 A = [[ 10 , - 1 , 2 , 0 ], [ - 1 , 11 , - 1 , 3 ], [ 2 , - 1 , 10 , - 1 ], [ 0 , 3 , - 1 , 8 ]] B = [ 6 , 25 , - 11 , 15 ] X = [ 0 ] * len ( A ) X_temp = copy . copy ( X ) Letak komputasi utama terdapat pada listing berikut. Program tersebut akan berhenti saat nilai dari $ \\sqrt { \\sum _{i=1}^{n} (x_i - x_{i-1})^2 } $ kurang dari error yang ditetapkan, atau iterasi telah mencapai batas yang ditentukan e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : ##Gauss Jacobi Method print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_temp [ i ]) ** 2 X_temp = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) Dalam listing berikut melakukan komputasi dari motode Gauss Jacobi, yaitu $ \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} $ for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X_temp [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) Setelah program tersebut dijalankan maka menghasilkan output seperti berikut. Matrix A | 10 - 1 2 0 | | - 1 11 - 1 3 | | 2 - 1 10 - 1 | | 0 3 - 1 8 | Matrix B [ 6 , 25 , - 11 , 15 ] k - 1 X = [ 0.6 , 2.2727 , - 1.1 , 1.875 ] k - 2 X = [ 1.0473 , 1.7159 , - 0.8052 , 0.8852 ] k - 3 X = [ 0.9326 , 2.0533 , - 1.0494 , 1.1309 ] k - 4 X = [ 1.0152 , 1.9537 , - 0.9681 , 0.9738 ] k - 5 X = [ 0.989 , 2.0114 , - 1.0103 , 1.0213 ] k - 6 X = [ 1.0032 , 1.9923 , - 0.9945 , 0.9944 ] k - 7 X = [ 0.9981 , 2.0023 , - 1.002 , 1.0036 ] k - 8 X = [ 1.0006 , 1.9987 , - 0.999 , 0.9989 ] k - 9 X = [ 0.9997 , 2.0004 , - 1.0004 , 1.0006 ] k - 10 X = [ 1.0001 , 1.9998 , - 0.9998 , 0.9998 ] k - 11 X = [ 0.9999 , 2.0001 , - 1.0001 , 1.0001 ] X1 : 0.9999 X2 : 2.0001 X3 : - 1.0001 X4 : 1.0001","title":"Implementasi Gauss Jacobi dengan Python"},{"location":"komnum/sistem persamaan linear/#metode-gauss-seidel","text":"Gauss Seidel adalah salah satu metode iteratif yang menggunakan proses iterasi hingga diperoleh nilai-nilai yang berubah-ubah dan akhirnya relatif konstan. Metode iterasi Gauss-Seidel dikembangkan dari gagasan metode iterasi pada solusi persamaan tak linier. Secara umum iterasi gauss seidel di definisikan sebagai berikut. \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}}","title":"Metode Gauss Seidel"},{"location":"komnum/sistem persamaan linear/#perhitungan-gauss-seidel","text":"Sebagai contoh, terdapat sistem persamaan linear berikut. Kita dapat mencari nilai x tersebut menggunakan metode Gauss Seidel. 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 10x_1 - x_2 + 2x_3 = 6 \\\\ -x_1 + 11x_2 - x_3 + 3x_3 = 25 \\\\ 2x_1 - x_2 + 10x_3 - x_4 = -11 \\\\ 3x_2 - x_3 + 8x_4 = 15 Pertama kita dapat menginisialisasi nilai x, dalam contoh ini semua nilai x di inisialisasi dengan 0. x_1=0, x_2=0, x_3=0, x_4=0 x_1=0, x_2=0, x_3=0, x_4=0 Sama halnya dengan perhitungan metode Gauss Jacobi, hanya saja dalam perhitungan metode Gauss Seidel menggunakan nilai x terbaru setiap mencari nilai x berikutnya. x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0,6 + 0 -3(0) + 25 \\over 11} = 2,3273 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0,6) + 2,3273 + 0 +11 \\over 10} = -0,9873 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(2,3273) + (-0,9873) + 15 \\over -8} = 0,8789 x_1 = {x_2 + 2x_3 + 6 \\over 10}, x_1= {0 + 2(0) + 6 \\over 10} = 0,6000 \\\\ x_2 = {-x_1 + x_3 - 3x_4 + 25 \\over 11}, x_2 = {0,6 + 0 -3(0) + 25 \\over 11} = 2,3273 \\\\ x_3 = {-2x_1 + x_2 + x_4 + 11 \\over 10}, x_3 = {-2(0,6) + 2,3273 + 0 +11 \\over 10} = -0,9873 \\\\ x_4 = {-3x_2 + x_3 +15 \\over -8}, x_4 = {-3(2,3273) + (-0,9873) + 15 \\over -8} = 0,8789 Setelah menyelesaikan satu iterasi dari metode Gauss Seidel maka ditemukan nilai x_1=0,6000 x_1=0,6000 , x_2=2,3273 x_2=2,3273 , x_3=-0,9873 x_3=-0,9873 , dan x_4=0,8789 x_4=0,8789 .","title":"Perhitungan Gauss Seidel"},{"location":"komnum/sistem persamaan linear/#implementasi-gauss-seidel-dengan-python","text":"import math import copy from numpy import linalg ##A = [[10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8]] ##B = [6, 25, -11, 15] A = [] B = [] n_spl = int ( input ( 'masukkan banyak persamaan : ' )) for i in range ( n_spl ): temp = [] for j in range ( n_var ): temp . append ( float ( input ( 'masukkan koefisien SPL ke- %i x %i : ' % (( i + 1 ),( j + 1 ))))) A . append ( temp ) B . append ( float ( input ( 'masukkan hasil SPL ke- %i : ' % ( i + 1 )))) error = float ( input ( 'masukkan batas error : ' )) max_iterasi = int ( input ( 'masukkan maksimal iterasi : ' )) X = [ 0 ] * len ( A ) X_prev = copy . copy ( X ) def tampil_matrix ( matrix ): for i in range ( len ( matrix )): print ( '|' , end = ' ' ) for j in range ( len ( matrix [ 0 ])): print ( matrix [ i ][ j ], end = ' ' ) print ( '|' ) print () print ( 'Matrix A' ) tampil_matrix ( A ) print ( 'Matrix B' , B ) print () e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_prev [ i ]) ** 2 X_prev = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) Berikut merupakan listing utama dari program tersebut. listing tersebut merupakan tempat komputasi dari metode Gauss Seidel. Program tersebut akan berjalan dan berhenti dalam kondisi seperti program Gauss Jacobi, hanya saja perbedaannya terletak pada proses perhitungan. e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : ### Gauss Seidel Method print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_prev [ i ]) ** 2 X_prev = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) Dalam listing berikut melakukan komputasi dari motode Gauss Seidel, yaitu $ \\sum _ { i = 1 }^{n} x _i ^{(k+1)} = {b_i - \\sum _{j=1}^{i-1} a_{ij}x_{j}^{(k+1)} \\sum _{j=i+1}^{n} a_{ij}x_{j}^{(k)} \\over a_{ii}} $ for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) Setelah program tersebut dijalankan maka menghasilkan output seperti berikut. Matrix A | 10 - 1 2 0 | | - 1 11 - 1 3 | | 2 - 1 10 - 1 | | 0 3 - 1 8 | Matrix B [ 6 , 25 , - 11 , 15 ] k - 1 X = [ 0.6 , 2.3273 , - 0.9873 , 0.8788 ] k - 2 X = [ 1.0302 , 2.037 , - 1.0145 , 0.9843 ] k - 3 X = [ 1.0066 , 2.0036 , - 1.0025 , 0.9983 ] k - 4 X = [ 1.0009 , 2.0003 , - 1.0003 , 0.9998 ] k - 5 X = [ 1.0001 , 2.0 , - 1.0 , 1.0 ] X1 : 1.0001 X2 : 2.0 X3 : - 1.0 X4 : 1.0 Sekian terimakasih :) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Implementasi Gauss Seidel dengan Python"},{"location":"komnum/tabel richardson/","text":"Mencari Estimasi Turunan Fungsi dengan Ekstrapolasi Richardson \u00b6 Ekstrapolasi Richardson \u00b6 Ekstrapolasi Richardson adalah salah satu teknik menggabungkan dua nilai perkiraan yang dihitung diperoleh dengan menggunakan rumus yang sama atau metode dengan dua ukuran langkah yang berbeda, untuk mendapatkan metode orde tinggi yang menyediakan lebih dekat perkiraan jumlah tertentu. Dalam extrapolasi Richardson ditetapkan $ f(x) $ dan $ x $ tertentu. \\varnothing(h) = {f(x+h) - f(x-h) \\over 2h} \\\\ \\varnothing(h) = f'(x) - a_2h^2 - a_4h_4 - a_6h_6- ... \\\\ \\varnothing(h) = f'(x) - a_2{h \\over 2}^2 - a_4{h \\over 2}^4 - a_6{h \\over 2}^6 -...\\\\ \\varnothing(h)-4 \\varnothing(h/2) = 3f'(x)-{3 \\over 4} a_4h^4 - {15 \\over 16} a_6h^6 -... \\\\ => f'(x)={4\\over3} \\varnothing(h/2) - {1\\over3}\\varnothing(h)+O(h^4) \\varnothing(h) = {f(x+h) - f(x-h) \\over 2h} \\\\ \\varnothing(h) = f'(x) - a_2h^2 - a_4h_4 - a_6h_6- ... \\\\ \\varnothing(h) = f'(x) - a_2{h \\over 2}^2 - a_4{h \\over 2}^4 - a_6{h \\over 2}^6 -...\\\\ \\varnothing(h)-4 \\varnothing(h/2) = 3f'(x)-{3 \\over 4} a_4h^4 - {15 \\over 16} a_6h^6 -... \\\\ => f'(x)={4\\over3} \\varnothing(h/2) - {1\\over3}\\varnothing(h)+O(h^4) Bentuk Tabel Extrapolasi Richardson adalah seperti berikut. Tabel Richardson Extrapolation $ D(0,0) = \\varnothing(h) $ $ D(0,0) = \\varnothing(h/2) $ $ D(1,1) $ $ D(0,0) = \\varnothing(h/4) $ $ D(2,1) $ $ D(2,2) $ $ D(0,0) = \\varnothing(h/8) $ $ D(3,1) $ $ D(3,1) $ $ D(3,3) $ Nilai kolom pertama atau D(n,0) = $ \\varnothing {h\\over 2^n} $ = Central Difference. dan pada kolom yang lain menggunakan $ D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) $ Menghitung menggunakan Extrapolasi Richardson \u00b6 Menghitung nilai numerik dari turunan $ f(x) = x^{cos(x)} $, pada $ x=0.6 $ dengan $ h=0.1 $ D(0,0) = \\varnothing (h) = {f(x+h)-f(x-h) \\over 2h} \\\\ D(1,0) = \\varnothing (0.1) = {f(0.7)-f(0.5) \\over 0.2} = 1.08483 \\\\ D(2,0) = \\varnothing (0.05) = {f(0.65)-f(0.55) \\over 0.2} = 1.08988 \\\\ D(3,0) = \\varnothing (0.025) = {f(0.625)-f(0.575) \\over 0.05} = 1.09115 D(0,0) = \\varnothing (h) = {f(x+h)-f(x-h) \\over 2h} \\\\ D(1,0) = \\varnothing (0.1) = {f(0.7)-f(0.5) \\over 0.2} = 1.08483 \\\\ D(2,0) = \\varnothing (0.05) = {f(0.65)-f(0.55) \\over 0.2} = 1.08988 \\\\ D(3,0) = \\varnothing (0.025) = {f(0.625)-f(0.575) \\over 0.05} = 1.09115 Kemudian untuk D(n,m), m tidak samadengan 0. dihitung dengan cara berikut D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) \\\\ D(1,1) = {4 \\over 3} D(1,0) - {1 \\over 3}D(0,0) = 1.09156 \\\\ D(2,1) = {4 \\over 3} D(2,0) - {1 \\over 3}D(1,0) = 1.09157 \\\\ D(2,2) = {16 \\over 15} D(2,1) - {1 \\over 15}D(1,1) = 1.09157 D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) \\\\ D(1,1) = {4 \\over 3} D(1,0) - {1 \\over 3}D(0,0) = 1.09156 \\\\ D(2,1) = {4 \\over 3} D(2,0) - {1 \\over 3}D(1,0) = 1.09157 \\\\ D(2,2) = {16 \\over 15} D(2,1) - {1 \\over 15}D(1,1) = 1.09157 Dari hasil perhitungan tersebut kemudian didapatkan nilai dalam bentuk tabel Richardson Tabel Richardson 1,08483 1,08988 1,09156 1,09115 1,09157 1,09157 Pada tabel tersebut baris ke 3 kolom ke 3 adalah hasil estimasi terbaik dari turunan suatu fungsi $ f(x) = x^{cos(x)} $ pada $ x=0.6 $ yaitu 1,09157. Penerapan Extrapolasi Richardson dengan Python \u00b6 import math from numpy import zeros def Oh ( x , h ): return ( f ( x + h ) - f ( x - h )) / ( 2 * h ) def richardson_extrapolation ( f , x , h , n ): D = zeros (( n + 1 , n + 1 )) for i in range ( n + 1 ): for j in range ( i + 1 ): if j == 0 : D [ i , 0 ] = round ( Oh ( x , h / ( 2 ** i )), 5 ) else : D [ i , j ] = round ((( 4 ** j ) / (( 4 ** j ) - 1 ) * D [ i , j - 1 ]) - ( 1 / (( 4 ** j ) - 1 ) * D [ i - 1 , j - 1 ]), 5 ) print ( D [ i , 0 : i + 1 ]) return D def f ( x ): return x ** math . cos ( x ) x = 0.6 h = 0.1 n = 2 print ( '=Tabel Richardson= \\n ' ) print ( 'f(x) = x^cos(x) \\n ' ) hasil = richardson_extrapolation ( f , x , h , n ) print ( 'hasil estimasi terbaik adalah' , hasil [ n , n ]) Pada program tersebut menggunakan bantuan dari library numpy untuk menampung nilai hasil perhitungan dalam bentuk array matriks. dan library math yang berisi banyak sekali fungsi matematika. import math from numpy import zeros Kemudian terdapat fungsi Oh(x, h) yang merupakan fungsi untuk beda terpusat ( Central Difference ) yaitu $ f'(x) = {f(x+h) - f(x-h) \\over 2h} $ def Oh ( x , h ): return ( f ( x + h ) - f ( x - h )) / ( 2 * h ) Kemudian terdapat fungsi richardson extrapolation(f, x, h, n) dengan f merupakan fungsi yang didefinisikan, x dan h merupakan nilai yang telah didefinisikan, dan n merupakan banyak iterasi/panjang tabel n x n. Di fungsi ini library numpy baru digunakan yaitu zeros((n+1,n+1)) untuk membetuk arrar 0 sepanjang n. kemudian melakukan iterasi untuk menghitung D(0,0) sampai D(n,m). saat iterasi j adalah 0 maka akan menghitung $ D(n,0) = \\varnothing (h) = {f(x+h)-f(x-h) \\over 2h} $, selain itu akan menghitung $ D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) $ def richardson_extrapolation ( f , x , h , n ): D = zeros (( n + 1 , n + 1 )) for i in range ( n + 1 ): for j in range ( i + 1 ): if j == 0 : D [ i , 0 ] = round ( Oh ( x , h / ( 2 ** i )), 5 ) else : D [ i , j ] = round ((( 4 ** j ) / (( 4 ** j ) - 1 ) * D [ i , j - 1 ]) - ( 1 / (( 4 ** j ) - 1 ) * D [ i - 1 , j - 1 ]), 5 ) print ( D [ i , 0 : i + 1 ]) return D Kemudian membuat fungsi yang akan dihitung turunannya. Dalam program tersebut fungsi yang digunakan adalah $ f(x) = x^{cox(x)} $ dengan x=0.6 x=0.6 , h=0.1 h=0.1 , dan n=2 n=2 . def f ( x ): return x ** math . cos ( x ) x = 0.6 h = 0.1 n = 2 Saat program tersebut dijalankan maka menghasilkan output seperti berikut. = Tabel Richardson = f ( x ) = x ^ cos ( x ) [ 1.08483 ] [ 1.08988 1.09156 ] [ 1.09115 1.09157 1.09157 ] hasil estimasi terbaik adalah 1.09157 Sekian terimakasih:) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Tugas 5"},{"location":"komnum/tabel richardson/#mencari-estimasi-turunan-fungsi-dengan-ekstrapolasi-richardson","text":"","title":"Mencari Estimasi Turunan Fungsi dengan Ekstrapolasi Richardson"},{"location":"komnum/tabel richardson/#ekstrapolasi-richardson","text":"Ekstrapolasi Richardson adalah salah satu teknik menggabungkan dua nilai perkiraan yang dihitung diperoleh dengan menggunakan rumus yang sama atau metode dengan dua ukuran langkah yang berbeda, untuk mendapatkan metode orde tinggi yang menyediakan lebih dekat perkiraan jumlah tertentu. Dalam extrapolasi Richardson ditetapkan $ f(x) $ dan $ x $ tertentu. \\varnothing(h) = {f(x+h) - f(x-h) \\over 2h} \\\\ \\varnothing(h) = f'(x) - a_2h^2 - a_4h_4 - a_6h_6- ... \\\\ \\varnothing(h) = f'(x) - a_2{h \\over 2}^2 - a_4{h \\over 2}^4 - a_6{h \\over 2}^6 -...\\\\ \\varnothing(h)-4 \\varnothing(h/2) = 3f'(x)-{3 \\over 4} a_4h^4 - {15 \\over 16} a_6h^6 -... \\\\ => f'(x)={4\\over3} \\varnothing(h/2) - {1\\over3}\\varnothing(h)+O(h^4) \\varnothing(h) = {f(x+h) - f(x-h) \\over 2h} \\\\ \\varnothing(h) = f'(x) - a_2h^2 - a_4h_4 - a_6h_6- ... \\\\ \\varnothing(h) = f'(x) - a_2{h \\over 2}^2 - a_4{h \\over 2}^4 - a_6{h \\over 2}^6 -...\\\\ \\varnothing(h)-4 \\varnothing(h/2) = 3f'(x)-{3 \\over 4} a_4h^4 - {15 \\over 16} a_6h^6 -... \\\\ => f'(x)={4\\over3} \\varnothing(h/2) - {1\\over3}\\varnothing(h)+O(h^4) Bentuk Tabel Extrapolasi Richardson adalah seperti berikut. Tabel Richardson Extrapolation $ D(0,0) = \\varnothing(h) $ $ D(0,0) = \\varnothing(h/2) $ $ D(1,1) $ $ D(0,0) = \\varnothing(h/4) $ $ D(2,1) $ $ D(2,2) $ $ D(0,0) = \\varnothing(h/8) $ $ D(3,1) $ $ D(3,1) $ $ D(3,3) $ Nilai kolom pertama atau D(n,0) = $ \\varnothing {h\\over 2^n} $ = Central Difference. dan pada kolom yang lain menggunakan $ D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) $","title":"Ekstrapolasi Richardson"},{"location":"komnum/tabel richardson/#menghitung-menggunakan-extrapolasi-richardson","text":"Menghitung nilai numerik dari turunan $ f(x) = x^{cos(x)} $, pada $ x=0.6 $ dengan $ h=0.1 $ D(0,0) = \\varnothing (h) = {f(x+h)-f(x-h) \\over 2h} \\\\ D(1,0) = \\varnothing (0.1) = {f(0.7)-f(0.5) \\over 0.2} = 1.08483 \\\\ D(2,0) = \\varnothing (0.05) = {f(0.65)-f(0.55) \\over 0.2} = 1.08988 \\\\ D(3,0) = \\varnothing (0.025) = {f(0.625)-f(0.575) \\over 0.05} = 1.09115 D(0,0) = \\varnothing (h) = {f(x+h)-f(x-h) \\over 2h} \\\\ D(1,0) = \\varnothing (0.1) = {f(0.7)-f(0.5) \\over 0.2} = 1.08483 \\\\ D(2,0) = \\varnothing (0.05) = {f(0.65)-f(0.55) \\over 0.2} = 1.08988 \\\\ D(3,0) = \\varnothing (0.025) = {f(0.625)-f(0.575) \\over 0.05} = 1.09115 Kemudian untuk D(n,m), m tidak samadengan 0. dihitung dengan cara berikut D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) \\\\ D(1,1) = {4 \\over 3} D(1,0) - {1 \\over 3}D(0,0) = 1.09156 \\\\ D(2,1) = {4 \\over 3} D(2,0) - {1 \\over 3}D(1,0) = 1.09157 \\\\ D(2,2) = {16 \\over 15} D(2,1) - {1 \\over 15}D(1,1) = 1.09157 D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) \\\\ D(1,1) = {4 \\over 3} D(1,0) - {1 \\over 3}D(0,0) = 1.09156 \\\\ D(2,1) = {4 \\over 3} D(2,0) - {1 \\over 3}D(1,0) = 1.09157 \\\\ D(2,2) = {16 \\over 15} D(2,1) - {1 \\over 15}D(1,1) = 1.09157 Dari hasil perhitungan tersebut kemudian didapatkan nilai dalam bentuk tabel Richardson Tabel Richardson 1,08483 1,08988 1,09156 1,09115 1,09157 1,09157 Pada tabel tersebut baris ke 3 kolom ke 3 adalah hasil estimasi terbaik dari turunan suatu fungsi $ f(x) = x^{cos(x)} $ pada $ x=0.6 $ yaitu 1,09157.","title":"Menghitung menggunakan Extrapolasi Richardson"},{"location":"komnum/tabel richardson/#penerapan-extrapolasi-richardson-dengan-python","text":"import math from numpy import zeros def Oh ( x , h ): return ( f ( x + h ) - f ( x - h )) / ( 2 * h ) def richardson_extrapolation ( f , x , h , n ): D = zeros (( n + 1 , n + 1 )) for i in range ( n + 1 ): for j in range ( i + 1 ): if j == 0 : D [ i , 0 ] = round ( Oh ( x , h / ( 2 ** i )), 5 ) else : D [ i , j ] = round ((( 4 ** j ) / (( 4 ** j ) - 1 ) * D [ i , j - 1 ]) - ( 1 / (( 4 ** j ) - 1 ) * D [ i - 1 , j - 1 ]), 5 ) print ( D [ i , 0 : i + 1 ]) return D def f ( x ): return x ** math . cos ( x ) x = 0.6 h = 0.1 n = 2 print ( '=Tabel Richardson= \\n ' ) print ( 'f(x) = x^cos(x) \\n ' ) hasil = richardson_extrapolation ( f , x , h , n ) print ( 'hasil estimasi terbaik adalah' , hasil [ n , n ]) Pada program tersebut menggunakan bantuan dari library numpy untuk menampung nilai hasil perhitungan dalam bentuk array matriks. dan library math yang berisi banyak sekali fungsi matematika. import math from numpy import zeros Kemudian terdapat fungsi Oh(x, h) yang merupakan fungsi untuk beda terpusat ( Central Difference ) yaitu $ f'(x) = {f(x+h) - f(x-h) \\over 2h} $ def Oh ( x , h ): return ( f ( x + h ) - f ( x - h )) / ( 2 * h ) Kemudian terdapat fungsi richardson extrapolation(f, x, h, n) dengan f merupakan fungsi yang didefinisikan, x dan h merupakan nilai yang telah didefinisikan, dan n merupakan banyak iterasi/panjang tabel n x n. Di fungsi ini library numpy baru digunakan yaitu zeros((n+1,n+1)) untuk membetuk arrar 0 sepanjang n. kemudian melakukan iterasi untuk menghitung D(0,0) sampai D(n,m). saat iterasi j adalah 0 maka akan menghitung $ D(n,0) = \\varnothing (h) = {f(x+h)-f(x-h) \\over 2h} $, selain itu akan menghitung $ D(n,m) = {4^m \\over 4^m - 1}D(n,m-1) - {1 \\over 4^m-1}D(n-1,m-1) $ def richardson_extrapolation ( f , x , h , n ): D = zeros (( n + 1 , n + 1 )) for i in range ( n + 1 ): for j in range ( i + 1 ): if j == 0 : D [ i , 0 ] = round ( Oh ( x , h / ( 2 ** i )), 5 ) else : D [ i , j ] = round ((( 4 ** j ) / (( 4 ** j ) - 1 ) * D [ i , j - 1 ]) - ( 1 / (( 4 ** j ) - 1 ) * D [ i - 1 , j - 1 ]), 5 ) print ( D [ i , 0 : i + 1 ]) return D Kemudian membuat fungsi yang akan dihitung turunannya. Dalam program tersebut fungsi yang digunakan adalah $ f(x) = x^{cox(x)} $ dengan x=0.6 x=0.6 , h=0.1 h=0.1 , dan n=2 n=2 . def f ( x ): return x ** math . cos ( x ) x = 0.6 h = 0.1 n = 2 Saat program tersebut dijalankan maka menghasilkan output seperti berikut. = Tabel Richardson = f ( x ) = x ^ cos ( x ) [ 1.08483 ] [ 1.08988 1.09156 ] [ 1.09115 1.09157 1.09157 ] hasil estimasi terbaik adalah 1.09157 Sekian terimakasih:) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"Penerapan Extrapolasi Richardson dengan Python"},{"location":"komnum/uas komnum/","text":"Ujian Akhir Semester Komputasi Numerik \u00b6 Soal \u00b6 Gunakan metode Midpoint untuk menyelesaikan Persamaan Deferensial Biasa berikut $ y(x) = 1 + 2x^2 + y \\\\ y(0) = 1 $ gunakan $ h= 0,1 $ Tentukan $ y(0.1) $ and $ y(0.2) $ Hitunglah dengan metode iterasi Jacobi sampai iterasi ke 4 untuk penyelesaian sistem persamaan liner berikut $ x_1 + 2x_2 + 3x_3 = 10 \\\\ 2x_1 + 3x_2 + 3x_3 = 13 \\\\ x_1 + x_2 + x_3 = 15 $ Hitunglah $ \\int_{1}^{3} 2x $ dengan Metode Trapesium Rekursif No 1 \u00b6 Berikut merupakan program dengan metode midpoint untuk meyelesaikan Persamaan Defrensial Biasa dari $ y(x) = 1 + 2x^2 + y \\space \\space \\space$, $ y(0) = 1 $ dengan $ h= 0,1 $ dan initial $ x_0 = 0 $, initial $ y_0 = 1 $ from numpy import arange def midpoint_method ( f , x0 , y0 , h ): print ( ' \\n Midpoint Method' ) y = y0 for i in arange ( 0 , 0.5 , 0.1 ): y = y0 + h * i * f ( x0 , y ) print ( 'y' , round ( i , 1 ), '=' , round ( y , 4 )) def f ( x , y ): return 1 + 2 * ( x ** 2 ) + y y0 = 1 x0 = 0 h = 0.1 midpoint_method ( f , x0 , y0 , h ) Dalam program tersebut, digunakan fungsi arange dari library numpy, yang nantinya akan digunakan untuk membuat range berupa float untuk digunakan pada perulangan for. Dengan fungsi tersebut perulangan akan menghasilkan nilai range float, seperti 0.1, 0.2, 0.3 dst. Kemudian dalam program tersebut dibuat sebuah fungsi midpoint_method(arg1,..) dengan parameter f untuk persamaan yang ditentukan, x0, y0, dan h. Dalam fungsi tersebut berisi variabel y sebagai initial yang bernilai awal y0, selanjutnya akan melakukan looping dari 0.0 hingga 0.4 ( karena yang dicari hanya 0.1 dan 0.3 maka yang saya memberika batasan hanya sampai 0.5 ), dalam setiap looping tersebut akan melakukan perhitungan y. Setelah program tersebut dijalankan, maka output yang dihasilkan adalah seperti berikut. Midpoint Method y 0.0 = 1.0 y 0.1 = 1.02 y 0.2 = 1.0404 y 0.3 = 1.0612 y 0.4 = 1.0824 Dari program tersebut ditemukan nilai dari dari y(0.1) adalah 1.02, dan y(0.2) adalah 1.0404. No 2 \u00b6 Berikut merupakan program dengan metode iterasi Jacobi untuk penyelesian sistem persamaan linear dari $ x_1 + 2x_2 + 3x_3 = 10 \\\\ 2x_1 + 3x_2 + 3x_3 = 13 \\\\ x_1 + x_2 + x_3 = 15 $ import math import copy from numpy import linalg A = [[ 1 , 2 , 3 ], [ 2 , 3 , 3 ], [ 1 , 1 , 1 ]] B = [ 10 , 13 , 5 ] X = [ 0 ] * len ( A ) X_temp = copy . copy ( X ) error = 0.1 max_iterasi = 4 print ( 'Matrix A' , A ) print ( 'Matrix B' , B , ' \\n ' ) e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X_temp [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_temp [ i ]) ** 2 X_temp = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) print ( ' \\n aproksimsai error =' , math . sqrt ( e )) Dalam program tersebut, digunakan libarary math yang nantinya digunakan untuk menghitung akar, kemudian libarary copy untuk menyalin nilai dari sebuah variabel. dan fungsi linalg dari libarary numpy untuk mencari determinan dari matrik. Kemudian terdapat list A yang berisi nilai koefisen dari Sistem Persamaan Linear yang akan diselesaikan, dan list B merupakan nilai hasil dari SPL tersebut, kemudian list X untuk menampung hasil dari perhitungan. Diprogram tersebut dideklarasikan toleransi error sebesar 0.1 dan maxsimal melakukan iterasi sebayak 4 kali, selanjutnya program akan melakukan iterasi ketika error yang dihasilkan kurang dari tolerasi error dan iterasi yang dilakukan belum mencapai batas iterasi, maka program akan lanjut. Selanjutnya akan dicek determinan dari matrik A, jika determinannya adalah 0 maka program akan lanjut dan melakukan perhitungan iteratif sesuai dengan formula dari metode iterasi Jacobi. Selain itu program akan berhenti dan menyatakan bahwa \"tidak ada penyelesaian untuk SPL tersebut\". Setelah program tersebut dijalankan dan berhenti setelah 4 kali iterasi, dan output yang dihasilkan adalah seperti berikut . Matrix A [[ 1 , 2 , 3 ], [ 2 , 3 , 3 ], [ 1 , 1 , 1 ]] Matrix B [ 10 , 13 , 5 ] k - 1 X = [ 10.0 , 4.3333 , 5.0 ] k - 2 X = [ - 13.6666 , - 7.3333 , - 9.3333 ] k - 3 X = [ 52.6665 , 22.7777 , 25.9999 ] k - 4 X = [ - 113.5551 , - 56.7776 , - 70.4442 ] X1 : - 113.5551 X2 : - 56.7776 X3 : - 70.4442 aproksimasi error = 207.9906980839768 Maka ditemukan nilai dari X1 : -113.5551, X2 : -56.7776, dan X3 : -70.4442, dengan error sebesar 207.9906980839768. No 3 \u00b6 Berikut program dengan menggunakan metode Trapesium Rekursif untuk menghitung nilai integral dari $ \\int_{1}^{3} 2x $ dengan 4 kali kali iterasi. def trapezoid_rekursif ( f , a , b , n ): trapezoid = 0 print ( ' R' , ' \\t ' , 'Trapezoid' ) for i in range ( 0 , n + 1 ): k = 2 ** i h = ( b - a ) / k xi = a jum = 0 for j in range ( 1 , k ): xi += h jum += f ( xi ) old_trapezoid = trapezoid trapezoid = ( h * ( f ( a ) + ( 2 * jum ) + f ( b )) ) / 2 print ( '(' + str ( i ) + ',0) \\t ' , round ( trapezoid , 4 )) print ( ' \\n aproksimasi error :' , old_trapezoid - trapezoid ) def f ( x ): return 2 * x print ( \"f(x) = 2x \\n \" ) a = 1 b = 3 n = 3 trapezoid_rekursif ( f , a , b , n ) Dalam program tersebut, dibuat fungsi trapezoid_rekusif(arg1,...) , di fungsi tersebut terdapat parameter f untuk persamaan yang digunakan, a untuk batas bawah, b untuk batas atas, dan n untuk banyaknya iterasi. Kemudian di fungsi tersebut akan melakukan iterasi sebanya n untuk melakukan perhitungan sesuai dengan formula dari metode Trapesium Rekursif. Saat program tersebut dijalankan dan berhenti setelah 4kali iterasi, dan output yang dihasilkan adalah seperti berikut. f ( x ) = 2 x R Trapezoid ( 0 , 0 ) 8.0 ( 1 , 0 ) 8.0 ( 2 , 0 ) 8.0 ( 3 , 0 ) 8.0 aproksimasi error : 0.0 Maka ditemukan nilai dari integral tersebut yaitu 8.0 dengan error = 0.0. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"UAS"},{"location":"komnum/uas komnum/#ujian-akhir-semester-komputasi-numerik","text":"","title":"Ujian Akhir Semester Komputasi Numerik"},{"location":"komnum/uas komnum/#soal","text":"Gunakan metode Midpoint untuk menyelesaikan Persamaan Deferensial Biasa berikut $ y(x) = 1 + 2x^2 + y \\\\ y(0) = 1 $ gunakan $ h= 0,1 $ Tentukan $ y(0.1) $ and $ y(0.2) $ Hitunglah dengan metode iterasi Jacobi sampai iterasi ke 4 untuk penyelesaian sistem persamaan liner berikut $ x_1 + 2x_2 + 3x_3 = 10 \\\\ 2x_1 + 3x_2 + 3x_3 = 13 \\\\ x_1 + x_2 + x_3 = 15 $ Hitunglah $ \\int_{1}^{3} 2x $ dengan Metode Trapesium Rekursif","title":"Soal"},{"location":"komnum/uas komnum/#no-1","text":"Berikut merupakan program dengan metode midpoint untuk meyelesaikan Persamaan Defrensial Biasa dari $ y(x) = 1 + 2x^2 + y \\space \\space \\space$, $ y(0) = 1 $ dengan $ h= 0,1 $ dan initial $ x_0 = 0 $, initial $ y_0 = 1 $ from numpy import arange def midpoint_method ( f , x0 , y0 , h ): print ( ' \\n Midpoint Method' ) y = y0 for i in arange ( 0 , 0.5 , 0.1 ): y = y0 + h * i * f ( x0 , y ) print ( 'y' , round ( i , 1 ), '=' , round ( y , 4 )) def f ( x , y ): return 1 + 2 * ( x ** 2 ) + y y0 = 1 x0 = 0 h = 0.1 midpoint_method ( f , x0 , y0 , h ) Dalam program tersebut, digunakan fungsi arange dari library numpy, yang nantinya akan digunakan untuk membuat range berupa float untuk digunakan pada perulangan for. Dengan fungsi tersebut perulangan akan menghasilkan nilai range float, seperti 0.1, 0.2, 0.3 dst. Kemudian dalam program tersebut dibuat sebuah fungsi midpoint_method(arg1,..) dengan parameter f untuk persamaan yang ditentukan, x0, y0, dan h. Dalam fungsi tersebut berisi variabel y sebagai initial yang bernilai awal y0, selanjutnya akan melakukan looping dari 0.0 hingga 0.4 ( karena yang dicari hanya 0.1 dan 0.3 maka yang saya memberika batasan hanya sampai 0.5 ), dalam setiap looping tersebut akan melakukan perhitungan y. Setelah program tersebut dijalankan, maka output yang dihasilkan adalah seperti berikut. Midpoint Method y 0.0 = 1.0 y 0.1 = 1.02 y 0.2 = 1.0404 y 0.3 = 1.0612 y 0.4 = 1.0824 Dari program tersebut ditemukan nilai dari dari y(0.1) adalah 1.02, dan y(0.2) adalah 1.0404.","title":"No 1"},{"location":"komnum/uas komnum/#no-2","text":"Berikut merupakan program dengan metode iterasi Jacobi untuk penyelesian sistem persamaan linear dari $ x_1 + 2x_2 + 3x_3 = 10 \\\\ 2x_1 + 3x_2 + 3x_3 = 13 \\\\ x_1 + x_2 + x_3 = 15 $ import math import copy from numpy import linalg A = [[ 1 , 2 , 3 ], [ 2 , 3 , 3 ], [ 1 , 1 , 1 ]] B = [ 10 , 13 , 5 ] X = [ 0 ] * len ( A ) X_temp = copy . copy ( X ) error = 0.1 max_iterasi = 4 print ( 'Matrix A' , A ) print ( 'Matrix B' , B , ' \\n ' ) e = 1 iterasi = 0 while math . sqrt ( e ) >= error and iterasi < max_iterasi : if linalg . det ( A ) != 0 : for i in range ( len ( X )): i_sum = 0 for j in range ( len ( X )): if j != i : i_sum += A [ i ][ j ] * X_temp [ j ] X [ i ] = round (( B [ i ] - i_sum ) / A [ i ][ i ], 4 ) print ( 'k-' + str ( iterasi + 1 ), 'X =' , X ) e = 0 for i in range ( len ( X )): e += ( X [ i ] - X_temp [ i ]) ** 2 X_temp = copy . copy ( X ) iterasi += 1 else : print ( 'tidak ada peneyelesaian untuk persamaan tersebut!' ) for i in range ( len ( X )): print ( 'X' + str ( i + 1 ), ':' , X [ i ]) print ( ' \\n aproksimsai error =' , math . sqrt ( e )) Dalam program tersebut, digunakan libarary math yang nantinya digunakan untuk menghitung akar, kemudian libarary copy untuk menyalin nilai dari sebuah variabel. dan fungsi linalg dari libarary numpy untuk mencari determinan dari matrik. Kemudian terdapat list A yang berisi nilai koefisen dari Sistem Persamaan Linear yang akan diselesaikan, dan list B merupakan nilai hasil dari SPL tersebut, kemudian list X untuk menampung hasil dari perhitungan. Diprogram tersebut dideklarasikan toleransi error sebesar 0.1 dan maxsimal melakukan iterasi sebayak 4 kali, selanjutnya program akan melakukan iterasi ketika error yang dihasilkan kurang dari tolerasi error dan iterasi yang dilakukan belum mencapai batas iterasi, maka program akan lanjut. Selanjutnya akan dicek determinan dari matrik A, jika determinannya adalah 0 maka program akan lanjut dan melakukan perhitungan iteratif sesuai dengan formula dari metode iterasi Jacobi. Selain itu program akan berhenti dan menyatakan bahwa \"tidak ada penyelesaian untuk SPL tersebut\". Setelah program tersebut dijalankan dan berhenti setelah 4 kali iterasi, dan output yang dihasilkan adalah seperti berikut . Matrix A [[ 1 , 2 , 3 ], [ 2 , 3 , 3 ], [ 1 , 1 , 1 ]] Matrix B [ 10 , 13 , 5 ] k - 1 X = [ 10.0 , 4.3333 , 5.0 ] k - 2 X = [ - 13.6666 , - 7.3333 , - 9.3333 ] k - 3 X = [ 52.6665 , 22.7777 , 25.9999 ] k - 4 X = [ - 113.5551 , - 56.7776 , - 70.4442 ] X1 : - 113.5551 X2 : - 56.7776 X3 : - 70.4442 aproksimasi error = 207.9906980839768 Maka ditemukan nilai dari X1 : -113.5551, X2 : -56.7776, dan X3 : -70.4442, dengan error sebesar 207.9906980839768.","title":"No 2"},{"location":"komnum/uas komnum/#no-3","text":"Berikut program dengan menggunakan metode Trapesium Rekursif untuk menghitung nilai integral dari $ \\int_{1}^{3} 2x $ dengan 4 kali kali iterasi. def trapezoid_rekursif ( f , a , b , n ): trapezoid = 0 print ( ' R' , ' \\t ' , 'Trapezoid' ) for i in range ( 0 , n + 1 ): k = 2 ** i h = ( b - a ) / k xi = a jum = 0 for j in range ( 1 , k ): xi += h jum += f ( xi ) old_trapezoid = trapezoid trapezoid = ( h * ( f ( a ) + ( 2 * jum ) + f ( b )) ) / 2 print ( '(' + str ( i ) + ',0) \\t ' , round ( trapezoid , 4 )) print ( ' \\n aproksimasi error :' , old_trapezoid - trapezoid ) def f ( x ): return 2 * x print ( \"f(x) = 2x \\n \" ) a = 1 b = 3 n = 3 trapezoid_rekursif ( f , a , b , n ) Dalam program tersebut, dibuat fungsi trapezoid_rekusif(arg1,...) , di fungsi tersebut terdapat parameter f untuk persamaan yang digunakan, a untuk batas bawah, b untuk batas atas, dan n untuk banyaknya iterasi. Kemudian di fungsi tersebut akan melakukan iterasi sebanya n untuk melakukan perhitungan sesuai dengan formula dari metode Trapesium Rekursif. Saat program tersebut dijalankan dan berhenti setelah 4kali iterasi, dan output yang dihasilkan adalah seperti berikut. f ( x ) = 2 x R Trapezoid ( 0 , 0 ) 8.0 ( 1 , 0 ) 8.0 ( 2 , 0 ) 8.0 ( 3 , 0 ) 8.0 aproksimasi error : 0.0 Maka ditemukan nilai dari integral tersebut yaitu 8.0 dengan error = 0.0. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]}, displayAlign: \"left\" });","title":"No 3"},{"location":"pendat/","text":"Selamat Datang di Halaman Tugas Penambangan Data \u00b6 Nama : Ach. Faisol S. Arifin NRP : 180411100073 Jurusan : Teknik Informatika, Universitas Trunojoyo Madura Kelas : Penambangan Data 5D Dosen Pengampu : MULA'AB, S.Si., M.Kom","title":"Beranda"},{"location":"pendat/#selamat-datang-di-halaman-tugas-penambangan-data","text":"Nama : Ach. Faisol S. Arifin NRP : 180411100073 Jurusan : Teknik Informatika, Universitas Trunojoyo Madura Kelas : Penambangan Data 5D Dosen Pengampu : MULA'AB, S.Si., M.Kom","title":"Selamat Datang di Halaman Tugas Penambangan Data"},{"location":"pendat/clustering/","text":"Implementasi Metode K-Means, K-Modes, dan K-Prototype dengan python \u00b6 Clustering \u00b6 Clustering adalah suatu metode untuk mengelompokkan data berdasarkan ukuran kemiripan data tersebut. Pada metode clustering pengelompokan datanya tidak harus sama, akan tetapi hanya kemiripan data tersebut yang didapatkan berdasarkan pada kedekatan suatu karakteristik sample yang, ada dengan menghitung jarak salah satunya dengan menggunakan rumus ecluidian distance. pada dasarnya, metode clustering mengoptimumkan pusat cluster(centroid) untuk melakukan pengelompokan. Pada prinsipnya metode clustering sangat bermanfaat sekali dalam bidang kelimuan, seperti Identifikasi obyek (Recoginition) Metode clustering biasa dipakai dalam bidang Image Processing, Computer Vision, Robot Vision, dan lain-lain. Decission Support System dan Data Mining Dalam hal ini metode clusting biasa digunakan dalam Segmentasi Pasar, pemetaan wilayah, Manajement marketing, dan lain-lain. dalam hal ini metode clusting biasa digunakan dalam Segmentasi Pasar, pemetaan wilayah, Manajement marketing, dan lain-lain. Salah satu algoritma clustring yang banyak dipakai adalah K-Means clustering. Hal ini memungkinkan untuk mengelompokkan data sesuai dengan kesamaan yang ada di antara mereka dalam k cluster, diberikan sebagai input ke algoritma. K-Means Clustering \u00b6 K-Means adalah metode pengelompokan data atau salah satu metode data mining dengan melakukan proses pemodelan yang unsupervised ( yang tidak terawasi ) dan merupakan salah satu metode clustering dengan sistem partisi. Dalam proses pengelompokan data, terdapat 2 jenis data yang digunakan, yaitu Hierarchical dan Non-Hierarchical . Metode K-Means clustering salah satu metode clustering untuk mengelompokkan data yang non-herarchical. Metode K-Means akan berusaha untuk mengelompokkan data ke dalam beberapa cluster, dari setiap cluster memiliki karakteristik yang mirip antara dari yang satu dengan data yang lainnya dan miliki karakteristik yang berbeda dengan data pada cluster yang lain. Secara umum, K-Means clustering melakukan pengelompokan dengan algoritma seperti berikut: Tentukan jumlah k (k=cluster) Alokasikan data awal ke dalam cluster secara random Hitung centroid/rata-rata dari masing-masing cluster yang telah ditentukan. Hitung jarak masing-masing data dengan centroid, dan alokasikan data pada cluster terdekat. Ulangi langka 3 dan 4, hingga nilai dari centroid tidak berubah lagi. K-Modes Clustering \u00b6 K-Modes clustering adalah turunan dari metode K-Means clustering. Pada metode K-Means hanya bekerja pada data yang nilainya numeric dan tidak akan bekerja jika data yang akan cluster adalah nilainya kategorikal. K-Modes berkerja mirip seperti K-Means, akan tetapi metode ini di khususkan untuk mengelompokkan data yang nilainya adalah kategorikal. K-Modes berkerja dengan menggunakan metode berbasis frekuensi untuk memperbarui modus dalam proses pengelompokan dan mengkuantifikasi total ketidakcocokan antara dua objek. semakin kecil jumlah ini, semakin mirip kedua objek. K-Prototype Clustering \u00b6 K-Prototype clustering merupakan metode clustring gabungan dari K-Means dan K-Modes. Metode ini digunakan untuk mengelompokkan data yang memiliki attribut numerik dan kategorikal. Implementasi dengan Python \u00b6 K-Means \u00b6 Pada implementasi K-Means, kita dapat menggunakan data glass yang dapat diunduh di link ini , data tersebut dapat kita tampilkan dalam bentuk data frame. Pertama kali yang dapat kita lakukan adalah memuat data tersebut menggunaka libarary pandas. import pandas as pd data = pd . read_csv ( 'glass.csv' , delimiter = ';' , decimal = ',' ) df = pd . DataFrame ( data ) df . style . hide_index () Dari data tersebut akan tampil seperti berikut: ID refractive index Sodium Magnesium Aluminum Silicon Potassium Calcium Barium Iron 1 1.52101 13.64 4.49 1.1 71.78 0.06 8.75 0 0.001 2 1.51761 13.89 3.6 1.36 72.73 0.48 7.83 0 0 3 1.51618 13.53 3.55 1.54 72.99 0.39 7.78 0 0 4 1.51766 13.21 3.69 1.29 72.61 0.57 8.22 0 0 5 1.51742 13.27 3.62 1.24 73.08 0.55 8.07 0 0 6 1.51596 12.79 3.61 1.62 72.97 0.64 8.07 0 0.26 7 1.51743 13.3 3.6 1.14 73.09 0.58 8.17 0 0 8 1.51756 13.15 3.61 1.05 73.24 0.57 8.24 0 0 9 1.51918 14.04 3.58 1.37 72.08 0.56 8.3 0 0 10 1.51755 13 3.6 1.36 72.99 0.57 8.4 0 0.11 11 1.51571 12.72 3.46 1.56 73.2 0.67 8.09 0 0.24 12 1.51763 12.8 3.66 1.27 73.01 0.6 8.56 0 0 13 1.51589 12.88 3.43 1.4 73.28 0.69 8.05 0 0.24 14 1.51748 12.86 3.56 1.27 73.21 0.54 8.38 0 0.17 15 1.51763 12.61 3.59 1.31 73.29 0.58 8.5 0 0 16 1.51761 12.81 3.54 1.23 73.24 0.58 8.39 0 0 17 1.51784 12.68 3.67 1.16 73.11 0.61 8.7 0 0 18 1.52196 14.36 3.85 0.89 71.36 0.15 9.15 0 0 19 1.51911 13.9 3.73 1.18 72.12 0.06 8.89 0 0 20 1.51735 13.02 3.54 1.69 72.73 0.54 8.44 0 0.07 21 1.5175 12.82 3.55 1.49 72.75 0.54 8.52 0 0.19 22 1.51966 14.77 3.75 0.29 72.02 0.03 9 0 0 23 1.51736 12.78 3.62 1.29 72.79 0.59 8.7 0 0 24 1.51751 12.81 3.57 1.35 73.02 0.62 8.59 0 0 25 1.5172 13.38 3.5 1.15 72.85 0.5 8.43 0 0 26 1.51764 12.98 3.54 1.21 73 0.65 8.53 0 0 27 1.51793 13.21 3.48 1.41 72.64 0.59 8.43 0 0 28 1.51721 12.87 3.48 1.33 73.04 0.56 8.43 0 0 29 1.51768 12.56 3.52 1.43 73.15 0.57 8.54 0 0 30 1.51784 13.08 3.49 1.28 72.86 0.6 8.49 0 0 31 1.51768 12.65 3.56 1.3 73.08 0.61 8.69 0 0.14 32 1.51747 12.84 3.5 1.14 73.27 0.56 8.55 0 0 33 1.51775 12.85 3.48 1.23 72.97 0.61 8.56 0.09 0.22 34 1.51753 12.57 3.47 1.38 73.39 0.6 8.55 0 0.06 35 1.51783 12.69 3.54 1.34 72.95 0.57 8.75 0 0 36 1.51567 13.29 3.45 1.21 72.74 0.56 8.57 0 0 37 1.51909 13.89 3.53 1.32 71.81 0.51 8.78 0.11 0 38 1.51797 12.74 3.48 1.35 72.96 0.64 8.68 0 0 39 1.52213 14.21 3.82 0.47 71.77 0.11 9.57 0 0 40 1.52213 14.21 3.82 0.47 71.77 0.11 9.57 0 0 41 1.51793 12.79 3.5 1.12 73.03 0.64 8.77 0 0 42 1.51755 12.71 3.42 1.2 73.2 0.59 8.64 0 0 43 1.51779 13.21 3.39 1.33 72.76 0.59 8.59 0 0 44 1.5221 13.73 3.84 0.72 71.76 0.17 9.74 0 0 45 1.51786 12.73 3.43 1.19 72.95 0.62 8.76 0 0.3 46 1.519 13.49 3.48 1.35 71.95 0.55 9 0 0 47 1.51869 13.19 3.37 1.18 72.72 0.57 8.83 0 0.16 48 1.52667 13.99 3.7 0.71 71.57 0.02 9.82 0 0.1 49 1.52223 13.21 3.77 0.79 71.99 0.13 10.02 0 0 50 1.51898 13.58 3.35 1.23 72.08 0.59 8.91 0 0 51 1.5232 13.72 3.72 0.51 71.75 0.09 10.06 0 0.16 52 1.51926 13.2 3.33 1.28 72.36 0.6 9.14 0 0.11 53 1.51808 13.43 2.87 1.19 72.84 0.55 9.03 0 0 54 1.51837 13.14 2.84 1.28 72.85 0.55 9.07 0 0 55 1.51778 13.21 2.81 1.29 72.98 0.51 9.02 0 0.09 56 1.51769 12.45 2.71 1.29 73.7 0.56 9.06 0 0.24 57 1.51215 12.99 3.47 1.12 72.98 0.62 8.35 0 0.31 58 1.51824 12.87 3.48 1.29 72.95 0.6 8.43 0 0 59 1.51754 13.48 3.74 1.17 72.99 0.59 8.03 0 0 60 1.51754 13.39 3.66 1.19 72.79 0.57 8.27 0 0.11 61 1.51905 13.6 3.62 1.11 72.64 0.14 8.76 0 0 62 1.51977 13.81 3.58 1.32 71.72 0.12 8.67 0.69 0 63 1.52172 13.51 3.86 0.88 71.79 0.23 9.54 0 0.11 64 1.52227 14.17 3.81 0.78 71.35 0 9.69 0 0 65 1.52172 13.48 3.74 0.9 72.01 0.18 9.61 0 0.07 66 1.52099 13.69 3.59 1.12 71.96 0.09 9.4 0 0 67 1.52152 13.05 3.65 0.87 72.22 0.19 9.85 0 0.17 68 1.52152 13.05 3.65 0.87 72.32 0.19 9.85 0 0.17 69 1.52152 13.12 3.58 0.9 72.2 0.23 9.82 0 0.16 70 1.523 13.31 3.58 0.82 71.99 0.12 10.17 0 0.03 71 1.51574 14.86 3.67 1.74 71.87 0.16 7.36 0 0.12 72 1.51848 13.64 3.87 1.27 71.96 0.54 8.32 0 0.32 73 1.51593 13.09 3.59 1.52 73.1 0.67 7.83 0 0 74 1.51631 13.34 3.57 1.57 72.87 0.61 7.89 0 0 75 1.51596 13.02 3.56 1.54 73.11 0.72 7.9 0 0 76 1.5159 13.02 3.58 1.51 73.12 0.69 7.96 0 0 77 1.51645 13.44 3.61 1.54 72.39 0.66 8.03 0 0 78 1.51627 13 3.58 1.54 72.83 0.61 8.04 0 0 79 1.51613 13.92 3.52 1.25 72.88 0.37 7.94 0 0.14 80 1.5159 12.82 3.52 1.9 72.86 0.69 7.97 0 0 81 1.51592 12.86 3.52 2.12 72.66 0.69 7.97 0 0 82 1.51593 13.25 3.45 1.43 73.17 0.61 7.86 0 0 83 1.51646 13.41 3.55 1.25 72.81 0.68 8.1 0 0 84 1.51594 13.09 3.52 1.55 72.87 0.68 8.05 0 0.09 85 1.51409 14.25 3.09 2.08 72.28 1.1 7.08 0 0 86 1.51625 13.36 3.58 1.49 72.72 0.45 8.21 0 0 87 1.51569 13.24 3.49 1.47 73.25 0.38 8.03 0 0 88 1.51645 13.4 3.49 1.52 72.65 0.67 8.08 0 0.1 89 1.51618 13.01 3.5 1.48 72.89 0.6 8.12 0 0 90 1.5164 12.55 3.48 1.87 73.23 0.63 8.08 0 0.09 91 1.51841 12.93 3.74 1.11 72.28 0.64 8.96 0 0.22 92 1.51605 12.9 3.44 1.45 73.06 0.44 8.27 0 0 93 1.51588 13.12 3.41 1.58 73.26 0.07 8.39 0 0.19 94 1.5159 13.24 3.34 1.47 73.1 0.39 8.22 0 0 95 1.51629 12.71 3.33 1.49 73.28 0.67 8.24 0 0 96 1.5186 13.36 3.43 1.43 72.26 0.51 8.6 0 0 97 1.51841 13.02 3.62 1.06 72.34 0.64 9.13 0 0.15 98 1.51743 12.2 3.25 1.16 73.55 0.62 8.9 0 0.24 99 1.51689 12.67 2.88 1.71 73.21 0.73 8.54 0 0 100 1.51811 12.96 2.96 1.43 72.92 0.6 8.79 0.14 0 101 1.51655 12.75 2.85 1.44 73.27 0.57 8.79 0.11 0.22 102 1.5173 12.35 2.72 1.63 72.87 0.7 9.23 0 0 103 1.5182 12.62 2.76 0.83 73.81 0.35 9.42 0 0.2 104 1.52725 13.8 3.15 0.66 70.57 0.08 11.64 0 0 105 1.5241 13.83 2.9 1.17 71.15 0.08 10.79 0 0 106 1.52475 11.45 0 1.88 72.19 0.81 13.24 0 0.34 107 1.53125 10.73 0 2.1 69.81 0.58 13.3 3.15 0.28 108 1.53393 12.3 0 1 70.16 0.12 16.19 0 0.24 109 1.52222 14.43 0 1 72.67 0.1 11.52 0 0.08 110 1.51818 13.72 0 0.56 74.45 0 10.99 0 0 111 1.52664 11.23 0 0.77 73.21 0 14.68 0 0 112 1.52739 11.02 0 0.75 73.08 0 14.96 0 0 113 1.52777 12.64 0 0.67 72.02 0.06 14.4 0 0 114 1.51892 13.46 3.83 1.26 72.55 0.57 8.21 0 0.14 115 1.51847 13.1 3.97 1.19 72.44 0.6 8.43 0 0 116 1.51846 13.41 3.89 1.33 72.38 0.51 8.28 0 0 117 1.51829 13.24 3.9 1.41 72.33 0.55 8.31 0 0.1 118 1.51708 13.72 3.68 1.81 72.06 0.64 7.88 0 0 119 1.51673 13.3 3.64 1.53 72.53 0.65 8.03 0 0.29 120 1.51652 13.56 3.57 1.47 72.45 0.64 7.96 0 0 121 1.51844 13.25 3.76 1.32 72.4 0.58 8.42 0 0 122 1.51663 12.93 3.54 1.62 72.96 0.64 8.03 0 0.21 123 1.51687 13.23 3.54 1.48 72.84 0.56 8.1 0 0 124 1.51707 13.48 3.48 1.71 72.52 0.62 7.99 0 0 125 1.52177 13.2 3.68 1.15 72.75 0.54 8.52 0 0 126 1.51872 12.93 3.66 1.56 72.51 0.58 8.55 0 0.12 127 1.51667 12.94 3.61 1.26 72.75 0.56 8.6 0 0 128 1.52081 13.78 2.28 1.43 71.99 0.49 9.85 0 0.17 129 1.52068 13.55 2.09 1.67 72.18 0.53 9.57 0.27 0.17 130 1.5202 13.98 1.35 1.63 71.76 0.39 10.56 0 0.18 131 1.52177 13.75 1.01 1.36 72.19 0.33 11.14 0 0 132 1.52614 13.7 0 1.36 71.24 0.19 13.44 0 0.1 133 1.51813 13.43 3.98 1.18 72.49 0.58 8.15 0 0 134 1.518 13.71 3.93 1.54 71.81 0.54 8.21 0 0.15 135 1.51811 13.33 3.85 1.25 72.78 0.52 8.12 0 0 136 1.51789 13.19 3.9 1.3 72.33 0.55 8.44 0 0.28 137 1.51806 13 3.8 1.08 73.07 0.56 8.38 0 0.12 138 1.51711 12.89 3.62 1.57 72.96 0.61 8.11 0 0 139 1.51674 12.79 3.52 1.54 73.36 0.66 7.9 0 0 140 1.51674 12.87 3.56 1.64 73.14 0.65 7.99 0 0 141 1.5169 13.33 3.54 1.61 72.54 0.68 8.11 0 0 142 1.51851 13.2 3.63 1.07 72.83 0.57 8.41 0.09 0.17 143 1.51662 12.85 3.51 1.44 73.01 0.68 8.23 0.06 0.25 144 1.51709 13 3.47 1.79 72.72 0.66 8.18 0 0 145 1.5166 12.99 3.18 1.23 72.97 0.58 8.81 0 0.24 146 1.51839 12.85 3.67 1.24 72.57 0.62 8.68 0 0.35 147 1.51769 13.65 3.66 1.11 72.77 0.11 8.6 0 0 148 1.5161 13.33 3.53 1.34 72.67 0.56 8.33 0 0 149 1.5167 13.24 3.57 1.38 72.7 0.56 8.44 0 0.1 150 1.51643 12.16 3.52 1.35 72.89 0.57 8.53 0 0 151 1.51665 13.14 3.45 1.76 72.48 0.6 8.38 0 0.17 152 1.52127 14.32 3.9 0.83 71.5 0 9.49 0 0 153 1.51779 13.64 3.65 0.65 73 0.06 8.93 0 0 154 1.5161 13.42 3.4 1.22 72.69 0.59 8.32 0 0 155 1.51694 12.86 3.58 1.31 72.61 0.61 8.79 0 0 156 1.51646 13.04 3.4 1.26 73.01 0.52 8.58 0 0 157 1.51655 13.41 3.39 1.28 72.64 0.52 8.65 0 0 158 1.52121 14.03 3.76 0.58 71.79 0.11 9.65 0 0 159 1.51776 13.53 3.41 1.52 72.04 0.58 8.79 0 0 160 1.51796 13.5 3.36 1.63 71.94 0.57 8.81 0 0.09 161 1.51832 13.33 3.34 1.54 72.14 0.56 8.99 0 0 162 1.51934 13.64 3.54 0.75 72.65 0.16 8.89 0.15 0.24 163 1.52211 14.19 3.78 0.91 71.36 0.23 9.14 0 0.37 164 1.51514 14.01 2.68 3.5 69.89 1.68 5.87 2.2 0 165 1.51915 12.73 1.85 1.86 72.69 0.6 10.09 0 0 166 1.52171 11.56 1.88 1.56 72.86 0.47 11.41 0 0 167 1.52151 11.03 1.71 1.56 73.44 0.58 11.62 0 0 168 1.51969 12.64 0 1.65 73.75 0.38 11.53 0 0 169 1.51666 12.86 0 1.83 73.88 0.97 10.17 0 0 170 1.51994 13.27 0 1.76 73.03 0.47 11.32 0 0 171 1.52369 13.44 0 1.58 72.22 0.32 12.24 0 0 172 1.51316 13.02 0 3.04 70.48 6.21 6.96 0 0 173 1.51321 13 0 3.02 70.7 6.21 6.93 0 0 174 1.52043 13.38 0 1.4 72.25 0.33 12.5 0 0 175 1.52058 12.85 1.61 2.17 72.18 0.76 9.7 0.24 0.51 176 1.52119 12.97 0.33 1.51 73.39 0.13 11.27 0 0.28 177 1.51905 14 2.39 1.56 72.37 0 9.57 0 0 178 1.51937 13.79 2.41 1.19 72.76 0 9.77 0 0 179 1.51829 14.46 2.24 1.62 72.38 0 9.26 0 0 180 1.51852 14.09 2.19 1.66 72.67 0 9.32 0 0 181 1.51299 14.4 1.74 1.54 74.55 0 7.59 0 0 182 1.51888 14.99 0.78 1.74 72.5 0 9.95 0 0 183 1.51916 14.15 0 2.09 72.74 0 10.88 0 0 184 1.51969 14.56 0 0.56 73.48 0 11.22 0 0 185 1.51115 17.38 0 0.34 75.41 0 6.65 0 0 186 1.51131 13.69 3.2 1.81 72.81 1.76 5.43 1.19 0 187 1.51838 14.32 3.26 2.22 71.25 1.46 5.79 1.63 0 188 1.52315 13.44 3.34 1.23 72.38 0.6 8.83 0 0 189 1.52247 14.86 2.2 2.06 70.26 0.76 9.76 0 0 190 1.52365 15.79 1.83 1.31 70.43 0.31 8.61 1.68 0 191 1.51613 13.88 1.78 1.79 73.1 0 8.67 0.76 0 192 1.51602 14.85 0 2.38 73.28 0 8.76 0.64 0.09 193 1.51623 14.2 0 2.79 73.46 0.04 9.04 0.4 0.09 194 1.51719 14.75 0 2 73.02 0 8.53 1.59 0.08 195 1.51683 14.56 0 1.98 73.29 0 8.52 1.57 0.07 196 1.51545 14.14 0 2.68 73.39 0.08 9.07 0.61 0.05 197 1.51556 13.87 0 2.54 73.23 0.14 9.41 0.81 0.01 198 1.51727 14.7 0 2.34 73.28 0 8.95 0.66 0 199 1.51531 14.38 0 2.66 73.1 0.04 9.08 0.64 0 200 1.51609 15.01 0 2.51 73.05 0.05 8.83 0.53 0 201 1.51508 15.15 0 2.25 73.5 0 8.34 0.63 0 202 1.51653 11.95 0 1.19 75.18 2.7 8.93 0 0 203 1.51514 14.85 0 2.42 73.72 0 8.39 0.56 0 204 1.51658 14.8 0 1.99 73.11 0 8.28 1.71 0 205 1.51617 14.95 0 2.27 73.3 0 8.71 0.67 0 206 1.51732 14.95 0 1.8 72.99 0 8.61 1.55 0 207 1.51645 14.94 0 1.87 73.11 0 8.67 1.38 0 208 1.51831 14.39 0 1.82 72.86 1.41 6.47 2.88 0 209 1.5164 14.37 0 2.74 72.85 0 9.45 0.54 0 210 1.51623 14.14 0 2.88 72.61 0.08 9.18 1.06 0 211 1.51685 14.92 0 1.99 73.06 0 8.4 1.59 0 212 1.52065 14.36 0 2.02 73.42 0 8.44 1.64 0 213 1.51651 14.38 0 1.94 73.61 0 8.48 1.57 0 214 1.51711 14.23 0 2.08 73.36 0 8.62 1.67 0 Kita dapat membuat fungsi untuk menampilkan masing -masing cluster dalam bentuk table. def show_cluster ( data , k ): cluster = {} for i in range ( k ): cluster [ 'Cluster ' + str ( i )] = data [ data [ \"Cluster\" ] . isin ([ i ])] . iloc [:, 0 ] . values dframe = pd . DataFrame . from_dict ( cluster , orient = 'index' ) dframe = dframe . transpose () dframe = dframe . fillna ( \"\" ) return dframe . style . hide_index () Kita dapat menggunakan KMeans yang merupakan library dari sklearn untuk melakukan clustering pada data numerik. dalam contoh ini digunakan k=5 untuk mengelompokkan menjadi 5 cluster. dari hasil proses clustering yang dilakukan, hasilnya dapat digabungkan dengan data yang telah ada dengan menambahkan attribut Cluster agar setiap baris data memiliki clusternya masing-msaing. from sklearn.cluster import KMeans k = 5 data_set = df . iloc [:, 1 :] . values df_dummy = pd . get_dummy ( df ) data_set = df_dummy . reset_index () . values kmeans = KMeans ( n_clusters = k ) cluster = kmeans . fit ( data_set ) data [ 'Cluster' ] = cluster . labels_ show_cluster ( data , k ) kita dapat menggunakan fungsi show_cluster() yang telah dibuat sebelumnya. dari fungsi tersebut kita dapat menampilkan cluster-cluster dan ID dari anggota cluster tersebut. Cluster 0 Cluster 1 Cluster 2 Cluster 3 Cluster 4 2 106 169 1 164 3 107 181 18 172 4 108 182 19 173 5 109 185 22 186 6 110 191 37 187 7 111 192 39 8 112 193 40 9 113 194 44 10 131 195 46 11 132 196 48 12 166 197 49 13 167 198 50 14 168 199 51 15 170 200 62 16 171 201 63 17 174 202 64 20 176 203 65 21 183 204 66 23 184 205 67 24 206 68 25 207 69 26 208 70 27 209 104 28 210 105 29 211 128 30 212 129 31 213 130 32 214 152 33 158 34 163 35 165 36 175 38 177 41 178 42 179 43 180 45 189 47 190 52 53 54 55 56 57 58 59 60 61 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 114 115 116 117 118 119 120 121 122 123 124 125 126 127 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 153 154 155 156 157 159 160 161 162 188 Hasil dari clustering tersebut dapat kita visualisasikan dalam bentuk plot dengan menggunakan library matpotlib. import matplotlib.pyplot as plt from sklearn.decomposition import PCA pca = PCA ( 2 ) plot_columns = pca . fit_transform ( df_dummy . iloc [:, 0 : 10 ]) plt . title ( \"Hasil Klustering K-Means\" ) plt . scatter ( x = plot_columns [:, 1 ], y = plot_columns [:, 0 ], c = data [ \"Cluster\" ], s = 30 ) plt . show () Maka akan menampilkan plot scatter tersebut dengan warna berbeda dari masing-masing cluster. K-Modes \u00b6 Pada contoh implementasi K-Modes kita dapat menggunakan data yang dapat di unduh pada link ini . data tersebut dapat kita visualisasikan dalam bentuk data frame . import pandas as pd data = pd . read_csv ( 'data_balloons.csv' , delimiter = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Setelah di load data tersebut akan tampil seperti berikut: ID color size act age inflated 1 YELLOW SMALL STRETCH ADULT T 2 YELLOW SMALL STRETCH ADULT T 3 YELLOW SMALL STRETCH ADULT T 4 YELLOW SMALL STRETCH ADULT T 5 YELLOW SMALL STRETCH ADULT T 6 YELLOW SMALL STRETCH ADULT T 7 YELLOW SMALL STRETCH ADULT T 8 YELLOW SMALL STRETCH ADULT T 9 YELLOW SMALL STRETCH ADULT T 10 YELLOW SMALL STRETCH ADULT T 11 YELLOW SMALL STRETCH CHILD F 12 YELLOW SMALL STRETCH CHILD F 13 YELLOW SMALL STRETCH CHILD F 14 YELLOW SMALL STRETCH CHILD F 15 YELLOW SMALL STRETCH CHILD F 16 YELLOW SMALL DIP ADULT F 17 YELLOW SMALL DIP ADULT F 18 YELLOW SMALL DIP ADULT F 19 YELLOW SMALL DIP ADULT F 20 YELLOW SMALL DIP ADULT F 21 YELLOW SMALL DIP CHILD F 22 YELLOW SMALL DIP CHILD F 23 YELLOW SMALL DIP CHILD F 24 YELLOW SMALL DIP CHILD F 25 YELLOW SMALL DIP CHILD F 26 YELLOW LARGE STRETCH ADULT T 27 YELLOW LARGE STRETCH ADULT T 28 YELLOW LARGE STRETCH ADULT T 29 YELLOW LARGE STRETCH ADULT T 30 YELLOW LARGE STRETCH ADULT T 31 YELLOW LARGE STRETCH ADULT T 32 YELLOW LARGE STRETCH ADULT T 33 YELLOW LARGE STRETCH ADULT T 34 YELLOW LARGE STRETCH ADULT T 35 YELLOW LARGE STRETCH ADULT T 36 YELLOW LARGE STRETCH CHILD F 37 YELLOW LARGE STRETCH CHILD F 38 YELLOW LARGE STRETCH CHILD F 39 YELLOW LARGE STRETCH CHILD F 40 YELLOW LARGE STRETCH CHILD F 41 YELLOW LARGE DIP ADULT F 42 YELLOW LARGE DIP ADULT F 43 YELLOW LARGE DIP ADULT F 44 YELLOW LARGE DIP ADULT F 45 YELLOW LARGE DIP ADULT F 46 YELLOW LARGE DIP CHILD F 47 YELLOW LARGE DIP CHILD F 48 YELLOW LARGE DIP CHILD F 49 YELLOW LARGE DIP CHILD F 50 YELLOW LARGE DIP CHILD F 51 PURPLE SMALL STRETCH ADULT T 52 PURPLE SMALL STRETCH ADULT T 53 PURPLE SMALL STRETCH ADULT T 54 PURPLE SMALL STRETCH ADULT T 55 PURPLE SMALL STRETCH ADULT T 56 PURPLE SMALL STRETCH ADULT T 57 PURPLE SMALL STRETCH ADULT T 58 PURPLE SMALL STRETCH ADULT T 59 PURPLE SMALL STRETCH ADULT T 60 PURPLE SMALL STRETCH ADULT T 61 PURPLE SMALL STRETCH CHILD F 62 PURPLE SMALL STRETCH CHILD F 63 PURPLE SMALL STRETCH CHILD F 64 PURPLE SMALL STRETCH CHILD F 65 PURPLE SMALL STRETCH CHILD F 66 PURPLE SMALL DIP ADULT F 67 PURPLE SMALL DIP ADULT F 68 PURPLE SMALL DIP ADULT F 69 PURPLE SMALL DIP ADULT F 70 PURPLE SMALL DIP ADULT F 71 PURPLE SMALL DIP CHILD F 72 PURPLE SMALL DIP CHILD F 73 PURPLE SMALL DIP CHILD F 74 PURPLE SMALL DIP CHILD F 75 PURPLE SMALL DIP CHILD F 76 PURPLE LARGE STRETCH ADULT T 77 PURPLE LARGE STRETCH ADULT T 78 PURPLE LARGE STRETCH ADULT T 79 PURPLE LARGE STRETCH ADULT T 80 PURPLE LARGE STRETCH ADULT T 81 PURPLE LARGE STRETCH ADULT T 82 PURPLE LARGE STRETCH ADULT T 83 PURPLE LARGE STRETCH ADULT T 84 PURPLE LARGE STRETCH ADULT T 85 PURPLE LARGE STRETCH ADULT T 86 PURPLE LARGE STRETCH CHILD F 87 PURPLE LARGE STRETCH CHILD F 88 PURPLE LARGE STRETCH CHILD F 89 PURPLE LARGE STRETCH CHILD F 90 PURPLE LARGE STRETCH CHILD F 91 PURPLE LARGE DIP ADULT F 92 PURPLE LARGE DIP ADULT F 93 PURPLE LARGE DIP ADULT F 94 PURPLE LARGE DIP ADULT F 95 PURPLE LARGE DIP ADULT F 96 PURPLE LARGE DIP CHILD F 97 PURPLE LARGE DIP CHILD F 98 PURPLE LARGE DIP CHILD F 99 PURPLE LARGE DIP CHILD F 100 PURPLE LARGE DIP CHILD F kita dapat menggunakan KModes yang merupakan library dari kmodes untuk melakukan clustering. data kategorikal dalam contoh ini digunakan k=3 untuk mengelompokkan menjadi 3 cluster. dari hasil proses clustering yang dilakukan, hasilnya dapat digabungkan dengan data yang telah ada dengan menambahkan attribut Cluster agar setiap baris data memiliki clusternya masing-msaing. from kmodes.kmodes import KModes k = 3 df_dummy = pd . get_dummies ( df ) data_set = df_dummy . reset_index () . values kmodes_cao = KModes ( n_clusters = k , init = 'Cao' , verbose = 1 ) cluster = kmodes_cao . fit ( data_set ) data [ 'Cluster' ] = cluster . labels_ show_cluster ( data , k ) kita dapat menggunakan fungsi show_cluster() yang telah dibuat sebelumnya. dari fungsi tersebut kita dapat menampilkan cluster-cluster dan ID dari anggota cluster tersebut. Cluster 0 Cluster 1 Cluster 2 1 41 11 2 42 12 3 43 13 4 44 14 5 45 15 6 46 21 7 47 22 8 48 23 9 49 24 10 50 25 16 66 36 17 67 37 18 68 38 19 69 39 20 70 40 26 71 61 27 72 62 28 73 63 29 74 64 30 75 65 31 86 32 87 33 88 34 89 35 90 51 91 52 92 53 93 54 94 55 95 56 96 57 97 58 98 59 99 60 100 76 77 78 79 80 81 82 83 84 85 Hasil dari clustering tersebut dapat kita visualisasikan dalam bentuk plot dengan menggunakan library matpotlib. import matplotlib.pyplot as plt from sklearn.decomposition import PCA pca = PCA ( 2 ) plot_columns = pca . fit_transform ( df_dummy . iloc [:, 0 : 6 ]) plt . title ( \"Hasil Klustering K-Modes\" ) plt . scatter ( x = plot_columns [:, 1 ], y = plot_columns [:, 0 ], c = df_dummy [ \"Cluster\" ], s = 30 ) plt . show () Maka akan menampilkan plot scatter tersebut dengan warna berbeda dari masing-masing cluster. K-Prototype \u00b6 Pada implementasi K-Prototype, kita dapat menggunakan data yang dapat diunduh di link ini , data tersebut dapat kita load untuk ditampilkan dalam bentuk data frame . import pandas as pd data = pd . read_csv ( 'tae_data.csv' , delimiter = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Setelah di load data tersebut akan tampil seperti berikut: ID Whether TA Course instructor Course Summer Class size Class attribute 1 english speaker 23 3 summer 19 high 2 non es 15 3 summer 17 high 3 english speaker 23 3 regular 49 high 4 english speaker 5 2 regular 33 high 5 non es 7 11 regular 55 high 6 non es 23 3 summer 20 high 7 non es 9 5 regular 19 high 8 non es 10 3 regular 27 high 9 english speaker 22 3 summer 58 high 10 non es 15 3 summer 20 high 11 non es 10 22 regular 9 high 12 non es 13 1 regular 30 high 13 non es 18 21 regular 29 high 14 non es 6 17 regular 39 high 15 non es 6 17 regular 42 medium 16 non es 6 17 regular 43 medium 17 non es 7 11 regular 10 medium 18 non es 22 3 regular 46 medium 19 non es 13 3 summer 10 medium 20 non es 7 25 regular 42 medium 21 non es 25 7 regular 27 medium 22 non es 25 7 regular 23 medium 23 non es 2 9 regular 31 medium 24 non es 1 15 summer 22 medium 25 non es 15 13 regular 37 medium 26 non es 7 11 regular 13 medium 27 non es 8 3 regular 24 medium 28 non es 14 15 regular 38 medium 29 non es 21 2 regular 42 low 30 non es 22 3 regular 28 low 31 non es 11 1 regular 51 low 32 non es 18 5 regular 19 low 33 non es 13 1 regular 31 low 34 english speaker 13 3 summer 13 low 35 non es 5 2 regular 37 low 36 non es 16 8 regular 36 low 37 non es 4 16 regular 21 low 38 non es 5 2 regular 48 low 39 non es 14 15 regular 38 low 40 english speaker 23 3 summer 19 high 41 non es 15 3 summer 17 high 42 english speaker 23 3 regular 49 high 43 english speaker 5 2 regular 33 high 44 non es 7 11 regular 55 high 45 non es 23 3 summer 20 high 46 non es 9 5 regular 19 high 47 non es 10 3 regular 27 high 48 english speaker 22 3 regular 58 high 49 non es 15 3 summer 20 high 50 non es 10 22 regular 9 high 51 non es 13 1 regular 30 high 52 non es 18 21 regular 29 high 53 non es 6 17 regular 39 high 54 non es 6 17 regular 42 medium 55 non es 6 17 regular 43 medium 56 non es 7 11 regular 10 medium 57 non es 22 3 regular 46 medium 58 non es 13 3 summer 10 medium 59 non es 7 25 regular 42 medium 60 non es 25 7 regular 27 medium 61 non es 25 7 regular 23 medium 62 non es 2 9 regular 31 medium 63 non es 1 15 summer 22 medium 64 non es 15 13 regular 37 medium 65 non es 7 11 regular 13 medium 66 non es 8 3 regular 24 medium 67 non es 14 15 regular 38 medium 68 non es 21 2 regular 42 low 69 non es 22 3 regular 28 low 70 non es 11 1 regular 51 low 71 non es 18 5 regular 19 low 72 non es 13 1 regular 31 low 73 english speaker 13 3 summer 13 low 74 non es 5 2 regular 37 low 75 non es 16 8 regular 36 low 76 non es 4 16 regular 21 low 77 non es 5 2 regular 48 low 78 non es 14 15 regular 38 low 79 english speaker 23 3 summer 25 high 80 english speaker 13 3 summer 17 high 81 non es 16 19 regular 11 high 82 non es 9 2 regular 39 high 83 non es 13 3 summer 11 high 84 non es 18 21 regular 19 high 85 english speaker 22 3 regular 45 high 86 non es 7 11 summer 20 high 87 non es 23 3 summer 20 high 88 english speaker 23 3 summer 20 high 89 english speaker 23 3 regular 38 high 90 non es 14 22 regular 17 high 91 english speaker 17 17 regular 19 high 92 non es 9 5 regular 24 high 93 non es 18 25 regular 25 high 94 english speaker 17 17 regular 31 high 95 non es 1 15 regular 31 high 96 non es 1 8 regular 18 medium 97 english speaker 11 16 regular 22 medium 98 english speaker 22 13 regular 27 medium 99 non es 9 2 regular 14 medium 100 non es 13 1 regular 20 medium 101 english speaker 6 17 regular 35 medium 102 non es 23 3 summer 20 medium 103 english speaker 23 3 summer 20 medium 104 non es 6 17 regular 37 medium 105 english speaker 22 3 regular 15 medium 106 non es 20 2 regular 25 medium 107 non es 23 3 regular 10 medium 108 non es 20 2 regular 14 low 109 english speaker 23 3 regular 38 low 110 non es 13 1 regular 29 low 111 non es 10 3 regular 19 low 112 non es 7 11 regular 30 low 113 english speaker 14 15 regular 32 low 114 non es 8 3 regular 27 low 115 non es 12 7 regular 34 low 116 non es 8 7 regular 23 low 117 non es 15 1 regular 66 low 118 non es 23 3 regular 12 low 119 non es 2 9 regular 29 low 120 non es 15 1 regular 19 low 121 non es 20 2 regular 3 low 122 non es 13 14 regular 17 high 123 non es 9 6 regular 7 high 124 english speaker 10 3 regular 21 high 125 non es 14 15 regular 36 high 126 english speaker 13 1 regular 54 high 127 english speaker 8 3 regular 29 high 128 non es 20 2 regular 45 high 129 non es 22 1 regular 11 medium 130 non es 18 12 regular 16 medium 131 non es 20 15 regular 18 medium 132 english speaker 17 18 regular 44 medium 133 non es 14 23 regular 17 medium 134 non es 24 26 regular 21 medium 135 non es 9 24 regular 20 medium 136 non es 12 8 regular 24 medium 137 non es 9 6 regular 5 medium 138 non es 22 1 regular 42 medium 139 non es 7 11 regular 30 low 140 non es 10 3 regular 19 low 141 non es 23 3 regular 11 low 142 non es 17 18 regular 29 low 143 non es 16 20 regular 15 low 144 non es 3 2 regular 37 low 145 non es 19 4 regular 10 low 146 non es 23 3 regular 24 low 147 non es 3 2 regular 26 low 148 non es 10 3 regular 12 low 149 english speaker 18 7 regular 48 low 150 non es 22 1 regular 51 low 151 non es 2 10 regular 27 low Kita dapat menggunakan Kprototype yang merupakan library dari kmodes untuk melakukan clustering data campuran dari numerik dan kategorikal. dalam contoh ini digunakan k=5 untuk mengelompokkan menjadi 5 cluster. from kmodes.kprototypes import KPrototypes k = 5 df_dummy = pd . get_dummies ( df ) data_set = df_dummy . reset_index () . values kproto = KPrototypes ( n_clusters = k , init = 'Cao' , verbose = 2 ) cluster = kproto . fit ( data_set , categorical = [ 0 , 1 , 2 , 3 , 5 ]) data [ 'Cluster' ] = cluster . labels_ show_cluster ( data , k ) kita dapat menggunakan fungsi show_cluster() yang telah dibuat sebelumnya. dari fungsi tersebut kita dapat menampilkan cluster-cluster dan ID dari anggota cluster tersebut. Cluster 0 Cluster 1 Cluster 2 Cluster 3 Cluster 4 4 1 3 14 11 8 2 5 15 17 12 6 9 16 19 13 7 18 20 26 21 10 31 25 34 23 22 38 28 50 30 24 42 29 56 33 27 44 35 58 43 32 48 36 65 47 37 57 39 73 51 40 70 53 81 52 41 77 54 83 60 45 85 55 99 62 46 117 59 105 69 49 126 64 107 72 61 149 67 108 93 63 150 68 118 94 66 74 121 95 71 75 123 98 76 78 129 106 79 82 137 110 80 89 141 112 84 101 143 113 86 104 145 114 87 109 148 115 88 125 119 90 128 127 91 132 139 92 138 142 96 144 147 97 151 100 102 103 111 116 120 122 124 130 131 133 134 135 136 140 146 Hasil dari clustering tersebut dapat kita visualisasikan dalam bentuk plot dengan menggunakan library matpotlib. import matplotlib.pyplot as plt from sklearn.decomposition import PCA pca = PCA ( 2 ) plot_columns = pca . fit_transform ( df_dummy . iloc [:, 1 :]) plt . title ( \"Hasil Klustering K-Prototype\" ) plt . scatter ( x = plot_columns [:, 1 ], y = plot_columns [:, 0 ], c = df_dummy [ \"Cluster\" ], s = 30 ) plt . show () Maka akan menampilkan plot scatter tersebut dengan warna berbeda dari setiap cluster.","title":"Tugas 5"},{"location":"pendat/clustering/#implementasi-metode-k-means-k-modes-dan-k-prototype-dengan-python","text":"","title":"Implementasi Metode K-Means, K-Modes, dan K-Prototype dengan python"},{"location":"pendat/clustering/#clustering","text":"Clustering adalah suatu metode untuk mengelompokkan data berdasarkan ukuran kemiripan data tersebut. Pada metode clustering pengelompokan datanya tidak harus sama, akan tetapi hanya kemiripan data tersebut yang didapatkan berdasarkan pada kedekatan suatu karakteristik sample yang, ada dengan menghitung jarak salah satunya dengan menggunakan rumus ecluidian distance. pada dasarnya, metode clustering mengoptimumkan pusat cluster(centroid) untuk melakukan pengelompokan. Pada prinsipnya metode clustering sangat bermanfaat sekali dalam bidang kelimuan, seperti Identifikasi obyek (Recoginition) Metode clustering biasa dipakai dalam bidang Image Processing, Computer Vision, Robot Vision, dan lain-lain. Decission Support System dan Data Mining Dalam hal ini metode clusting biasa digunakan dalam Segmentasi Pasar, pemetaan wilayah, Manajement marketing, dan lain-lain. dalam hal ini metode clusting biasa digunakan dalam Segmentasi Pasar, pemetaan wilayah, Manajement marketing, dan lain-lain. Salah satu algoritma clustring yang banyak dipakai adalah K-Means clustering. Hal ini memungkinkan untuk mengelompokkan data sesuai dengan kesamaan yang ada di antara mereka dalam k cluster, diberikan sebagai input ke algoritma.","title":"Clustering"},{"location":"pendat/clustering/#k-means-clustering","text":"K-Means adalah metode pengelompokan data atau salah satu metode data mining dengan melakukan proses pemodelan yang unsupervised ( yang tidak terawasi ) dan merupakan salah satu metode clustering dengan sistem partisi. Dalam proses pengelompokan data, terdapat 2 jenis data yang digunakan, yaitu Hierarchical dan Non-Hierarchical . Metode K-Means clustering salah satu metode clustering untuk mengelompokkan data yang non-herarchical. Metode K-Means akan berusaha untuk mengelompokkan data ke dalam beberapa cluster, dari setiap cluster memiliki karakteristik yang mirip antara dari yang satu dengan data yang lainnya dan miliki karakteristik yang berbeda dengan data pada cluster yang lain. Secara umum, K-Means clustering melakukan pengelompokan dengan algoritma seperti berikut: Tentukan jumlah k (k=cluster) Alokasikan data awal ke dalam cluster secara random Hitung centroid/rata-rata dari masing-masing cluster yang telah ditentukan. Hitung jarak masing-masing data dengan centroid, dan alokasikan data pada cluster terdekat. Ulangi langka 3 dan 4, hingga nilai dari centroid tidak berubah lagi.","title":"K-Means Clustering"},{"location":"pendat/clustering/#k-modes-clustering","text":"K-Modes clustering adalah turunan dari metode K-Means clustering. Pada metode K-Means hanya bekerja pada data yang nilainya numeric dan tidak akan bekerja jika data yang akan cluster adalah nilainya kategorikal. K-Modes berkerja mirip seperti K-Means, akan tetapi metode ini di khususkan untuk mengelompokkan data yang nilainya adalah kategorikal. K-Modes berkerja dengan menggunakan metode berbasis frekuensi untuk memperbarui modus dalam proses pengelompokan dan mengkuantifikasi total ketidakcocokan antara dua objek. semakin kecil jumlah ini, semakin mirip kedua objek.","title":"K-Modes Clustering"},{"location":"pendat/clustering/#k-prototype-clustering","text":"K-Prototype clustering merupakan metode clustring gabungan dari K-Means dan K-Modes. Metode ini digunakan untuk mengelompokkan data yang memiliki attribut numerik dan kategorikal.","title":"K-Prototype Clustering"},{"location":"pendat/clustering/#implementasi-dengan-python","text":"","title":"Implementasi dengan Python"},{"location":"pendat/clustering/#k-means","text":"Pada implementasi K-Means, kita dapat menggunakan data glass yang dapat diunduh di link ini , data tersebut dapat kita tampilkan dalam bentuk data frame. Pertama kali yang dapat kita lakukan adalah memuat data tersebut menggunaka libarary pandas. import pandas as pd data = pd . read_csv ( 'glass.csv' , delimiter = ';' , decimal = ',' ) df = pd . DataFrame ( data ) df . style . hide_index () Dari data tersebut akan tampil seperti berikut: ID refractive index Sodium Magnesium Aluminum Silicon Potassium Calcium Barium Iron 1 1.52101 13.64 4.49 1.1 71.78 0.06 8.75 0 0.001 2 1.51761 13.89 3.6 1.36 72.73 0.48 7.83 0 0 3 1.51618 13.53 3.55 1.54 72.99 0.39 7.78 0 0 4 1.51766 13.21 3.69 1.29 72.61 0.57 8.22 0 0 5 1.51742 13.27 3.62 1.24 73.08 0.55 8.07 0 0 6 1.51596 12.79 3.61 1.62 72.97 0.64 8.07 0 0.26 7 1.51743 13.3 3.6 1.14 73.09 0.58 8.17 0 0 8 1.51756 13.15 3.61 1.05 73.24 0.57 8.24 0 0 9 1.51918 14.04 3.58 1.37 72.08 0.56 8.3 0 0 10 1.51755 13 3.6 1.36 72.99 0.57 8.4 0 0.11 11 1.51571 12.72 3.46 1.56 73.2 0.67 8.09 0 0.24 12 1.51763 12.8 3.66 1.27 73.01 0.6 8.56 0 0 13 1.51589 12.88 3.43 1.4 73.28 0.69 8.05 0 0.24 14 1.51748 12.86 3.56 1.27 73.21 0.54 8.38 0 0.17 15 1.51763 12.61 3.59 1.31 73.29 0.58 8.5 0 0 16 1.51761 12.81 3.54 1.23 73.24 0.58 8.39 0 0 17 1.51784 12.68 3.67 1.16 73.11 0.61 8.7 0 0 18 1.52196 14.36 3.85 0.89 71.36 0.15 9.15 0 0 19 1.51911 13.9 3.73 1.18 72.12 0.06 8.89 0 0 20 1.51735 13.02 3.54 1.69 72.73 0.54 8.44 0 0.07 21 1.5175 12.82 3.55 1.49 72.75 0.54 8.52 0 0.19 22 1.51966 14.77 3.75 0.29 72.02 0.03 9 0 0 23 1.51736 12.78 3.62 1.29 72.79 0.59 8.7 0 0 24 1.51751 12.81 3.57 1.35 73.02 0.62 8.59 0 0 25 1.5172 13.38 3.5 1.15 72.85 0.5 8.43 0 0 26 1.51764 12.98 3.54 1.21 73 0.65 8.53 0 0 27 1.51793 13.21 3.48 1.41 72.64 0.59 8.43 0 0 28 1.51721 12.87 3.48 1.33 73.04 0.56 8.43 0 0 29 1.51768 12.56 3.52 1.43 73.15 0.57 8.54 0 0 30 1.51784 13.08 3.49 1.28 72.86 0.6 8.49 0 0 31 1.51768 12.65 3.56 1.3 73.08 0.61 8.69 0 0.14 32 1.51747 12.84 3.5 1.14 73.27 0.56 8.55 0 0 33 1.51775 12.85 3.48 1.23 72.97 0.61 8.56 0.09 0.22 34 1.51753 12.57 3.47 1.38 73.39 0.6 8.55 0 0.06 35 1.51783 12.69 3.54 1.34 72.95 0.57 8.75 0 0 36 1.51567 13.29 3.45 1.21 72.74 0.56 8.57 0 0 37 1.51909 13.89 3.53 1.32 71.81 0.51 8.78 0.11 0 38 1.51797 12.74 3.48 1.35 72.96 0.64 8.68 0 0 39 1.52213 14.21 3.82 0.47 71.77 0.11 9.57 0 0 40 1.52213 14.21 3.82 0.47 71.77 0.11 9.57 0 0 41 1.51793 12.79 3.5 1.12 73.03 0.64 8.77 0 0 42 1.51755 12.71 3.42 1.2 73.2 0.59 8.64 0 0 43 1.51779 13.21 3.39 1.33 72.76 0.59 8.59 0 0 44 1.5221 13.73 3.84 0.72 71.76 0.17 9.74 0 0 45 1.51786 12.73 3.43 1.19 72.95 0.62 8.76 0 0.3 46 1.519 13.49 3.48 1.35 71.95 0.55 9 0 0 47 1.51869 13.19 3.37 1.18 72.72 0.57 8.83 0 0.16 48 1.52667 13.99 3.7 0.71 71.57 0.02 9.82 0 0.1 49 1.52223 13.21 3.77 0.79 71.99 0.13 10.02 0 0 50 1.51898 13.58 3.35 1.23 72.08 0.59 8.91 0 0 51 1.5232 13.72 3.72 0.51 71.75 0.09 10.06 0 0.16 52 1.51926 13.2 3.33 1.28 72.36 0.6 9.14 0 0.11 53 1.51808 13.43 2.87 1.19 72.84 0.55 9.03 0 0 54 1.51837 13.14 2.84 1.28 72.85 0.55 9.07 0 0 55 1.51778 13.21 2.81 1.29 72.98 0.51 9.02 0 0.09 56 1.51769 12.45 2.71 1.29 73.7 0.56 9.06 0 0.24 57 1.51215 12.99 3.47 1.12 72.98 0.62 8.35 0 0.31 58 1.51824 12.87 3.48 1.29 72.95 0.6 8.43 0 0 59 1.51754 13.48 3.74 1.17 72.99 0.59 8.03 0 0 60 1.51754 13.39 3.66 1.19 72.79 0.57 8.27 0 0.11 61 1.51905 13.6 3.62 1.11 72.64 0.14 8.76 0 0 62 1.51977 13.81 3.58 1.32 71.72 0.12 8.67 0.69 0 63 1.52172 13.51 3.86 0.88 71.79 0.23 9.54 0 0.11 64 1.52227 14.17 3.81 0.78 71.35 0 9.69 0 0 65 1.52172 13.48 3.74 0.9 72.01 0.18 9.61 0 0.07 66 1.52099 13.69 3.59 1.12 71.96 0.09 9.4 0 0 67 1.52152 13.05 3.65 0.87 72.22 0.19 9.85 0 0.17 68 1.52152 13.05 3.65 0.87 72.32 0.19 9.85 0 0.17 69 1.52152 13.12 3.58 0.9 72.2 0.23 9.82 0 0.16 70 1.523 13.31 3.58 0.82 71.99 0.12 10.17 0 0.03 71 1.51574 14.86 3.67 1.74 71.87 0.16 7.36 0 0.12 72 1.51848 13.64 3.87 1.27 71.96 0.54 8.32 0 0.32 73 1.51593 13.09 3.59 1.52 73.1 0.67 7.83 0 0 74 1.51631 13.34 3.57 1.57 72.87 0.61 7.89 0 0 75 1.51596 13.02 3.56 1.54 73.11 0.72 7.9 0 0 76 1.5159 13.02 3.58 1.51 73.12 0.69 7.96 0 0 77 1.51645 13.44 3.61 1.54 72.39 0.66 8.03 0 0 78 1.51627 13 3.58 1.54 72.83 0.61 8.04 0 0 79 1.51613 13.92 3.52 1.25 72.88 0.37 7.94 0 0.14 80 1.5159 12.82 3.52 1.9 72.86 0.69 7.97 0 0 81 1.51592 12.86 3.52 2.12 72.66 0.69 7.97 0 0 82 1.51593 13.25 3.45 1.43 73.17 0.61 7.86 0 0 83 1.51646 13.41 3.55 1.25 72.81 0.68 8.1 0 0 84 1.51594 13.09 3.52 1.55 72.87 0.68 8.05 0 0.09 85 1.51409 14.25 3.09 2.08 72.28 1.1 7.08 0 0 86 1.51625 13.36 3.58 1.49 72.72 0.45 8.21 0 0 87 1.51569 13.24 3.49 1.47 73.25 0.38 8.03 0 0 88 1.51645 13.4 3.49 1.52 72.65 0.67 8.08 0 0.1 89 1.51618 13.01 3.5 1.48 72.89 0.6 8.12 0 0 90 1.5164 12.55 3.48 1.87 73.23 0.63 8.08 0 0.09 91 1.51841 12.93 3.74 1.11 72.28 0.64 8.96 0 0.22 92 1.51605 12.9 3.44 1.45 73.06 0.44 8.27 0 0 93 1.51588 13.12 3.41 1.58 73.26 0.07 8.39 0 0.19 94 1.5159 13.24 3.34 1.47 73.1 0.39 8.22 0 0 95 1.51629 12.71 3.33 1.49 73.28 0.67 8.24 0 0 96 1.5186 13.36 3.43 1.43 72.26 0.51 8.6 0 0 97 1.51841 13.02 3.62 1.06 72.34 0.64 9.13 0 0.15 98 1.51743 12.2 3.25 1.16 73.55 0.62 8.9 0 0.24 99 1.51689 12.67 2.88 1.71 73.21 0.73 8.54 0 0 100 1.51811 12.96 2.96 1.43 72.92 0.6 8.79 0.14 0 101 1.51655 12.75 2.85 1.44 73.27 0.57 8.79 0.11 0.22 102 1.5173 12.35 2.72 1.63 72.87 0.7 9.23 0 0 103 1.5182 12.62 2.76 0.83 73.81 0.35 9.42 0 0.2 104 1.52725 13.8 3.15 0.66 70.57 0.08 11.64 0 0 105 1.5241 13.83 2.9 1.17 71.15 0.08 10.79 0 0 106 1.52475 11.45 0 1.88 72.19 0.81 13.24 0 0.34 107 1.53125 10.73 0 2.1 69.81 0.58 13.3 3.15 0.28 108 1.53393 12.3 0 1 70.16 0.12 16.19 0 0.24 109 1.52222 14.43 0 1 72.67 0.1 11.52 0 0.08 110 1.51818 13.72 0 0.56 74.45 0 10.99 0 0 111 1.52664 11.23 0 0.77 73.21 0 14.68 0 0 112 1.52739 11.02 0 0.75 73.08 0 14.96 0 0 113 1.52777 12.64 0 0.67 72.02 0.06 14.4 0 0 114 1.51892 13.46 3.83 1.26 72.55 0.57 8.21 0 0.14 115 1.51847 13.1 3.97 1.19 72.44 0.6 8.43 0 0 116 1.51846 13.41 3.89 1.33 72.38 0.51 8.28 0 0 117 1.51829 13.24 3.9 1.41 72.33 0.55 8.31 0 0.1 118 1.51708 13.72 3.68 1.81 72.06 0.64 7.88 0 0 119 1.51673 13.3 3.64 1.53 72.53 0.65 8.03 0 0.29 120 1.51652 13.56 3.57 1.47 72.45 0.64 7.96 0 0 121 1.51844 13.25 3.76 1.32 72.4 0.58 8.42 0 0 122 1.51663 12.93 3.54 1.62 72.96 0.64 8.03 0 0.21 123 1.51687 13.23 3.54 1.48 72.84 0.56 8.1 0 0 124 1.51707 13.48 3.48 1.71 72.52 0.62 7.99 0 0 125 1.52177 13.2 3.68 1.15 72.75 0.54 8.52 0 0 126 1.51872 12.93 3.66 1.56 72.51 0.58 8.55 0 0.12 127 1.51667 12.94 3.61 1.26 72.75 0.56 8.6 0 0 128 1.52081 13.78 2.28 1.43 71.99 0.49 9.85 0 0.17 129 1.52068 13.55 2.09 1.67 72.18 0.53 9.57 0.27 0.17 130 1.5202 13.98 1.35 1.63 71.76 0.39 10.56 0 0.18 131 1.52177 13.75 1.01 1.36 72.19 0.33 11.14 0 0 132 1.52614 13.7 0 1.36 71.24 0.19 13.44 0 0.1 133 1.51813 13.43 3.98 1.18 72.49 0.58 8.15 0 0 134 1.518 13.71 3.93 1.54 71.81 0.54 8.21 0 0.15 135 1.51811 13.33 3.85 1.25 72.78 0.52 8.12 0 0 136 1.51789 13.19 3.9 1.3 72.33 0.55 8.44 0 0.28 137 1.51806 13 3.8 1.08 73.07 0.56 8.38 0 0.12 138 1.51711 12.89 3.62 1.57 72.96 0.61 8.11 0 0 139 1.51674 12.79 3.52 1.54 73.36 0.66 7.9 0 0 140 1.51674 12.87 3.56 1.64 73.14 0.65 7.99 0 0 141 1.5169 13.33 3.54 1.61 72.54 0.68 8.11 0 0 142 1.51851 13.2 3.63 1.07 72.83 0.57 8.41 0.09 0.17 143 1.51662 12.85 3.51 1.44 73.01 0.68 8.23 0.06 0.25 144 1.51709 13 3.47 1.79 72.72 0.66 8.18 0 0 145 1.5166 12.99 3.18 1.23 72.97 0.58 8.81 0 0.24 146 1.51839 12.85 3.67 1.24 72.57 0.62 8.68 0 0.35 147 1.51769 13.65 3.66 1.11 72.77 0.11 8.6 0 0 148 1.5161 13.33 3.53 1.34 72.67 0.56 8.33 0 0 149 1.5167 13.24 3.57 1.38 72.7 0.56 8.44 0 0.1 150 1.51643 12.16 3.52 1.35 72.89 0.57 8.53 0 0 151 1.51665 13.14 3.45 1.76 72.48 0.6 8.38 0 0.17 152 1.52127 14.32 3.9 0.83 71.5 0 9.49 0 0 153 1.51779 13.64 3.65 0.65 73 0.06 8.93 0 0 154 1.5161 13.42 3.4 1.22 72.69 0.59 8.32 0 0 155 1.51694 12.86 3.58 1.31 72.61 0.61 8.79 0 0 156 1.51646 13.04 3.4 1.26 73.01 0.52 8.58 0 0 157 1.51655 13.41 3.39 1.28 72.64 0.52 8.65 0 0 158 1.52121 14.03 3.76 0.58 71.79 0.11 9.65 0 0 159 1.51776 13.53 3.41 1.52 72.04 0.58 8.79 0 0 160 1.51796 13.5 3.36 1.63 71.94 0.57 8.81 0 0.09 161 1.51832 13.33 3.34 1.54 72.14 0.56 8.99 0 0 162 1.51934 13.64 3.54 0.75 72.65 0.16 8.89 0.15 0.24 163 1.52211 14.19 3.78 0.91 71.36 0.23 9.14 0 0.37 164 1.51514 14.01 2.68 3.5 69.89 1.68 5.87 2.2 0 165 1.51915 12.73 1.85 1.86 72.69 0.6 10.09 0 0 166 1.52171 11.56 1.88 1.56 72.86 0.47 11.41 0 0 167 1.52151 11.03 1.71 1.56 73.44 0.58 11.62 0 0 168 1.51969 12.64 0 1.65 73.75 0.38 11.53 0 0 169 1.51666 12.86 0 1.83 73.88 0.97 10.17 0 0 170 1.51994 13.27 0 1.76 73.03 0.47 11.32 0 0 171 1.52369 13.44 0 1.58 72.22 0.32 12.24 0 0 172 1.51316 13.02 0 3.04 70.48 6.21 6.96 0 0 173 1.51321 13 0 3.02 70.7 6.21 6.93 0 0 174 1.52043 13.38 0 1.4 72.25 0.33 12.5 0 0 175 1.52058 12.85 1.61 2.17 72.18 0.76 9.7 0.24 0.51 176 1.52119 12.97 0.33 1.51 73.39 0.13 11.27 0 0.28 177 1.51905 14 2.39 1.56 72.37 0 9.57 0 0 178 1.51937 13.79 2.41 1.19 72.76 0 9.77 0 0 179 1.51829 14.46 2.24 1.62 72.38 0 9.26 0 0 180 1.51852 14.09 2.19 1.66 72.67 0 9.32 0 0 181 1.51299 14.4 1.74 1.54 74.55 0 7.59 0 0 182 1.51888 14.99 0.78 1.74 72.5 0 9.95 0 0 183 1.51916 14.15 0 2.09 72.74 0 10.88 0 0 184 1.51969 14.56 0 0.56 73.48 0 11.22 0 0 185 1.51115 17.38 0 0.34 75.41 0 6.65 0 0 186 1.51131 13.69 3.2 1.81 72.81 1.76 5.43 1.19 0 187 1.51838 14.32 3.26 2.22 71.25 1.46 5.79 1.63 0 188 1.52315 13.44 3.34 1.23 72.38 0.6 8.83 0 0 189 1.52247 14.86 2.2 2.06 70.26 0.76 9.76 0 0 190 1.52365 15.79 1.83 1.31 70.43 0.31 8.61 1.68 0 191 1.51613 13.88 1.78 1.79 73.1 0 8.67 0.76 0 192 1.51602 14.85 0 2.38 73.28 0 8.76 0.64 0.09 193 1.51623 14.2 0 2.79 73.46 0.04 9.04 0.4 0.09 194 1.51719 14.75 0 2 73.02 0 8.53 1.59 0.08 195 1.51683 14.56 0 1.98 73.29 0 8.52 1.57 0.07 196 1.51545 14.14 0 2.68 73.39 0.08 9.07 0.61 0.05 197 1.51556 13.87 0 2.54 73.23 0.14 9.41 0.81 0.01 198 1.51727 14.7 0 2.34 73.28 0 8.95 0.66 0 199 1.51531 14.38 0 2.66 73.1 0.04 9.08 0.64 0 200 1.51609 15.01 0 2.51 73.05 0.05 8.83 0.53 0 201 1.51508 15.15 0 2.25 73.5 0 8.34 0.63 0 202 1.51653 11.95 0 1.19 75.18 2.7 8.93 0 0 203 1.51514 14.85 0 2.42 73.72 0 8.39 0.56 0 204 1.51658 14.8 0 1.99 73.11 0 8.28 1.71 0 205 1.51617 14.95 0 2.27 73.3 0 8.71 0.67 0 206 1.51732 14.95 0 1.8 72.99 0 8.61 1.55 0 207 1.51645 14.94 0 1.87 73.11 0 8.67 1.38 0 208 1.51831 14.39 0 1.82 72.86 1.41 6.47 2.88 0 209 1.5164 14.37 0 2.74 72.85 0 9.45 0.54 0 210 1.51623 14.14 0 2.88 72.61 0.08 9.18 1.06 0 211 1.51685 14.92 0 1.99 73.06 0 8.4 1.59 0 212 1.52065 14.36 0 2.02 73.42 0 8.44 1.64 0 213 1.51651 14.38 0 1.94 73.61 0 8.48 1.57 0 214 1.51711 14.23 0 2.08 73.36 0 8.62 1.67 0 Kita dapat membuat fungsi untuk menampilkan masing -masing cluster dalam bentuk table. def show_cluster ( data , k ): cluster = {} for i in range ( k ): cluster [ 'Cluster ' + str ( i )] = data [ data [ \"Cluster\" ] . isin ([ i ])] . iloc [:, 0 ] . values dframe = pd . DataFrame . from_dict ( cluster , orient = 'index' ) dframe = dframe . transpose () dframe = dframe . fillna ( \"\" ) return dframe . style . hide_index () Kita dapat menggunakan KMeans yang merupakan library dari sklearn untuk melakukan clustering pada data numerik. dalam contoh ini digunakan k=5 untuk mengelompokkan menjadi 5 cluster. dari hasil proses clustering yang dilakukan, hasilnya dapat digabungkan dengan data yang telah ada dengan menambahkan attribut Cluster agar setiap baris data memiliki clusternya masing-msaing. from sklearn.cluster import KMeans k = 5 data_set = df . iloc [:, 1 :] . values df_dummy = pd . get_dummy ( df ) data_set = df_dummy . reset_index () . values kmeans = KMeans ( n_clusters = k ) cluster = kmeans . fit ( data_set ) data [ 'Cluster' ] = cluster . labels_ show_cluster ( data , k ) kita dapat menggunakan fungsi show_cluster() yang telah dibuat sebelumnya. dari fungsi tersebut kita dapat menampilkan cluster-cluster dan ID dari anggota cluster tersebut. Cluster 0 Cluster 1 Cluster 2 Cluster 3 Cluster 4 2 106 169 1 164 3 107 181 18 172 4 108 182 19 173 5 109 185 22 186 6 110 191 37 187 7 111 192 39 8 112 193 40 9 113 194 44 10 131 195 46 11 132 196 48 12 166 197 49 13 167 198 50 14 168 199 51 15 170 200 62 16 171 201 63 17 174 202 64 20 176 203 65 21 183 204 66 23 184 205 67 24 206 68 25 207 69 26 208 70 27 209 104 28 210 105 29 211 128 30 212 129 31 213 130 32 214 152 33 158 34 163 35 165 36 175 38 177 41 178 42 179 43 180 45 189 47 190 52 53 54 55 56 57 58 59 60 61 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 114 115 116 117 118 119 120 121 122 123 124 125 126 127 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 153 154 155 156 157 159 160 161 162 188 Hasil dari clustering tersebut dapat kita visualisasikan dalam bentuk plot dengan menggunakan library matpotlib. import matplotlib.pyplot as plt from sklearn.decomposition import PCA pca = PCA ( 2 ) plot_columns = pca . fit_transform ( df_dummy . iloc [:, 0 : 10 ]) plt . title ( \"Hasil Klustering K-Means\" ) plt . scatter ( x = plot_columns [:, 1 ], y = plot_columns [:, 0 ], c = data [ \"Cluster\" ], s = 30 ) plt . show () Maka akan menampilkan plot scatter tersebut dengan warna berbeda dari masing-masing cluster.","title":"K-Means"},{"location":"pendat/clustering/#k-modes","text":"Pada contoh implementasi K-Modes kita dapat menggunakan data yang dapat di unduh pada link ini . data tersebut dapat kita visualisasikan dalam bentuk data frame . import pandas as pd data = pd . read_csv ( 'data_balloons.csv' , delimiter = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Setelah di load data tersebut akan tampil seperti berikut: ID color size act age inflated 1 YELLOW SMALL STRETCH ADULT T 2 YELLOW SMALL STRETCH ADULT T 3 YELLOW SMALL STRETCH ADULT T 4 YELLOW SMALL STRETCH ADULT T 5 YELLOW SMALL STRETCH ADULT T 6 YELLOW SMALL STRETCH ADULT T 7 YELLOW SMALL STRETCH ADULT T 8 YELLOW SMALL STRETCH ADULT T 9 YELLOW SMALL STRETCH ADULT T 10 YELLOW SMALL STRETCH ADULT T 11 YELLOW SMALL STRETCH CHILD F 12 YELLOW SMALL STRETCH CHILD F 13 YELLOW SMALL STRETCH CHILD F 14 YELLOW SMALL STRETCH CHILD F 15 YELLOW SMALL STRETCH CHILD F 16 YELLOW SMALL DIP ADULT F 17 YELLOW SMALL DIP ADULT F 18 YELLOW SMALL DIP ADULT F 19 YELLOW SMALL DIP ADULT F 20 YELLOW SMALL DIP ADULT F 21 YELLOW SMALL DIP CHILD F 22 YELLOW SMALL DIP CHILD F 23 YELLOW SMALL DIP CHILD F 24 YELLOW SMALL DIP CHILD F 25 YELLOW SMALL DIP CHILD F 26 YELLOW LARGE STRETCH ADULT T 27 YELLOW LARGE STRETCH ADULT T 28 YELLOW LARGE STRETCH ADULT T 29 YELLOW LARGE STRETCH ADULT T 30 YELLOW LARGE STRETCH ADULT T 31 YELLOW LARGE STRETCH ADULT T 32 YELLOW LARGE STRETCH ADULT T 33 YELLOW LARGE STRETCH ADULT T 34 YELLOW LARGE STRETCH ADULT T 35 YELLOW LARGE STRETCH ADULT T 36 YELLOW LARGE STRETCH CHILD F 37 YELLOW LARGE STRETCH CHILD F 38 YELLOW LARGE STRETCH CHILD F 39 YELLOW LARGE STRETCH CHILD F 40 YELLOW LARGE STRETCH CHILD F 41 YELLOW LARGE DIP ADULT F 42 YELLOW LARGE DIP ADULT F 43 YELLOW LARGE DIP ADULT F 44 YELLOW LARGE DIP ADULT F 45 YELLOW LARGE DIP ADULT F 46 YELLOW LARGE DIP CHILD F 47 YELLOW LARGE DIP CHILD F 48 YELLOW LARGE DIP CHILD F 49 YELLOW LARGE DIP CHILD F 50 YELLOW LARGE DIP CHILD F 51 PURPLE SMALL STRETCH ADULT T 52 PURPLE SMALL STRETCH ADULT T 53 PURPLE SMALL STRETCH ADULT T 54 PURPLE SMALL STRETCH ADULT T 55 PURPLE SMALL STRETCH ADULT T 56 PURPLE SMALL STRETCH ADULT T 57 PURPLE SMALL STRETCH ADULT T 58 PURPLE SMALL STRETCH ADULT T 59 PURPLE SMALL STRETCH ADULT T 60 PURPLE SMALL STRETCH ADULT T 61 PURPLE SMALL STRETCH CHILD F 62 PURPLE SMALL STRETCH CHILD F 63 PURPLE SMALL STRETCH CHILD F 64 PURPLE SMALL STRETCH CHILD F 65 PURPLE SMALL STRETCH CHILD F 66 PURPLE SMALL DIP ADULT F 67 PURPLE SMALL DIP ADULT F 68 PURPLE SMALL DIP ADULT F 69 PURPLE SMALL DIP ADULT F 70 PURPLE SMALL DIP ADULT F 71 PURPLE SMALL DIP CHILD F 72 PURPLE SMALL DIP CHILD F 73 PURPLE SMALL DIP CHILD F 74 PURPLE SMALL DIP CHILD F 75 PURPLE SMALL DIP CHILD F 76 PURPLE LARGE STRETCH ADULT T 77 PURPLE LARGE STRETCH ADULT T 78 PURPLE LARGE STRETCH ADULT T 79 PURPLE LARGE STRETCH ADULT T 80 PURPLE LARGE STRETCH ADULT T 81 PURPLE LARGE STRETCH ADULT T 82 PURPLE LARGE STRETCH ADULT T 83 PURPLE LARGE STRETCH ADULT T 84 PURPLE LARGE STRETCH ADULT T 85 PURPLE LARGE STRETCH ADULT T 86 PURPLE LARGE STRETCH CHILD F 87 PURPLE LARGE STRETCH CHILD F 88 PURPLE LARGE STRETCH CHILD F 89 PURPLE LARGE STRETCH CHILD F 90 PURPLE LARGE STRETCH CHILD F 91 PURPLE LARGE DIP ADULT F 92 PURPLE LARGE DIP ADULT F 93 PURPLE LARGE DIP ADULT F 94 PURPLE LARGE DIP ADULT F 95 PURPLE LARGE DIP ADULT F 96 PURPLE LARGE DIP CHILD F 97 PURPLE LARGE DIP CHILD F 98 PURPLE LARGE DIP CHILD F 99 PURPLE LARGE DIP CHILD F 100 PURPLE LARGE DIP CHILD F kita dapat menggunakan KModes yang merupakan library dari kmodes untuk melakukan clustering. data kategorikal dalam contoh ini digunakan k=3 untuk mengelompokkan menjadi 3 cluster. dari hasil proses clustering yang dilakukan, hasilnya dapat digabungkan dengan data yang telah ada dengan menambahkan attribut Cluster agar setiap baris data memiliki clusternya masing-msaing. from kmodes.kmodes import KModes k = 3 df_dummy = pd . get_dummies ( df ) data_set = df_dummy . reset_index () . values kmodes_cao = KModes ( n_clusters = k , init = 'Cao' , verbose = 1 ) cluster = kmodes_cao . fit ( data_set ) data [ 'Cluster' ] = cluster . labels_ show_cluster ( data , k ) kita dapat menggunakan fungsi show_cluster() yang telah dibuat sebelumnya. dari fungsi tersebut kita dapat menampilkan cluster-cluster dan ID dari anggota cluster tersebut. Cluster 0 Cluster 1 Cluster 2 1 41 11 2 42 12 3 43 13 4 44 14 5 45 15 6 46 21 7 47 22 8 48 23 9 49 24 10 50 25 16 66 36 17 67 37 18 68 38 19 69 39 20 70 40 26 71 61 27 72 62 28 73 63 29 74 64 30 75 65 31 86 32 87 33 88 34 89 35 90 51 91 52 92 53 93 54 94 55 95 56 96 57 97 58 98 59 99 60 100 76 77 78 79 80 81 82 83 84 85 Hasil dari clustering tersebut dapat kita visualisasikan dalam bentuk plot dengan menggunakan library matpotlib. import matplotlib.pyplot as plt from sklearn.decomposition import PCA pca = PCA ( 2 ) plot_columns = pca . fit_transform ( df_dummy . iloc [:, 0 : 6 ]) plt . title ( \"Hasil Klustering K-Modes\" ) plt . scatter ( x = plot_columns [:, 1 ], y = plot_columns [:, 0 ], c = df_dummy [ \"Cluster\" ], s = 30 ) plt . show () Maka akan menampilkan plot scatter tersebut dengan warna berbeda dari masing-masing cluster.","title":"K-Modes"},{"location":"pendat/clustering/#k-prototype","text":"Pada implementasi K-Prototype, kita dapat menggunakan data yang dapat diunduh di link ini , data tersebut dapat kita load untuk ditampilkan dalam bentuk data frame . import pandas as pd data = pd . read_csv ( 'tae_data.csv' , delimiter = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Setelah di load data tersebut akan tampil seperti berikut: ID Whether TA Course instructor Course Summer Class size Class attribute 1 english speaker 23 3 summer 19 high 2 non es 15 3 summer 17 high 3 english speaker 23 3 regular 49 high 4 english speaker 5 2 regular 33 high 5 non es 7 11 regular 55 high 6 non es 23 3 summer 20 high 7 non es 9 5 regular 19 high 8 non es 10 3 regular 27 high 9 english speaker 22 3 summer 58 high 10 non es 15 3 summer 20 high 11 non es 10 22 regular 9 high 12 non es 13 1 regular 30 high 13 non es 18 21 regular 29 high 14 non es 6 17 regular 39 high 15 non es 6 17 regular 42 medium 16 non es 6 17 regular 43 medium 17 non es 7 11 regular 10 medium 18 non es 22 3 regular 46 medium 19 non es 13 3 summer 10 medium 20 non es 7 25 regular 42 medium 21 non es 25 7 regular 27 medium 22 non es 25 7 regular 23 medium 23 non es 2 9 regular 31 medium 24 non es 1 15 summer 22 medium 25 non es 15 13 regular 37 medium 26 non es 7 11 regular 13 medium 27 non es 8 3 regular 24 medium 28 non es 14 15 regular 38 medium 29 non es 21 2 regular 42 low 30 non es 22 3 regular 28 low 31 non es 11 1 regular 51 low 32 non es 18 5 regular 19 low 33 non es 13 1 regular 31 low 34 english speaker 13 3 summer 13 low 35 non es 5 2 regular 37 low 36 non es 16 8 regular 36 low 37 non es 4 16 regular 21 low 38 non es 5 2 regular 48 low 39 non es 14 15 regular 38 low 40 english speaker 23 3 summer 19 high 41 non es 15 3 summer 17 high 42 english speaker 23 3 regular 49 high 43 english speaker 5 2 regular 33 high 44 non es 7 11 regular 55 high 45 non es 23 3 summer 20 high 46 non es 9 5 regular 19 high 47 non es 10 3 regular 27 high 48 english speaker 22 3 regular 58 high 49 non es 15 3 summer 20 high 50 non es 10 22 regular 9 high 51 non es 13 1 regular 30 high 52 non es 18 21 regular 29 high 53 non es 6 17 regular 39 high 54 non es 6 17 regular 42 medium 55 non es 6 17 regular 43 medium 56 non es 7 11 regular 10 medium 57 non es 22 3 regular 46 medium 58 non es 13 3 summer 10 medium 59 non es 7 25 regular 42 medium 60 non es 25 7 regular 27 medium 61 non es 25 7 regular 23 medium 62 non es 2 9 regular 31 medium 63 non es 1 15 summer 22 medium 64 non es 15 13 regular 37 medium 65 non es 7 11 regular 13 medium 66 non es 8 3 regular 24 medium 67 non es 14 15 regular 38 medium 68 non es 21 2 regular 42 low 69 non es 22 3 regular 28 low 70 non es 11 1 regular 51 low 71 non es 18 5 regular 19 low 72 non es 13 1 regular 31 low 73 english speaker 13 3 summer 13 low 74 non es 5 2 regular 37 low 75 non es 16 8 regular 36 low 76 non es 4 16 regular 21 low 77 non es 5 2 regular 48 low 78 non es 14 15 regular 38 low 79 english speaker 23 3 summer 25 high 80 english speaker 13 3 summer 17 high 81 non es 16 19 regular 11 high 82 non es 9 2 regular 39 high 83 non es 13 3 summer 11 high 84 non es 18 21 regular 19 high 85 english speaker 22 3 regular 45 high 86 non es 7 11 summer 20 high 87 non es 23 3 summer 20 high 88 english speaker 23 3 summer 20 high 89 english speaker 23 3 regular 38 high 90 non es 14 22 regular 17 high 91 english speaker 17 17 regular 19 high 92 non es 9 5 regular 24 high 93 non es 18 25 regular 25 high 94 english speaker 17 17 regular 31 high 95 non es 1 15 regular 31 high 96 non es 1 8 regular 18 medium 97 english speaker 11 16 regular 22 medium 98 english speaker 22 13 regular 27 medium 99 non es 9 2 regular 14 medium 100 non es 13 1 regular 20 medium 101 english speaker 6 17 regular 35 medium 102 non es 23 3 summer 20 medium 103 english speaker 23 3 summer 20 medium 104 non es 6 17 regular 37 medium 105 english speaker 22 3 regular 15 medium 106 non es 20 2 regular 25 medium 107 non es 23 3 regular 10 medium 108 non es 20 2 regular 14 low 109 english speaker 23 3 regular 38 low 110 non es 13 1 regular 29 low 111 non es 10 3 regular 19 low 112 non es 7 11 regular 30 low 113 english speaker 14 15 regular 32 low 114 non es 8 3 regular 27 low 115 non es 12 7 regular 34 low 116 non es 8 7 regular 23 low 117 non es 15 1 regular 66 low 118 non es 23 3 regular 12 low 119 non es 2 9 regular 29 low 120 non es 15 1 regular 19 low 121 non es 20 2 regular 3 low 122 non es 13 14 regular 17 high 123 non es 9 6 regular 7 high 124 english speaker 10 3 regular 21 high 125 non es 14 15 regular 36 high 126 english speaker 13 1 regular 54 high 127 english speaker 8 3 regular 29 high 128 non es 20 2 regular 45 high 129 non es 22 1 regular 11 medium 130 non es 18 12 regular 16 medium 131 non es 20 15 regular 18 medium 132 english speaker 17 18 regular 44 medium 133 non es 14 23 regular 17 medium 134 non es 24 26 regular 21 medium 135 non es 9 24 regular 20 medium 136 non es 12 8 regular 24 medium 137 non es 9 6 regular 5 medium 138 non es 22 1 regular 42 medium 139 non es 7 11 regular 30 low 140 non es 10 3 regular 19 low 141 non es 23 3 regular 11 low 142 non es 17 18 regular 29 low 143 non es 16 20 regular 15 low 144 non es 3 2 regular 37 low 145 non es 19 4 regular 10 low 146 non es 23 3 regular 24 low 147 non es 3 2 regular 26 low 148 non es 10 3 regular 12 low 149 english speaker 18 7 regular 48 low 150 non es 22 1 regular 51 low 151 non es 2 10 regular 27 low Kita dapat menggunakan Kprototype yang merupakan library dari kmodes untuk melakukan clustering data campuran dari numerik dan kategorikal. dalam contoh ini digunakan k=5 untuk mengelompokkan menjadi 5 cluster. from kmodes.kprototypes import KPrototypes k = 5 df_dummy = pd . get_dummies ( df ) data_set = df_dummy . reset_index () . values kproto = KPrototypes ( n_clusters = k , init = 'Cao' , verbose = 2 ) cluster = kproto . fit ( data_set , categorical = [ 0 , 1 , 2 , 3 , 5 ]) data [ 'Cluster' ] = cluster . labels_ show_cluster ( data , k ) kita dapat menggunakan fungsi show_cluster() yang telah dibuat sebelumnya. dari fungsi tersebut kita dapat menampilkan cluster-cluster dan ID dari anggota cluster tersebut. Cluster 0 Cluster 1 Cluster 2 Cluster 3 Cluster 4 4 1 3 14 11 8 2 5 15 17 12 6 9 16 19 13 7 18 20 26 21 10 31 25 34 23 22 38 28 50 30 24 42 29 56 33 27 44 35 58 43 32 48 36 65 47 37 57 39 73 51 40 70 53 81 52 41 77 54 83 60 45 85 55 99 62 46 117 59 105 69 49 126 64 107 72 61 149 67 108 93 63 150 68 118 94 66 74 121 95 71 75 123 98 76 78 129 106 79 82 137 110 80 89 141 112 84 101 143 113 86 104 145 114 87 109 148 115 88 125 119 90 128 127 91 132 139 92 138 142 96 144 147 97 151 100 102 103 111 116 120 122 124 130 131 133 134 135 136 140 146 Hasil dari clustering tersebut dapat kita visualisasikan dalam bentuk plot dengan menggunakan library matpotlib. import matplotlib.pyplot as plt from sklearn.decomposition import PCA pca = PCA ( 2 ) plot_columns = pca . fit_transform ( df_dummy . iloc [:, 1 :]) plt . title ( \"Hasil Klustering K-Prototype\" ) plt . scatter ( x = plot_columns [:, 1 ], y = plot_columns [:, 0 ], c = df_dummy [ \"Cluster\" ], s = 30 ) plt . show () Maka akan menampilkan plot scatter tersebut dengan warna berbeda dari setiap cluster.","title":"K-Prototype"},{"location":"pendat/distance/","text":"Mengukur Jarak Data \u00b6 Mengukur Jarak Tipe Numerik \u00b6 Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperti Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan. Ada beberapa cara untuk menghitung similaritas atau jarak dari dari data tipe numerik, diantaranya: Minkowski Distance \u00b6 Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan: $$ d _ { \\operatorname { min } } = ( sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Diman $ m $ adalah bilangan riel positif dan $ x_i $ dan $ y_i $ adalah dua vektor dalam runang dimensi $ n $ Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar. Manhattan Distance \u00b6 Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan: d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| Euiclidian Distance \u00b6 Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. Euclidian Distance dinyatakan dengan: d_(x,y) =\\sqrt{ \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - y _ { i } \\right)^2} d_(x,y) =\\sqrt{ \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - y _ { i } \\right)^2} Average Distance \u00b6 Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasi dari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik $ x,y $ dalam ruang dimensi $ n $, rata-rata jarak didefinisikan dengan: d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } Weighted euclidean distance \u00b6 Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ dimana w i adalah bobot yang diberikan pada atribut ke i. Chord distance \u00b6 Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan: $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ dimana $ { | x | _ { 2 } } $ adalah $ L^2-norm { | x | _ { 2 } } =\\sqrt { \\sum_{ i = 1 }^{ n }x_{i}^{2}} $ Mahalanobis distance \u00b6 Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ diman $ S $ adalah matrik covariance data. Cosine measure \u00b6 Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ dimana $ | y | _ { 2 } $ adalah Euclidean norm dari vektor $ y=(y_{1} , y_{2} , \\dots , y_{n} ) $ di definisikan dengan $ |y|_{2}=\\sqrt{ y _ { 1 } ^ { 2 } + y _ { 2 } ^ { 2 } + \\ldots + y _ { n } ^ { 2 } } $ Pearson Correlation \u00b6 Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$ The Pearson correlation kelemahannya adalah sensitif terhadap outlier Mengukur Jarak Tipe Binary \u00b6 Atribut biner merupakan atribut yang hanya memiliki dua status: 0 dan 1. Contoh dari atribut biner adalah hasil tes urine yang akan mendapatkan hasil positiv dan negatif, dimana hasil dari positif representasikan sebagai 1 dan sebaliknya hasil negative representasikan sebagai 0. Dalam menghitung jarak tipe biner tidak diperkenankan menyamakan dengan menghitung jarak tipe numerik ada metode khusus untuk menghitungnya. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d72 di mana q adalah jumlah atribut yang sama dengan 1 untuk kedua objek i dan j, r adalah jumlah atribut yang sama dengan 1 untuk objek i tetapi 0 untuk objek j, s adalah jumlah atribut yang sama dengan 0 untuk objek i tetapi 1 untuk objek j, dan t adalah jumlah atribut yang sama dengan 0 untuk kedua objek i dan j. Jumlah total atribut adalah p, di mana p=q+r+s+t Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama .Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antari dan j adalah : $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya: $$ d ( i , j ) = \\frac { r + s } { q + r + s } $$ Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek i dan j dapat dihitung dengan $$ \\operatorname { sim } ( i , j ) = \\frac { q } { q + r + s } = 1 - d ( i , j ) $$ Persamaan similarity ini disebut dengan Jaccard coefficient Mengukur Jarak Tipe Kategorical \u00b6 Sebuah data tipe kategorial bisa membawa dua atau lebih pernyataan. Misalnya, map_color sebuah atribut nominal yang mempunya 5 pernyataan yaitu: merah, kuning, hijau, merah jambu, dan biru. Status dapat dilambangkan dengan byletters, simbol, atau satu set bilangan bulat, seperti 1, 2, ..., M. Perhatikan bahwa bilangan bulat tersebut digunakan hanya untuk penanganan data dan tidak mewakili pemesanan khusus apa pun. Perbedaan antara dua objek i dan j bisa di hitung dengan menggunakan rasio ketidak cocokan : $$ d_(i,j) = {p - m \\over p} $$ dimana, $ m $ merupakan angka yang cocok (nomer yang cocok untuk $ i $ dan $ j $ ). Dan p merupakan banyak fitur yang di hitung sebagai tipe nominal. Mengukur Jarak Tipe Ordinal \u00b6 Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal $ f $ yang memiliki $ M_f $ state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius) dapat diatur ke dalam status berikut: \u221230 hingga \u221210, \u221210 hingga 10, 10 hingga 0, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. $ M $ adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat $ 1,...,M_f$ Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan $ f $ adalah atribut-atribut dari atribut ordinal dari n objek. Menghitung disimilarity terhadap $ f $ fitur sebagai berikut: Nilai$ f $ untuk objek ke-i adalah $ x_if $, dan f memiliki $ M_f $ status urutan , mewakili peringkat $ 1,..,Mf $ Ganti setiap $ x_if $ dengan peringkatnya, $ r_if \u2208 {1...M_f} $ Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat $ r_if $ dengan : z_if = {r_if - 1 \\over M_f -1} z_if = {r_if - 1 \\over M_f -1} Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi $ z_if $ Mencari Jarak Data Tipe Campuran Menggunakan Python \u00b6 Alat dan Bahan \u00b6 Pada kasus kali ini saya telah menyediakan data tipe campuran yang disimpan dalam bentuk .csv yang dapat di unduh disini . untuk mempermudah dalam penyelesaian kasus ini, perlu di siapkan library dari python untuk mempermudah dalam pengerjaan. Library ini dapat di unduh secara gratis dari internet. Berikut merupakan library yang harus di persiapkan: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika. Pertama \u00b6 Langkah pertama yang harus dilakukan adalah memasukkan library yang telah diunduh sebelumnya. import pandas as pd import math as mt from sklearn.preprocessing import LabelEncoder Kedua \u00b6 Selanjutnya kita dapat membaca file csv tersebut. data = pd . read_csv ( 'data-mhs.csv' , sep = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Maka akan tampil sebagai berikut: Nama Jenis Kelamin IPK Penghasilan Orangtua Alamat Prestasi Ali L 3.4 3000000 Sumenep Internasional Ani P 3.2 5000000 Surabaya Regional Abi L 3.3 4000000 Bangkalan Nasional Ketiga \u00b6 Langkah ini, kita menerapkan dari formula menghitung jarak diatas dalam bentuk fungsi pada python. Fungsi berikut digunakan untuk melakukan normalisasi pada data numerikal. def Zscore ( x , mean , std ): top = x - mean if top == 0 : return top else : return round ( top / std , 2 ) def normalisasi ( num , col_x ): return Zscore ( num , pd . Series ( data [ col_x ] . values ) . mean (), pd . Series ( data [ col_x ] . values ) . std ()) Fungsi berikut merupakan penerapan dari rumus Euclidian Distance untuk menghitung jarak tipe numerikal. #menghitung jarak tipe numerikal def euclidianDistance ( x , y ): dis = 0 for i in range ( len ( x )): dis += ( x [ i ] - y [ i ]) ** 2 return round ( mt . sqrt ( dis ), 2 ) Fungsi berikut untuk menghitung jarak pada data tipe binary symetris. #Menghitung jarak tipe binary def distanceSimetris ( x , y ): q = r = s = t = 0 for i in range ( len ( x )): if x [ i ] == 1 and y [ i ] == 1 : q += 1 elif x [ i ] == 1 and y [ i ] == 0 : r += 1 elif x [ i ] == 0 and y [ i ] == 1 : s += 1 elif x [ i ] == 0 and y [ i ] == 0 : t += 1 return (( r + s ) / ( q + r + s + t )) Fungsi berikut untuk menghitung jarak tipe kategorikal. #Menghitung Jarak tipe categorikal def distanceNom ( x , y ): p = len ( x ) or len ( y ) m = 0 for i in range ( len ( x )): if x [ i ][ 0 ] == y [ i ][ 0 ]: m += 1 return ( p - m ) / p \u200b Fungsi berikut untuk melakukan normalisasi pada data tipe ordinal: #inisialisasi x = { 'Internasional' : 3 , 'Nasional' : 2 , 'Regional' : 1 } #Menghitung Jarak tipe ordinal def normalizedOrd ( y ): i_max = 0 for i in x : if x [ i ] > i_max : i_max = x [ i ] if y [ 0 ] == i : i_val = x [ i ] return ( i_val - 1 ) / ( i_max - 1 ) Keempat \u00b6 Pada langkah ini kita membuat inisialisasi dictionary dissimilarity matrix: d_x = { 0 : [ '' , 'Ali' , 'Ani' , 'Abi' ], 1 : [ 'Ali' , 0 , '' , '' ], 2 : [ 'Ani' , '' , 0 , '' ], 3 : [ 'Abi' , '' , '' , 0 ] } Kelima \u00b6 Untuk mempermudah dalam menghitung jarak dari data tipe binary, alangkah lebih baiknya kita konversi nilai dari fitur tersebut dalam bentuk angka 0 / 1. Dalam proses konversi tersebut kita dapat menggunakan fungsi LabelEncode yang merupakan bawaan dari library sklearn . X = data . iloc [:,:] . values labelEncode_X = LabelEncoder () X [:, 1 ] = labelEncode_X . fit_transform ( X [:, 1 ]) Keenam \u00b6 Pada langkah ini kita akan menghitung jarak dari masing-masing tipe menggunakan fungsi yang telah dibuat sebelumnya. Menghitung Jarak Tipe Numerikal \u00b6 Berikut merupakan proses menghitung jarak dengan tipe numerikal. Pada proses berikut kita mengambil fitur-fitur numerik dari masing-masing objek, yaitu: ali, ani, dan abi. dari data numerik tersebut kemudian dilakukan normalisasi dan menghitungnya dengan mengunakan fungsi Euclidian Distance yang hasilnya di tampung pada dictionary dissimilarity matrix. #ambil data numerikal aliNum = df . iloc [ 0 , 2 : 4 ] . values aniNum = df . iloc [ 1 , 2 : 4 ] . values abiNum = df . iloc [ 2 , 2 : 4 ] . values #normalisasi data numerikal aliNum = [ normalisasi ( aliNum [ 0 ], data . columns [ 2 ]), normalisasi ( aliNum [ 1 ], data . columns [ 3 ])] aniNum = [ normalisasi ( aniNum [ 0 ], data . columns [ 2 ]), normalisasi ( aniNum [ 1 ], data . columns [ 3 ])] abiNum = [ normalisasi ( abiNum [ 0 ], data . columns [ 2 ]), normalisasi ( abiNum [ 1 ], data . columns [ 3 ])] d_x [ 1 ][ 2 ] = euclidianDistance ( aniNum , aliNum ) d_x [ 1 ][ 3 ] = euclidianDistance ( abiNum , aliNum ) d_x [ 2 ][ 3 ] = euclidianDistance ( abiNum , aniNum ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. Apabila nilai dari dissimilarity matrix mendekati 0, maka kedua objek tersebut semakin sama: 0 1 2 3 Ali Ani Abi Ali 0 Ani 2.83 0 Abi 1.41 1.41 0 Menghitung Jarak Tipe Kategorikal \u00b6 Pada proses berikut kita menghitung jarak dengan tipe kategorikal / nominal. Pada proses tersebut kita akan mengambil nilai dari fitur kategorikal dari masing-masing objek. Dalam kasus ini yang menjadi fitur kategorikal adalah Kabupaten. Selanjutnya dari masing-masing nilai yang telah di ambil akan dihitung mengunakan fungsi distanceNom(obj1,obj2) yang telah dibuat sebelumnya, yang hasilnya ditampung pada dictionary dissimilarity matrix. #ambil data kategorical aliKat = [ df . iloc [ 0 , 4 : 5 ] . values ] aniKat = [ df . iloc [ 1 , 4 : 5 ] . values ] abiKat = [ df . iloc [ 2 , 4 : 5 ] . values ] d_x [ 1 ][ 2 ] = distanceNom ( aniKat , aliKat ) d_x [ 1 ][ 3 ] = distanceNom ( abiKat , aliKat ) d_x [ 2 ][ 3 ] = distanceNom ( abiKat , aniKat ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. Pada dissimilarity matrix berikut, apabila nilainya berupa 0, maka kedua objek tersebut memiliki kesamaan dan juga sebaliknya, apabila nilainya berupa 1, kedua objek tersebut memiliki perbedaan. 0 1 2 3 Ali Ani Abi Ali 0 Ani 1 0 Abi 1 1 0 Menghitung Jarak Tipe Binary \u00b6 Berikut ini kita akan menghitung jarak dengan tipe binary. Pada proses berikut kita harus mengambil nilai dari masing-masing objek. Dalam kasus ini, yang menjadi fitur biner adalah Jenis Kelamin. Selanjutnya, dari nilai masing-masing objek dihitung jaraknya menggunakan menggunakan fungsi distanceSimetris(obj1, obj2) yang telah dibuat sebelumnya. Dari hasil perhitungan tersebut ditampung pada dictionary dissimilarity matrix. #ambil data binary aliBin = X [ 0 , 1 : 2 ] aniBin = X [ 1 , 1 : 2 ] abiBin = X [ 2 , 1 : 2 ] d_x [ 1 ][ 2 ] = distanceSimetris ( aniBin , aliBin ) d_x [ 1 ][ 3 ] = distanceSimetris ( abiBin , aliBin ) d_x [ 2 ][ 3 ] = distanceSimetris ( abiBin , aniBin ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. 0 1 2 3 Ali Ani Abi Ali 0 Ani 1 0 Abi 0 1 0 Menghitung Jarak Tipe Ordinal \u00b6 Berikut ini kita akan memghitung jarak tipe ordinal. Pada prosesnya, kita akan mengambil nilai dari masing-masing objek dari fitur Prestasi. Nilai dari masing-masing objek di normalisasi menggunakan fungsi normalizedOrd(ordObj) yang telah dibuat sebelumnya, dan dihitung jaraknya menggunakan fungsi euclidianDistance(obj1, obj2) yang hasilnya kemudian ditampung pada dictionary dissimilarity matrix. #ambil data ordinal aliOrd = [ df . iloc [ 0 , 5 : 6 ] . values ] aniOrd = [ df . iloc [ 1 , 5 : 6 ] . values ] abiOrd = [ df . iloc [ 2 , 5 : 6 ] . values ] d_x [ 1 ][ 2 ] = euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas akan menampilkan jarak dalam bentuk dissimilarity matrix. 0 1 2 3 Ali Ani Abi Ali 0 Ani 1 0 Abi 0.5 0.5 0 Menghitung Jarak Tipe Campuran \u00b6 Pada proses berikut kita akan menghitung jarak dengan berbagai tipe. Untuk menghitungnya kita dapat menjumlah jarak dari masing-masing tipe. d_x [ 1 ][ 2 ] = euclidianDistance ( aniNum , aliNum ) + \\ distanceNom ( aniKat , aliKat ) + distanceSimetris ( aniBin , aliBin ) + \\ euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ( abiNum , aliNum ) + \\ distanceNom ( abiKat , aliKat ) + distanceSimetris ( abiBin , aliBin ) + \\ euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ( abiNum , aniNum ) + \\ distanceNom ( abiKat , aniKat ) + distanceSimetris ( abiBin , aniBin ) + \\ euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. 0 1 2 3 Ali Ani Abi Ali 0 Ani 5.83 0 Abi 2.91 3.91 0 Seluruh file percobaan diatas dapat di unduh disini MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 2"},{"location":"pendat/distance/#mengukur-jarak-data","text":"","title":"Mengukur Jarak Data"},{"location":"pendat/distance/#mengukur-jarak-tipe-numerik","text":"Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mengukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperti Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan. Ada beberapa cara untuk menghitung similaritas atau jarak dari dari data tipe numerik, diantaranya:","title":"Mengukur Jarak Tipe Numerik"},{"location":"pendat/distance/#minkowski-distance","text":"Kelompok Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan: $$ d _ { \\operatorname { min } } = ( sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \\frac { 1 } { m } } , m \\geq 1 $$ Diman $ m $ adalah bilangan riel positif dan $ x_i $ dan $ y_i $ adalah dua vektor dalam runang dimensi $ n $ Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar.","title":"Minkowski Distance"},{"location":"pendat/distance/#manhattan-distance","text":"Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan: d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right|","title":"Manhattan Distance"},{"location":"pendat/distance/#euiclidian-distance","text":"Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. Euclidian Distance dinyatakan dengan: d_(x,y) =\\sqrt{ \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - y _ { i } \\right)^2} d_(x,y) =\\sqrt{ \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - y _ { i } \\right)^2}","title":"Euiclidian Distance"},{"location":"pendat/distance/#average-distance","text":"Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasi dari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik $ x,y $ dalam ruang dimensi $ n $, rata-rata jarak didefinisikan dengan: d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } } d _ { a v e } = \\left ( \\frac { 1 } { n } \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \\right) ^ { \\frac { 1 } { 2 } }","title":"Average Distance"},{"location":"pendat/distance/#weighted-euclidean-distance","text":"Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan: $$ d _ { w e } = \\left ( \\sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \\right) ^ { 2 } ) ^ { \\frac { 1 } { 2 } } $$ dimana w i adalah bobot yang diberikan pada atribut ke i.","title":"Weighted euclidean distance"},{"location":"pendat/distance/#chord-distance","text":"Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan: $$ d _ { \\text {chord} } = \\left ( 2 - 2 \\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } \\right) ^ { \\frac { 1 } { 2 } } $$ dimana $ { | x | _ { 2 } } $ adalah $ L^2-norm { | x | _ { 2 } } =\\sqrt { \\sum_{ i = 1 }^{ n }x_{i}^{2}} $","title":"Chord distance"},{"location":"pendat/distance/#mahalanobis-distance","text":"Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan: $$ d _ { m a h } = \\sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } $$ diman $ S $ adalah matrik covariance data.","title":"Mahalanobis distance"},{"location":"pendat/distance/#cosine-measure","text":"Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan $$ Cosine(x,y)=\\frac { \\sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { | x | _ { 2 } | y | _ { 2 } } $$ dimana $ | y | _ { 2 } $ adalah Euclidean norm dari vektor $ y=(y_{1} , y_{2} , \\dots , y_{n} ) $ di definisikan dengan $ |y|_{2}=\\sqrt{ y _ { 1 } ^ { 2 } + y _ { 2 } ^ { 2 } + \\ldots + y _ { n } ^ { 2 } } $","title":"Cosine measure"},{"location":"pendat/distance/#pearson-correlation","text":"Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan: $$ Pearson ( x , y ) = \\frac { \\sum _ { i = 1 } ^ { n } ( x _ { i } - \\mu _ { x } ) ( y _ { i } - \\mu _ { y } ) } { \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \\sqrt { \\sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } $$ The Pearson correlation kelemahannya adalah sensitif terhadap outlier","title":"Pearson Correlation"},{"location":"pendat/distance/#mengukur-jarak-tipe-binary","text":"Atribut biner merupakan atribut yang hanya memiliki dua status: 0 dan 1. Contoh dari atribut biner adalah hasil tes urine yang akan mendapatkan hasil positiv dan negatif, dimana hasil dari positif representasikan sebagai 1 dan sebaliknya hasil negative representasikan sebagai 0. Dalam menghitung jarak tipe biner tidak diperkenankan menyamakan dengan menghitung jarak tipe numerik ada metode khusus untuk menghitungnya. Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? \u201dSatu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi 2\u00d72 di mana q adalah jumlah atribut yang sama dengan 1 untuk kedua objek i dan j, r adalah jumlah atribut yang sama dengan 1 untuk objek i tetapi 0 untuk objek j, s adalah jumlah atribut yang sama dengan 0 untuk objek i tetapi 1 untuk objek j, dan t adalah jumlah atribut yang sama dengan 0 untuk kedua objek i dan j. Jumlah total atribut adalah p, di mana p=q+r+s+t Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama .Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antari dan j adalah : $$ d ( i , j ) = \\frac { r + s } { q + r + s + t } $$ Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya: $$ d ( i , j ) = \\frac { r + s } { q + r + s } $$ Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek i dan j dapat dihitung dengan $$ \\operatorname { sim } ( i , j ) = \\frac { q } { q + r + s } = 1 - d ( i , j ) $$ Persamaan similarity ini disebut dengan Jaccard coefficient","title":"Mengukur Jarak Tipe Binary"},{"location":"pendat/distance/#mengukur-jarak-tipe-kategorical","text":"Sebuah data tipe kategorial bisa membawa dua atau lebih pernyataan. Misalnya, map_color sebuah atribut nominal yang mempunya 5 pernyataan yaitu: merah, kuning, hijau, merah jambu, dan biru. Status dapat dilambangkan dengan byletters, simbol, atau satu set bilangan bulat, seperti 1, 2, ..., M. Perhatikan bahwa bilangan bulat tersebut digunakan hanya untuk penanganan data dan tidak mewakili pemesanan khusus apa pun. Perbedaan antara dua objek i dan j bisa di hitung dengan menggunakan rasio ketidak cocokan : $$ d_(i,j) = {p - m \\over p} $$ dimana, $ m $ merupakan angka yang cocok (nomer yang cocok untuk $ i $ dan $ j $ ). Dan p merupakan banyak fitur yang di hitung sebagai tipe nominal.","title":"Mengukur Jarak Tipe Kategorical"},{"location":"pendat/distance/#mengukur-jarak-tipe-ordinal","text":"Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal $ f $ yang memiliki $ M_f $ state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius) dapat diatur ke dalam status berikut: \u221230 hingga \u221210, \u221210 hingga 10, 10 hingga 0, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. $ M $ adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat $ 1,...,M_f$ Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek. Misalkan $ f $ adalah atribut-atribut dari atribut ordinal dari n objek. Menghitung disimilarity terhadap $ f $ fitur sebagai berikut: Nilai$ f $ untuk objek ke-i adalah $ x_if $, dan f memiliki $ M_f $ status urutan , mewakili peringkat $ 1,..,Mf $ Ganti setiap $ x_if $ dengan peringkatnya, $ r_if \u2208 {1...M_f} $ Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat $ r_if $ dengan : z_if = {r_if - 1 \\over M_f -1} z_if = {r_if - 1 \\over M_f -1} Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi $ z_if $","title":"Mengukur Jarak Tipe Ordinal"},{"location":"pendat/distance/#mencari-jarak-data-tipe-campuran-menggunakan-python","text":"","title":"Mencari Jarak Data Tipe Campuran Menggunakan Python"},{"location":"pendat/distance/#alat-dan-bahan","text":"Pada kasus kali ini saya telah menyediakan data tipe campuran yang disimpan dalam bentuk .csv yang dapat di unduh disini . untuk mempermudah dalam penyelesaian kasus ini, perlu di siapkan library dari python untuk mempermudah dalam pengerjaan. Library ini dapat di unduh secara gratis dari internet. Berikut merupakan library yang harus di persiapkan: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika.","title":"Alat dan Bahan"},{"location":"pendat/distance/#pertama","text":"Langkah pertama yang harus dilakukan adalah memasukkan library yang telah diunduh sebelumnya. import pandas as pd import math as mt from sklearn.preprocessing import LabelEncoder","title":"Pertama"},{"location":"pendat/distance/#kedua","text":"Selanjutnya kita dapat membaca file csv tersebut. data = pd . read_csv ( 'data-mhs.csv' , sep = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Maka akan tampil sebagai berikut: Nama Jenis Kelamin IPK Penghasilan Orangtua Alamat Prestasi Ali L 3.4 3000000 Sumenep Internasional Ani P 3.2 5000000 Surabaya Regional Abi L 3.3 4000000 Bangkalan Nasional","title":"Kedua"},{"location":"pendat/distance/#ketiga","text":"Langkah ini, kita menerapkan dari formula menghitung jarak diatas dalam bentuk fungsi pada python. Fungsi berikut digunakan untuk melakukan normalisasi pada data numerikal. def Zscore ( x , mean , std ): top = x - mean if top == 0 : return top else : return round ( top / std , 2 ) def normalisasi ( num , col_x ): return Zscore ( num , pd . Series ( data [ col_x ] . values ) . mean (), pd . Series ( data [ col_x ] . values ) . std ()) Fungsi berikut merupakan penerapan dari rumus Euclidian Distance untuk menghitung jarak tipe numerikal. #menghitung jarak tipe numerikal def euclidianDistance ( x , y ): dis = 0 for i in range ( len ( x )): dis += ( x [ i ] - y [ i ]) ** 2 return round ( mt . sqrt ( dis ), 2 ) Fungsi berikut untuk menghitung jarak pada data tipe binary symetris. #Menghitung jarak tipe binary def distanceSimetris ( x , y ): q = r = s = t = 0 for i in range ( len ( x )): if x [ i ] == 1 and y [ i ] == 1 : q += 1 elif x [ i ] == 1 and y [ i ] == 0 : r += 1 elif x [ i ] == 0 and y [ i ] == 1 : s += 1 elif x [ i ] == 0 and y [ i ] == 0 : t += 1 return (( r + s ) / ( q + r + s + t )) Fungsi berikut untuk menghitung jarak tipe kategorikal. #Menghitung Jarak tipe categorikal def distanceNom ( x , y ): p = len ( x ) or len ( y ) m = 0 for i in range ( len ( x )): if x [ i ][ 0 ] == y [ i ][ 0 ]: m += 1 return ( p - m ) / p \u200b Fungsi berikut untuk melakukan normalisasi pada data tipe ordinal: #inisialisasi x = { 'Internasional' : 3 , 'Nasional' : 2 , 'Regional' : 1 } #Menghitung Jarak tipe ordinal def normalizedOrd ( y ): i_max = 0 for i in x : if x [ i ] > i_max : i_max = x [ i ] if y [ 0 ] == i : i_val = x [ i ] return ( i_val - 1 ) / ( i_max - 1 )","title":"Ketiga"},{"location":"pendat/distance/#keempat","text":"Pada langkah ini kita membuat inisialisasi dictionary dissimilarity matrix: d_x = { 0 : [ '' , 'Ali' , 'Ani' , 'Abi' ], 1 : [ 'Ali' , 0 , '' , '' ], 2 : [ 'Ani' , '' , 0 , '' ], 3 : [ 'Abi' , '' , '' , 0 ] }","title":"Keempat"},{"location":"pendat/distance/#kelima","text":"Untuk mempermudah dalam menghitung jarak dari data tipe binary, alangkah lebih baiknya kita konversi nilai dari fitur tersebut dalam bentuk angka 0 / 1. Dalam proses konversi tersebut kita dapat menggunakan fungsi LabelEncode yang merupakan bawaan dari library sklearn . X = data . iloc [:,:] . values labelEncode_X = LabelEncoder () X [:, 1 ] = labelEncode_X . fit_transform ( X [:, 1 ])","title":"Kelima"},{"location":"pendat/distance/#keenam","text":"Pada langkah ini kita akan menghitung jarak dari masing-masing tipe menggunakan fungsi yang telah dibuat sebelumnya.","title":"Keenam"},{"location":"pendat/distance/#menghitung-jarak-tipe-numerikal","text":"Berikut merupakan proses menghitung jarak dengan tipe numerikal. Pada proses berikut kita mengambil fitur-fitur numerik dari masing-masing objek, yaitu: ali, ani, dan abi. dari data numerik tersebut kemudian dilakukan normalisasi dan menghitungnya dengan mengunakan fungsi Euclidian Distance yang hasilnya di tampung pada dictionary dissimilarity matrix. #ambil data numerikal aliNum = df . iloc [ 0 , 2 : 4 ] . values aniNum = df . iloc [ 1 , 2 : 4 ] . values abiNum = df . iloc [ 2 , 2 : 4 ] . values #normalisasi data numerikal aliNum = [ normalisasi ( aliNum [ 0 ], data . columns [ 2 ]), normalisasi ( aliNum [ 1 ], data . columns [ 3 ])] aniNum = [ normalisasi ( aniNum [ 0 ], data . columns [ 2 ]), normalisasi ( aniNum [ 1 ], data . columns [ 3 ])] abiNum = [ normalisasi ( abiNum [ 0 ], data . columns [ 2 ]), normalisasi ( abiNum [ 1 ], data . columns [ 3 ])] d_x [ 1 ][ 2 ] = euclidianDistance ( aniNum , aliNum ) d_x [ 1 ][ 3 ] = euclidianDistance ( abiNum , aliNum ) d_x [ 2 ][ 3 ] = euclidianDistance ( abiNum , aniNum ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. Apabila nilai dari dissimilarity matrix mendekati 0, maka kedua objek tersebut semakin sama: 0 1 2 3 Ali Ani Abi Ali 0 Ani 2.83 0 Abi 1.41 1.41 0","title":"Menghitung Jarak Tipe Numerikal"},{"location":"pendat/distance/#menghitung-jarak-tipe-kategorikal","text":"Pada proses berikut kita menghitung jarak dengan tipe kategorikal / nominal. Pada proses tersebut kita akan mengambil nilai dari fitur kategorikal dari masing-masing objek. Dalam kasus ini yang menjadi fitur kategorikal adalah Kabupaten. Selanjutnya dari masing-masing nilai yang telah di ambil akan dihitung mengunakan fungsi distanceNom(obj1,obj2) yang telah dibuat sebelumnya, yang hasilnya ditampung pada dictionary dissimilarity matrix. #ambil data kategorical aliKat = [ df . iloc [ 0 , 4 : 5 ] . values ] aniKat = [ df . iloc [ 1 , 4 : 5 ] . values ] abiKat = [ df . iloc [ 2 , 4 : 5 ] . values ] d_x [ 1 ][ 2 ] = distanceNom ( aniKat , aliKat ) d_x [ 1 ][ 3 ] = distanceNom ( abiKat , aliKat ) d_x [ 2 ][ 3 ] = distanceNom ( abiKat , aniKat ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. Pada dissimilarity matrix berikut, apabila nilainya berupa 0, maka kedua objek tersebut memiliki kesamaan dan juga sebaliknya, apabila nilainya berupa 1, kedua objek tersebut memiliki perbedaan. 0 1 2 3 Ali Ani Abi Ali 0 Ani 1 0 Abi 1 1 0","title":"Menghitung Jarak Tipe Kategorikal"},{"location":"pendat/distance/#menghitung-jarak-tipe-binary","text":"Berikut ini kita akan menghitung jarak dengan tipe binary. Pada proses berikut kita harus mengambil nilai dari masing-masing objek. Dalam kasus ini, yang menjadi fitur biner adalah Jenis Kelamin. Selanjutnya, dari nilai masing-masing objek dihitung jaraknya menggunakan menggunakan fungsi distanceSimetris(obj1, obj2) yang telah dibuat sebelumnya. Dari hasil perhitungan tersebut ditampung pada dictionary dissimilarity matrix. #ambil data binary aliBin = X [ 0 , 1 : 2 ] aniBin = X [ 1 , 1 : 2 ] abiBin = X [ 2 , 1 : 2 ] d_x [ 1 ][ 2 ] = distanceSimetris ( aniBin , aliBin ) d_x [ 1 ][ 3 ] = distanceSimetris ( abiBin , aliBin ) d_x [ 2 ][ 3 ] = distanceSimetris ( abiBin , aniBin ) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. 0 1 2 3 Ali Ani Abi Ali 0 Ani 1 0 Abi 0 1 0","title":"Menghitung Jarak Tipe Binary"},{"location":"pendat/distance/#menghitung-jarak-tipe-ordinal","text":"Berikut ini kita akan memghitung jarak tipe ordinal. Pada prosesnya, kita akan mengambil nilai dari masing-masing objek dari fitur Prestasi. Nilai dari masing-masing objek di normalisasi menggunakan fungsi normalizedOrd(ordObj) yang telah dibuat sebelumnya, dan dihitung jaraknya menggunakan fungsi euclidianDistance(obj1, obj2) yang hasilnya kemudian ditampung pada dictionary dissimilarity matrix. #ambil data ordinal aliOrd = [ df . iloc [ 0 , 5 : 6 ] . values ] aniOrd = [ df . iloc [ 1 , 5 : 6 ] . values ] abiOrd = [ df . iloc [ 2 , 5 : 6 ] . values ] d_x [ 1 ][ 2 ] = euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas akan menampilkan jarak dalam bentuk dissimilarity matrix. 0 1 2 3 Ali Ani Abi Ali 0 Ani 1 0 Abi 0.5 0.5 0","title":"Menghitung Jarak Tipe Ordinal"},{"location":"pendat/distance/#menghitung-jarak-tipe-campuran","text":"Pada proses berikut kita akan menghitung jarak dengan berbagai tipe. Untuk menghitungnya kita dapat menjumlah jarak dari masing-masing tipe. d_x [ 1 ][ 2 ] = euclidianDistance ( aniNum , aliNum ) + \\ distanceNom ( aniKat , aliKat ) + distanceSimetris ( aniBin , aliBin ) + \\ euclidianDistance ([ normalizedOrd ( aniOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 1 ][ 3 ] = euclidianDistance ( abiNum , aliNum ) + \\ distanceNom ( abiKat , aliKat ) + distanceSimetris ( abiBin , aliBin ) + \\ euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aliOrd )]) d_x [ 2 ][ 3 ] = euclidianDistance ( abiNum , aniNum ) + \\ distanceNom ( abiKat , aniKat ) + distanceSimetris ( abiBin , aniBin ) + \\ euclidianDistance ([ normalizedOrd ( abiOrd )],[ normalizedOrd ( aniOrd )]) d_x = pd . DataFrame ( d_x ) d_x . style . hide_index () Dari proses diatas, akan menampilkan jarak dalam bentuk dissimilarity matrix. 0 1 2 3 Ali Ani Abi Ali 0 Ani 5.83 0 Abi 2.91 3.91 0 Seluruh file percobaan diatas dapat di unduh disini MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Menghitung Jarak Tipe Campuran"},{"location":"pendat/fuzzy/","text":"Implementasi Fuzzy C-Means Clustering dengan Python \u00b6 Pengertian Fuzzy C-Means \u00b6 Fuzzy c-means (FCM) adalah metode pengelompokan data yang dimana keberadaa setiap element data dalam suatu cluster dituntukan oleh derajat keanggotaannya. Metode ini dikembangkan oleh Dunn pada tahun 1973 dan ditingkatkan oleh Bezdek pada tahun 1981). Metode ini biasanya sering digunakan dalam pengenalan pola yamg mana didasarkan pada minimalisasi fungsinya yaitu: J_m = {\\sum \\limits_{i=1}^{N}} {\\sum \\limits_{j=1}^{C}} x_{ij}^m | | x_i - c_j | | ^2 , m \\leq 1 < \\infty J_m = {\\sum \\limits_{i=1}^{N}} {\\sum \\limits_{j=1}^{C}} x_{ij}^m | | x_i - c_j | | ^2 , m \\leq 1 < \\infty di mana $ m $ merupakan bilangan real yang lebih besar dari 1, $ u_{ij} $ adalah tingkat keanggotaan $ x_i $ dalam cluster $ j $, dan $ x_i $ adalah jumlah data terukur d-dimensi, $ c_j $ adalah pusat dimensi d dari cluster, dan $ || * | | $ adalah norma apa pun yang mengungkapkan kesamaan antara data yang diukur dan pusat. Partisi fuzzy dilakukan melalui optimasi berulang fungsi objektif yang ditunjukkan di atas, dengan pembaruan keanggotaan uij dan pusat-pusat cluster $ c_j $ oleh: Penentuan pusat cluster dapat dilakukan dengan menggunakan formula: $ c_j = {{{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m . x_i} \\over {{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m}} $ , dimana $ c $ adalah kumpulan cluster yang ada, yang akan di iterasi sebanyak jumlah cluster pada $ c_j $. setelah mendapatkan nilai pusat cluster ( cendroid ), dapat dilanjutkan dengan memperbaharui nilai derajat ke anggotaan dari masing-masing cluster dengan menggunakan formula, yaitu : $ \\mu_{ij} ={1 \\over \\sum \\limits_{k=1}^{C} \\left ( \\frac {| | x_i - c_j | | } {{| | x_i - c_k | | } } \\right) ^ { \\frac { 2 } { m-1 } }} $ Iterasi ini akan berhenti ketika $ {| | \\mu^{(k + 1)} - \\mu^{k} | | } < \\epsilon $ , dan iterasi telah mencapat batas yang telah ditentukan, di mana kriteria terminasi antara 0 dan 1, sedangkan $ k $ adalah langkah iterasi. Prosedur ini menyatu ke minimum lokal atau titik pelana $ J_m $. Algoritma Fuzzy C-Means \u00b6 Algoritma perhitungan dapat dilakukan seperti berikut : Menentukan jumlah cluster ( k ) Menginisialisasi nilai random darajat ke anggotaan dari masing masing cluster, dimana nilai diantara 0 s/d 1, dan ketika di jumlah sama dengan 1. Mencari pusat cluster ( cendroid ) sebanyak cluster, $ c_j = {{{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m . x_i} \\over {{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m}} $ Mengubah nilai derajat ke anggotaan setiap element cluster $ \\mu^{(k + 1)} - \\mu^{k} $, dengan $ \\mu_{ij} ={1 \\over \\sum \\limits_{k=1}^{C} \\left ( \\frac {| | x_i - c_j | | } {{| | x_i - c_k | | } } \\right) ^ { \\frac { 2 } { m-1 } }} $ Ketika jarak $ \\mu^{(k + 1)} - \\mu^{k} $ kurang dari ambang batas atau iterasi telah sampai pada batas yang telah ditentukan, maka iterasi dapat dihentikan. selain itu kita dapat mengulang dari langkah ke-2. Implementasi pada Python \u00b6 Pertama yang dapat dilakukan adalah dengan masukkan data yang berbentuk .csv menggunakan library pandas. import pandas as pd import random import math as mt data = pd . read_csv ( 'cmeans.csv' , sep = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Data akan tampil seperti berikut yang berisi tiga fitur, dan dua fitur akan digunakan untuk perhitungan yaitu, Rumah dan Mobil. Nama Rumah Mobil A 1 3 B 3 3 C 4 3 D 5 3 E 1 2 F 4 2 G 1 1 H 2 1 Kemudian dapat membuat membuat fungsi buat_mu(X, cluster) , yang akan digunakan membuat nilai derajat keanggotaan secara random sebanyak data dan jumlah cluster. def buat_mu ( X , cluster ): mu = [] for i in range ( len ( X )): temp_mu = [] for j in range ( cluster ): inp = random . randrange ( 1 , 10 ); temp_mu . append ( inp / 10 ) mu . append ( temp_mu ) return mu Fungsi berikut untuk melakukan normalisasi pada nilai $ \\mu $ agar ketika dijumlah berniali 1. def normalisasi_mu ( mu ): n_mu = [] for i in range ( len ( mu )): temp_mu = [] for j in range ( len ( mu [ i ])): nilai2 = 0 for k in range ( len ( mu [ i ])): if k == j : nilai = mu [ i ][ k ] else : nilai2 += mu [ i ][ k ] temp_mu . append ( round ( nilai / ( nilai + nilai2 ), 4 )) n_mu . append ( temp_mu ) return n_mu Fungsi berikut untuk melakukan perhitungan pada $ \\mu_{ij}^m $ def mu_kuadrat ( n_mu , m ): mu_pow = [] for i in range ( len ( n_mu )): temp = [] for j in range ( len ( n_mu [ i ])): temp . append ( round ( n_mu [ i ][ j ] ** m , 4 )) mu_pow . append ( temp ) return mu_pow Fungsi berikut untuk melakukan perhitungan $ \\mu_{ij}^m . x_i $ def mu_kuad_X ( jumlah_cluster , X , mu_kuad ): mu_kuad_X = [] for i in range ( jumlah_cluster ): mu_x = [] for j in range ( len ( X )): temp = [] for k in range ( len ( X [ j ])): temp . append ( round ( X [ j ][ k ] * mu_kuad [ j ][ i ], 4 )) mu_x . append ( temp ) mu_kuad_X . append ( mu_x ) return mu_kuad_X Fungsi berikut untuk melakukan sum/jumlah pada kolom setiap vektor yang dimasukkan. def jumlah ( N ): jumlah = [] for i in range ( len ( N )): temp = [] for j in range ( len ( N [ i ])): if i == 0 : ij = N [ i ][ j ] else : ij = jumlah [ i - 1 ][ j ] + N [ i ][ j ] temp . append ( ij ) jumlah . append ( temp ) return jumlah [ - 1 ] Fungsi berikut untuk mendapatkan nilai pusat cluster ( cendroid ) dari masing-masing cluster. perhitungan yang dilakukan adalah dengan menggabungkan fungsi yang telah di definisikan diatas, yang merupakan implementasi dari formula $ c_j = {{{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m . x_i} \\over {{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m}} $ def getCentroid ( U , mu_kuad_X ): SUM_C = jumlah ( U ) centroid = [] for i in range ( jumlah_cluster ): temp = [] SUM_U = jumlah ( mu_kuad_X [ i ]) for j in range ( len ( jumlah ( mu_kuad_X [ i ]))): temp . append ( SUM_U [ j ] / SUM_C [ i ]) centroid . append ( temp ) return centroid Fungsi berikut merupakan metode perhitungan jarak Mahatan Distance yang didefinisikan dengan $d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $ def manhatan_dist ( x = [], y = []): dist = 0 for i in range ( len ( x )): dist += round ( abs ( x [ i ] - y [ i ]), 4 ) return dist dan fungsi berikut juga merupakan metode perhitungan jarak Euclidian Distance yang didefinisikan dengan $ d_(x,y) =\\sqrt{ \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - y _ { i } \\right)^2} $ def euclidian_dist ( x = [], y = []): dist = 0 for i in range ( len ( x )): dist += ( x [ i ] - y [ i ]) ** 2 return round ( mt . sqrt ( dist ), 2 ) untuk dapat melakukan perubahan nilai derajat ke anggotaan, maka dibuat fungsi update_U() dengan parameter n_mu adalah derajat ke anggotaan $ \\mu $, jumlah cluster, data, dan pusat cluster. fungsi tersebut merupakan implementasi dari formula, $ \\mu_{ij} ={1 \\over \\sum \\limits_{k=1}^{C} \\left ( \\frac {| | x_i - c_j | | } {{| | x_i - c_k | | } } \\right) ^ { \\frac { 2 } { m-1 } }} $ def update_U ( n_mu , jumlah_cluster , X , centroid ): U = [] for i in range ( len ( n_mu )): temp = [] for j in range ( len ( n_mu [ i ])): penyebut = 0 for k in range ( jumlah_cluster ): pembilang = euclidian_dist ( X [ i ], centroid [ j ]) penyebut += euclidian_dist ( X [ i ], centroid [ k ]) hasil = pembilang / penyebut hasil = round ( 1 / ( hasil ** ( 2 / ( m - 1 ))), 4 ) temp . append ( hasil ) U . append ( temp ) return U Kemudian kita dapat membuat fungsi utama yaitu, Fuzzy_CMeans(X, jumlah_cluster, m, max_iter, threshold) yang akan melakukan komputasi berdasarkan algoritma yang telah ditentukan diatas. dan akan berhenti ketika telah nilai fungsi objectif kurang dari nilai ambang batas, atau iterasi telah mencapat batas yang telah ditentukan. def Fuzzy_CMeans ( X , jumlah_cluster , m , max_iter , threshold ): mu = buat_mu ( X , jumlah_cluster ) N_mu = normalisasi_mu ( mu ) iterasi = 0 stop = True while iterasi < max_iter and stop : N = N_mu print ( 'Iterasi' , iterasi ) centroid = getCentroid ( N_mu , mu_kuad_X ( jumlah_cluster , X , mu_kuadrat ( N_mu , m ))) U = update_U ( N_mu , jumlah_cluster , X , centroid ) N_mu = normalisasi_mu ( U ) iterasi += 1 if manhatan_dist ( jumlah ( N_mu ), jumlah ( N )) < threshold : print ( 'berhenti' ) stop = False print ( pd . DataFrame ( N_mu )) dan terakhir kita dapat memanggil fungsi Fuzzy_CMeans() diatas dengan menentukan jumlah cluster adalah 3, memberikan data yang akan dicluster yang berisi dua fitur yang disimpan pada variable X, memberikan nilai m=2, nilai ambang batas adalah 0.1 dan maksimal iterasi adalah 100 kali. data2 = data . drop ( \"Nama\" , axis = 1 ) X = data2 . values m = 2 threshold = 0.1 max_iter = 100 jumlah_cluster = 3 Fuzzy_CMeans ( X , jumlah_cluster , m , max_iter , threshold ) Maka akan mengembalikan hasil seperti berikut: Iterasi 0 0 1 2 0 0.3006 0.4336 0.2658 1 0.3419 0.4051 0.2530 2 0.3500 0.3839 0.2661 3 0.3510 0.3711 0.2780 4 0.2595 0.5347 0.2058 5 0.3633 0.3782 0.2585 6 0.3198 0.5441 0.1360 7 0.4481 0.3969 0.1550 Iterasi 1 0 1 2 0 0.3275 0.3870 0.2855 1 0.3390 0.3752 0.2858 2 0.3414 0.3642 0.2944 3 0.3403 0.3571 0.3025 4 0.3185 0.4347 0.2468 5 0.3441 0.3638 0.2921 6 0.0713 0.9094 0.0193 7 0.3667 0.4039 0.2294 Iterasi 2 0 1 2 0 0.3297 0.3686 0.3017 1 0.3342 0.3625 0.3032 2 0.3349 0.3554 0.3097 3 0.3362 0.3498 0.3140 4 0.3241 0.3994 0.2765 5 0.3373 0.3544 0.3083 6 0.1465 0.7976 0.0559 7 0.3444 0.3869 0.2687 Iterasi 3 0 1 2 0 0.3287 0.3569 0.3144 1 0.3314 0.3519 0.3167 2 0.3313 0.3475 0.3211 3 0.3327 0.3444 0.3229 4 0.3239 0.3770 0.2991 5 0.3330 0.3475 0.3194 6 0.2066 0.6590 0.1344 7 0.3314 0.3703 0.2983 Iterasi 4 0 1 2 0 0.3292 0.3474 0.3234 1 0.3310 0.3443 0.3247 2 0.3303 0.3427 0.3269 3 0.3323 0.3396 0.3281 4 0.3255 0.3592 0.3153 5 0.3313 0.3414 0.3273 6 0.2711 0.4940 0.2350 7 0.3268 0.3575 0.3157 Iterasi 5 0 1 2 0 0.3303 0.3423 0.3274 1 0.3311 0.3399 0.3290 2 0.3322 0.3374 0.3304 3 0.3324 0.3367 0.3310 4 0.3296 0.3459 0.3245 5 0.3320 0.3380 0.3300 6 0.3138 0.3936 0.2925 7 0.3313 0.3431 0.3256 Iterasi 6 berhenti 0 1 2 0 0.3314 0.3373 0.3314 1 0.3319 0.3362 0.3319 2 0.3351 0.3333 0.3316 3 0.3333 0.3348 0.3319 4 0.3298 0.3405 0.3298 5 0.3320 0.3320 0.3360 6 0.3234 0.3015 0.3751 7 0.3392 0.3276 0.3333 Claster data tersebut dapat ditentukan dengan nilai derajat ke anggota tertinggi pada masing-masing cluster. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 6"},{"location":"pendat/fuzzy/#implementasi-fuzzy-c-means-clustering-dengan-python","text":"","title":"Implementasi Fuzzy C-Means Clustering dengan  Python"},{"location":"pendat/fuzzy/#pengertian-fuzzy-c-means","text":"Fuzzy c-means (FCM) adalah metode pengelompokan data yang dimana keberadaa setiap element data dalam suatu cluster dituntukan oleh derajat keanggotaannya. Metode ini dikembangkan oleh Dunn pada tahun 1973 dan ditingkatkan oleh Bezdek pada tahun 1981). Metode ini biasanya sering digunakan dalam pengenalan pola yamg mana didasarkan pada minimalisasi fungsinya yaitu: J_m = {\\sum \\limits_{i=1}^{N}} {\\sum \\limits_{j=1}^{C}} x_{ij}^m | | x_i - c_j | | ^2 , m \\leq 1 < \\infty J_m = {\\sum \\limits_{i=1}^{N}} {\\sum \\limits_{j=1}^{C}} x_{ij}^m | | x_i - c_j | | ^2 , m \\leq 1 < \\infty di mana $ m $ merupakan bilangan real yang lebih besar dari 1, $ u_{ij} $ adalah tingkat keanggotaan $ x_i $ dalam cluster $ j $, dan $ x_i $ adalah jumlah data terukur d-dimensi, $ c_j $ adalah pusat dimensi d dari cluster, dan $ || * | | $ adalah norma apa pun yang mengungkapkan kesamaan antara data yang diukur dan pusat. Partisi fuzzy dilakukan melalui optimasi berulang fungsi objektif yang ditunjukkan di atas, dengan pembaruan keanggotaan uij dan pusat-pusat cluster $ c_j $ oleh: Penentuan pusat cluster dapat dilakukan dengan menggunakan formula: $ c_j = {{{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m . x_i} \\over {{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m}} $ , dimana $ c $ adalah kumpulan cluster yang ada, yang akan di iterasi sebanyak jumlah cluster pada $ c_j $. setelah mendapatkan nilai pusat cluster ( cendroid ), dapat dilanjutkan dengan memperbaharui nilai derajat ke anggotaan dari masing-masing cluster dengan menggunakan formula, yaitu : $ \\mu_{ij} ={1 \\over \\sum \\limits_{k=1}^{C} \\left ( \\frac {| | x_i - c_j | | } {{| | x_i - c_k | | } } \\right) ^ { \\frac { 2 } { m-1 } }} $ Iterasi ini akan berhenti ketika $ {| | \\mu^{(k + 1)} - \\mu^{k} | | } < \\epsilon $ , dan iterasi telah mencapat batas yang telah ditentukan, di mana kriteria terminasi antara 0 dan 1, sedangkan $ k $ adalah langkah iterasi. Prosedur ini menyatu ke minimum lokal atau titik pelana $ J_m $.","title":"Pengertian Fuzzy C-Means"},{"location":"pendat/fuzzy/#algoritma-fuzzy-c-means","text":"Algoritma perhitungan dapat dilakukan seperti berikut : Menentukan jumlah cluster ( k ) Menginisialisasi nilai random darajat ke anggotaan dari masing masing cluster, dimana nilai diantara 0 s/d 1, dan ketika di jumlah sama dengan 1. Mencari pusat cluster ( cendroid ) sebanyak cluster, $ c_j = {{{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m . x_i} \\over {{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m}} $ Mengubah nilai derajat ke anggotaan setiap element cluster $ \\mu^{(k + 1)} - \\mu^{k} $, dengan $ \\mu_{ij} ={1 \\over \\sum \\limits_{k=1}^{C} \\left ( \\frac {| | x_i - c_j | | } {{| | x_i - c_k | | } } \\right) ^ { \\frac { 2 } { m-1 } }} $ Ketika jarak $ \\mu^{(k + 1)} - \\mu^{k} $ kurang dari ambang batas atau iterasi telah sampai pada batas yang telah ditentukan, maka iterasi dapat dihentikan. selain itu kita dapat mengulang dari langkah ke-2.","title":"Algoritma Fuzzy C-Means"},{"location":"pendat/fuzzy/#implementasi-pada-python","text":"Pertama yang dapat dilakukan adalah dengan masukkan data yang berbentuk .csv menggunakan library pandas. import pandas as pd import random import math as mt data = pd . read_csv ( 'cmeans.csv' , sep = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Data akan tampil seperti berikut yang berisi tiga fitur, dan dua fitur akan digunakan untuk perhitungan yaitu, Rumah dan Mobil. Nama Rumah Mobil A 1 3 B 3 3 C 4 3 D 5 3 E 1 2 F 4 2 G 1 1 H 2 1 Kemudian dapat membuat membuat fungsi buat_mu(X, cluster) , yang akan digunakan membuat nilai derajat keanggotaan secara random sebanyak data dan jumlah cluster. def buat_mu ( X , cluster ): mu = [] for i in range ( len ( X )): temp_mu = [] for j in range ( cluster ): inp = random . randrange ( 1 , 10 ); temp_mu . append ( inp / 10 ) mu . append ( temp_mu ) return mu Fungsi berikut untuk melakukan normalisasi pada nilai $ \\mu $ agar ketika dijumlah berniali 1. def normalisasi_mu ( mu ): n_mu = [] for i in range ( len ( mu )): temp_mu = [] for j in range ( len ( mu [ i ])): nilai2 = 0 for k in range ( len ( mu [ i ])): if k == j : nilai = mu [ i ][ k ] else : nilai2 += mu [ i ][ k ] temp_mu . append ( round ( nilai / ( nilai + nilai2 ), 4 )) n_mu . append ( temp_mu ) return n_mu Fungsi berikut untuk melakukan perhitungan pada $ \\mu_{ij}^m $ def mu_kuadrat ( n_mu , m ): mu_pow = [] for i in range ( len ( n_mu )): temp = [] for j in range ( len ( n_mu [ i ])): temp . append ( round ( n_mu [ i ][ j ] ** m , 4 )) mu_pow . append ( temp ) return mu_pow Fungsi berikut untuk melakukan perhitungan $ \\mu_{ij}^m . x_i $ def mu_kuad_X ( jumlah_cluster , X , mu_kuad ): mu_kuad_X = [] for i in range ( jumlah_cluster ): mu_x = [] for j in range ( len ( X )): temp = [] for k in range ( len ( X [ j ])): temp . append ( round ( X [ j ][ k ] * mu_kuad [ j ][ i ], 4 )) mu_x . append ( temp ) mu_kuad_X . append ( mu_x ) return mu_kuad_X Fungsi berikut untuk melakukan sum/jumlah pada kolom setiap vektor yang dimasukkan. def jumlah ( N ): jumlah = [] for i in range ( len ( N )): temp = [] for j in range ( len ( N [ i ])): if i == 0 : ij = N [ i ][ j ] else : ij = jumlah [ i - 1 ][ j ] + N [ i ][ j ] temp . append ( ij ) jumlah . append ( temp ) return jumlah [ - 1 ] Fungsi berikut untuk mendapatkan nilai pusat cluster ( cendroid ) dari masing-masing cluster. perhitungan yang dilakukan adalah dengan menggabungkan fungsi yang telah di definisikan diatas, yang merupakan implementasi dari formula $ c_j = {{{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m . x_i} \\over {{\\sum \\limits_{j=1}^{C}} \\mu_{ij}^m}} $ def getCentroid ( U , mu_kuad_X ): SUM_C = jumlah ( U ) centroid = [] for i in range ( jumlah_cluster ): temp = [] SUM_U = jumlah ( mu_kuad_X [ i ]) for j in range ( len ( jumlah ( mu_kuad_X [ i ]))): temp . append ( SUM_U [ j ] / SUM_C [ i ]) centroid . append ( temp ) return centroid Fungsi berikut merupakan metode perhitungan jarak Mahatan Distance yang didefinisikan dengan $d _ { \\operatorname { man } } = \\sum _ { i = 1 } ^ { n } \\left| x _ { i } - y _ { i } \\right| $ def manhatan_dist ( x = [], y = []): dist = 0 for i in range ( len ( x )): dist += round ( abs ( x [ i ] - y [ i ]), 4 ) return dist dan fungsi berikut juga merupakan metode perhitungan jarak Euclidian Distance yang didefinisikan dengan $ d_(x,y) =\\sqrt{ \\sum _ { i = 1 } ^ { n } \\left( x _ { i } - y _ { i } \\right)^2} $ def euclidian_dist ( x = [], y = []): dist = 0 for i in range ( len ( x )): dist += ( x [ i ] - y [ i ]) ** 2 return round ( mt . sqrt ( dist ), 2 ) untuk dapat melakukan perubahan nilai derajat ke anggotaan, maka dibuat fungsi update_U() dengan parameter n_mu adalah derajat ke anggotaan $ \\mu $, jumlah cluster, data, dan pusat cluster. fungsi tersebut merupakan implementasi dari formula, $ \\mu_{ij} ={1 \\over \\sum \\limits_{k=1}^{C} \\left ( \\frac {| | x_i - c_j | | } {{| | x_i - c_k | | } } \\right) ^ { \\frac { 2 } { m-1 } }} $ def update_U ( n_mu , jumlah_cluster , X , centroid ): U = [] for i in range ( len ( n_mu )): temp = [] for j in range ( len ( n_mu [ i ])): penyebut = 0 for k in range ( jumlah_cluster ): pembilang = euclidian_dist ( X [ i ], centroid [ j ]) penyebut += euclidian_dist ( X [ i ], centroid [ k ]) hasil = pembilang / penyebut hasil = round ( 1 / ( hasil ** ( 2 / ( m - 1 ))), 4 ) temp . append ( hasil ) U . append ( temp ) return U Kemudian kita dapat membuat fungsi utama yaitu, Fuzzy_CMeans(X, jumlah_cluster, m, max_iter, threshold) yang akan melakukan komputasi berdasarkan algoritma yang telah ditentukan diatas. dan akan berhenti ketika telah nilai fungsi objectif kurang dari nilai ambang batas, atau iterasi telah mencapat batas yang telah ditentukan. def Fuzzy_CMeans ( X , jumlah_cluster , m , max_iter , threshold ): mu = buat_mu ( X , jumlah_cluster ) N_mu = normalisasi_mu ( mu ) iterasi = 0 stop = True while iterasi < max_iter and stop : N = N_mu print ( 'Iterasi' , iterasi ) centroid = getCentroid ( N_mu , mu_kuad_X ( jumlah_cluster , X , mu_kuadrat ( N_mu , m ))) U = update_U ( N_mu , jumlah_cluster , X , centroid ) N_mu = normalisasi_mu ( U ) iterasi += 1 if manhatan_dist ( jumlah ( N_mu ), jumlah ( N )) < threshold : print ( 'berhenti' ) stop = False print ( pd . DataFrame ( N_mu )) dan terakhir kita dapat memanggil fungsi Fuzzy_CMeans() diatas dengan menentukan jumlah cluster adalah 3, memberikan data yang akan dicluster yang berisi dua fitur yang disimpan pada variable X, memberikan nilai m=2, nilai ambang batas adalah 0.1 dan maksimal iterasi adalah 100 kali. data2 = data . drop ( \"Nama\" , axis = 1 ) X = data2 . values m = 2 threshold = 0.1 max_iter = 100 jumlah_cluster = 3 Fuzzy_CMeans ( X , jumlah_cluster , m , max_iter , threshold ) Maka akan mengembalikan hasil seperti berikut: Iterasi 0 0 1 2 0 0.3006 0.4336 0.2658 1 0.3419 0.4051 0.2530 2 0.3500 0.3839 0.2661 3 0.3510 0.3711 0.2780 4 0.2595 0.5347 0.2058 5 0.3633 0.3782 0.2585 6 0.3198 0.5441 0.1360 7 0.4481 0.3969 0.1550 Iterasi 1 0 1 2 0 0.3275 0.3870 0.2855 1 0.3390 0.3752 0.2858 2 0.3414 0.3642 0.2944 3 0.3403 0.3571 0.3025 4 0.3185 0.4347 0.2468 5 0.3441 0.3638 0.2921 6 0.0713 0.9094 0.0193 7 0.3667 0.4039 0.2294 Iterasi 2 0 1 2 0 0.3297 0.3686 0.3017 1 0.3342 0.3625 0.3032 2 0.3349 0.3554 0.3097 3 0.3362 0.3498 0.3140 4 0.3241 0.3994 0.2765 5 0.3373 0.3544 0.3083 6 0.1465 0.7976 0.0559 7 0.3444 0.3869 0.2687 Iterasi 3 0 1 2 0 0.3287 0.3569 0.3144 1 0.3314 0.3519 0.3167 2 0.3313 0.3475 0.3211 3 0.3327 0.3444 0.3229 4 0.3239 0.3770 0.2991 5 0.3330 0.3475 0.3194 6 0.2066 0.6590 0.1344 7 0.3314 0.3703 0.2983 Iterasi 4 0 1 2 0 0.3292 0.3474 0.3234 1 0.3310 0.3443 0.3247 2 0.3303 0.3427 0.3269 3 0.3323 0.3396 0.3281 4 0.3255 0.3592 0.3153 5 0.3313 0.3414 0.3273 6 0.2711 0.4940 0.2350 7 0.3268 0.3575 0.3157 Iterasi 5 0 1 2 0 0.3303 0.3423 0.3274 1 0.3311 0.3399 0.3290 2 0.3322 0.3374 0.3304 3 0.3324 0.3367 0.3310 4 0.3296 0.3459 0.3245 5 0.3320 0.3380 0.3300 6 0.3138 0.3936 0.2925 7 0.3313 0.3431 0.3256 Iterasi 6 berhenti 0 1 2 0 0.3314 0.3373 0.3314 1 0.3319 0.3362 0.3319 2 0.3351 0.3333 0.3316 3 0.3333 0.3348 0.3319 4 0.3298 0.3405 0.3298 5 0.3320 0.3320 0.3360 6 0.3234 0.3015 0.3751 7 0.3392 0.3276 0.3333 Claster data tersebut dapat ditentukan dengan nilai derajat ke anggota tertinggi pada masing-masing cluster. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Implementasi pada Python"},{"location":"pendat/klasifikasi/","text":"Klasifikasi dengan Decision Tree \u00b6 Klasifikasi adalah masalah pengidentifikasian sekumpulan kelompok kategori yang termasuk dalam observasi baru, berdasarkan serangkaian data pelatihan yang berisi observasi dan yang kategorinya diketahui keanggotaannya. Ada beberapa model/teknik yang dapat digunakan untuk klasifikasi yaitu : Decision Tree based Methods Rule based Method Neural Networks Naive Bayes and Bayesian Belief Networks Support Vektor Machines Akan tetapi disini hanya akan dibahas tentang pengklasifikasian dengan teknik Decision Tree based Methos ( Metode berbasis pohon keputusan ) . Decision Tree based Model \u00b6 Decision tree merupakan model prediktif untuk melakukan pengamatan yang diwakili oleh cabang-cabang yang berbentuk seperti pohon untuk mendapatkan kesimpulan tentang target nilai suatu item. Model untuk membangun pohon keputusan disebut ID3 oleh J. R. Quinlan. yang menggunakan pencarian serakah top-down melalui ruang cabang yang mungkin tanpa backtracking. Untuk menentukan akar dari decision tree kita harus menentukan attribut yang memiliki nilai information gain tertinggi. Entropy \u00b6 Entropy merupakan sebagai ukuran gangguan atau ketidakmurnian suatu sistem dalam banyak contoh. Kita dapat menghitung entorpy dengan rumus berikut. $$ E(S) = \\sum \\limits_{i=1}^{n} -P_i\\text log_2 \\text P_i $$ Dimana : S = Kemurnian suatu data. P = Probabilitas kelas. Information Gain \u00b6 Information gain (IG) merupakan ukuran informasi yang diberikan oleh fitur kepada kita tentang kelas. Information gain dinyatakan dengan. $$ Gain(S,A) = entropy(S)-\\sum_{i=1}^n \\frac{|s_i|}{|s|} \\times entropy(S_i) $$ Dimana : |S| = Banyaknya data S i = Niliai dari attribut A = Attribut Manual Klasifikasi Decision Tree \u00b6 Berikut merupakan sebuah data yang akan digunakan sebagai data training dalam klasifikasi ini. Customer ID Gender Car Type Shirt Size Class 1 M Family Small C0 2 M Sports Medium C0 3 M Sports Medium C0 4 M Sports Large C0 5 M Sports Extra Large C0 6 M Sports Extra Large C0 7 F Sports Small C0 8 F Sports Small C0 9 F Sports Medium C0 10 F Luxury Large C0 11 M Family Large C1 12 M Family Extra Large C1 13 M Family Medium C1 14 M Luxury Extra Large C1 15 F Luxury Small C1 16 F Luxury Small C1 17 F Luxury Medium C1 18 F Luxury Medium C1 19 F Luxury Medium C1 20 F Luxury Large C1 Agar mempermudah dalam menghitung entropi dan information gainnya, kita dapat membentuk dan mengumpukan seperti tabel berikut: Node Attibut Value Jumlah Kasus (S) C0 C1 1 Total 20 10 10 Gender F 10 6 4 M 10 4 6 Car Type Family 4 8 0 Sport 8 1 7 Luxury 8 Shirt Size Small 5 3 2 Medium 7 3 4 Large 4 2 2 Extra Large 4 2 2 Dari tabel diatas, pertama-tama kita harus mencari nilai entropy totalnya dengan menggunakan rumus yang telah di nyatakan diatas. $ Entropy(S) = -{10\\over20} \\times ^2log_{10\\over20} + -{10\\over20} \\times ^2log_{10\\over20} $ $ E(S) = 1 $ Setalah mendapatkan nilai entropy totalnya, kita harus mendapatkan information gain dari masing-masing fitur. Fitur yang memiliki nilai information gain tertinggi nantinya akan menjadi root(akar) dari decision tree tersebut. Menghitung information gain dari fitur Gender $ G(S,Gender) = 1 - {10\\over20} \\times E(6,4) + {10\\over20} \\times E(4,6) $ $ = 1 - {10\\over20} \\times 0.97095 + {10\\over20} \\times 0.97095 $ $ = 1 - 0.97095 = 0.02905 $ Menghitung information gain dari fitur Car Type $ G(S,Car Type) = 1 - {4\\over20} \\times E(1,3) + {8\\over20} \\times E(8,0) + {8\\over20} \\times E(1,7) $ $ = 1 - {4\\over20} \\times 0.81128 + {8\\over20} \\times 0 + {8\\over20} \\times 0.54356 $ $ = 1 - 0.37968 = 0.62032 $ Menghitung information gain dari fitur Shirt Size $ G(S,Shirt Size) = 1 - {5\\over20} \\times E(3,2) + {7\\over20} \\times E(3,4) + {4\\over20} \\times E(2,2) + {4\\over20} \\times E(2,2) $ $ = 1 - {5\\over20} \\times 0.97095 + {7\\over20} \\times 0.98523 + {4\\over20} \\times 1 + {8\\over20} \\times 1 $ $ = 1 - 0.98756 = 0.12440 $ Dari perhitungan diatas, fitur Car Type merupakan fitur yang memiliki nilai information gain tertinggi. Maka kita dapat membentuk decision tree dengan Car Type sebagai akar. Selanjutnya, kita dapat mengelompokkan kembali seperti tabel berikut dengan memfilter data dengan rule, seluruh nilai dari fitur car type adalah family. Node Attribut Value Jumlah Kasus (S) C0 C1 2 Car Type=Family 4 1 3 Gender M 4 1 3 Shirt Size Small 1 1 0 Medium 1 0 1 Large 1 0 1 Extra Large 1 0 1 Kemudian kita melakukan cara yang sama seperti yang telah dilakukan sebelumnya, yaitu mendapatkan nilai entopy totalnya. $ Entropy(Family) = -{1\\over4} \\times ^2log_{1\\over4} + -{3\\over4} \\times ^2log_{3\\over4} $ $ E(Family) = 0,811278 $ Dan kita harus mencari nilai information gain dari dari masing fitur yang telah difilter. Nilai fitur tertinggi nantinya akan menjadi akar yang selanjutnya. Menghitung information gain dari fitur Gender $ G(S,M) = 0,811278 - {4\\over4} \\times E(1,3) $ $ = 0,811278 - 1 \\times 0,811278 $ $ = 0,811278 - 0,811278 = 0 $ Menghitung information gain dari fitur Shirt Size $ G(S,M) = 0,811278 - {1\\over4} \\times E(1,0) + {1\\over4} \\times E(0,1) + {1\\over4} \\times E(0,1) + {1\\over4} \\times E(0,1) $ $ = 0,811278 - (({1\\over4} \\times 0) + ({1\\over4} \\times 0) + ({1\\over4} \\times 0) + ({1\\over4} \\times 0)) $ $ = 0,811278 - 0 = 0,811278 $ Maka didapatkan nilai information gain tertinggi yaitu Shirt Size. dan kita dapat membentuk decision tree seperti berikut: Selanjutnya kita harus lakukan hal yang sama seperti diatas, akan tetapi data tersebut kita filter dengan rule, seluruh nilai dari Car Type adalah Sport. Node Attribut Value Jumlah Kasus (S) C0 C1 2 Car Type=Sport 8 8 0 Gender M 5 5 0 F 3 3 0 Shirt Size Small 3 3 0 Medium 2 2 0 Large 1 1 0 Extra Large 2 2 0 Kita dapat menghitung seperti langkah diatas. Karena attribut pada class C1 adalah 0 atau atau attibut tidak memiliki class C1, maka dapat kita buat node setelah sport adalah C0. Selanjutnya kita filter data tersebut dengan rule, seluruh nilai dari Car Type adalah Luxury. Node Attribut Value Jumlah Kasus (S) C0 C1 2 Car Type=Luxury 8 1 7 Gender M 1 0 1 F 7 1 6 Shirt Size Small 2 0 1 Medium 3 0 3 Large 2 1 1 Extra Large 1 0 1 Kemudian kita melakukan cara yang sama seperti yang telah dilakukan sebelumnya, yaitu mendapatkan nilai entopy totalnya pada attribut car type dengan nilai luxury. $ Entropy(Luxury) = -{1\\over8} \\times ^2log_{1\\over8} + -{7\\over8} \\times ^2log_{7\\over8} $ $ E(Luxury) = 0,543564 $ Dan kita harus mencari nilai information gain dari dari masing fitur yang telah difilter. Nilai fitur tertinggi nantinya akan menjadi akar. Menghitung information gain dari fitur gender $ G(S,M) = 0,543564 - {1\\over8} \\times E(0,1) + {7\\over8} \\times E(1,6) $ $ = 0,543564 - ({1\\over8} \\times 0) + ({7\\over8}\\times 0,591673)$ $ = 0,543564 - 0,517714 = 0,025851 $ Menghitung information gain dari fitur shirt size $ G(S,M) = 0,543564 - {2\\over8} \\times E(0,1) + {3\\over8} \\times E(0,3) + {2\\over8} \\times E(1,1) + {1\\over8} \\times E(0,1) $ $ = 0,543564 - (({2\\over8} \\times 0) + ({3\\over8} \\times 0) + ({2\\over8} \\times 1) + ({1\\over8} \\times 0)) $ $ = 0,543564 - 0,25 =0,293564 $ Nilai information gain tertinggi pada perhitung yaitu Shirt Size. dan kita dapat membentuk decision tree seperti berikut: Selanjutnya kita kelompokkan data berdasarkan nilai dari attibut car type dan shirt size. kita dapat membuat table hasil pengelompokan dalam bentuk seperti dibawah. Data yang difilter dengan rule, car type adalah family dan shirt size adalah small. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Small 1 1 0 Gender M 1 1 0 Data yang difilter dengan rule, car type adalah family dan shirt size adalah medium. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Medium 1 0 1 Gender M 1 0 1 Data yang difilter dengan rule, car type adalah family dan shirt size adalah large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Large 1 0 1 Gender M 1 0 1 Data yang difilter dengan rule, car type adalah family dan shirt size adalah extra large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Extra Large 1 0 1 Gender M 1 0 1 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah small. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Small 2 0 2 Gender F 2 0 2 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah medium. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Medium 3 0 3 Gender F 3 0 3 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Large 2 1 1 Gender F 2 1 1 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah extra large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Extra Large 1 0 1 Gender F 1 0 1 Dari hasil pengelompokan diatas, karena attibut hanya memiliki satu class saja yaitu, C0 atau C1. maka di dapat decision tree sebagai berikut. Penerapan Klasifikasi Decision Tree Menggunakan Python \u00b6 Alat dan Bahan \u00b6 Sebelum melakukan implementasi Klasifikasi decision tree, kita perlu untuk mempersiapkan data training dan juga libarary python yang akan membantu kita untuk menyelesaikan kasus ini. Data training yang digunakan adalah data diatas. Berikut merupakan library yang harus di persiapkan: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika. Proses \u00b6 Pertama kita harus memasukkan library yang akan membantu kita untuk melakukan klasifikasi. Selanjutnya kita dapat mamanggil data yang akan digunakan sebagai data training. import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.tree import DecisionTreeClassifier , plot_tree data = pd . read_excel ( 'klasifikasi_data.xlsx' ) df = pd . DataFrame ( data ) df . style . hide_index () Maka akan menampilkan data dalam bentuk dataframe sebagai berikut: Customer ID Gender Car Type Shirt Size Class 1 M Family Small C0 2 M Sports Medium C0 3 M Sports Medium C0 4 M Sports Large C0 5 M Sports Extra Large C0 6 M Sports Extra Large C0 7 F Sports Small C0 8 F Sports Small C0 9 F Sports Medium C0 10 F Luxury Large C0 11 M Family Large C1 12 M Family Extra Large C1 13 M Family Medium C1 14 M Luxury Extra Large C1 15 F Luxury Small C1 16 F Luxury Small C1 17 F Luxury Medium C1 18 F Luxury Medium C1 19 F Luxury Medium C1 20 F Luxury Large C1 Sklearn tidak bisa untuk memproses data berbentuk karakter, maka kita harus mengubah seluruh fitur dalam bentuk angka dengan bantuan dari modul sklearn yaitu LabelEncoder() . la = LabelEncoder () df [ 'gender_n' ] = la . fit_transform ( df [ 'Gender' ]) df [ 'car_type_n' ] = la . fit_transform ( df [ 'Car Type' ]) df [ 'shirt_size_n' ] = la . fit_transform ( df [ 'Shirt Size' ]) df [ 'class_n' ] = la . fit_transform ( df [ 'Class' ]) df . style . hide_index () Ketika ditampilkan dalam bentuk dataframe maka akan muncul seperti berikut: Customer ID Gender Car Type Shirt Size Class gender_n car_type_n shirt_size_n class_n 1 M Family Small C0 1 0 3 0 2 M Sports Medium C0 1 2 2 0 3 M Sports Medium C0 1 2 2 0 4 M Sports Large C0 1 2 1 0 5 M Sports Extra Large C0 1 2 0 0 6 M Sports Extra Large C0 1 2 0 0 7 F Sports Small C0 0 2 3 0 8 F Sports Small C0 0 2 3 0 9 F Sports Medium C0 0 2 2 0 10 F Luxury Large C0 0 1 1 0 11 M Family Large C1 1 0 1 1 12 M Family Extra Large C1 1 0 0 1 13 M Family Medium C1 1 0 2 1 14 M Luxury Extra Large C1 1 1 0 1 15 F Luxury Small C1 0 1 3 1 16 F Luxury Small C1 0 1 3 1 17 F Luxury Medium C1 0 1 2 1 18 F Luxury Medium C1 0 1 2 1 19 F Luxury Medium C1 0 1 2 1 20 F Luxury Large C1 0 1 1 1 Selanjutnya kita akan membuang fitur yang masih dalam bentuk string, dan kita akan menggukaan fitur yang telah di ubah dalam bentuk angka untuk digunakan sebagai data training. inputs = df . drop ([ 'Customer ID' , 'Gender' , 'Car Type' , 'Shirt Size' , 'Class' , 'class_n' ], axis = 'columns' ) target = df [ 'class_n' ] Dari training yang telah ambil sebelumya, disini kita lakukan klasifikasi menggunakan modul yang merupakan bawaan dari sklearn dengan kriteria berupa entorpy seperti berikut. model = DecisionTreeClassifier ( criterion = \"entropy\" , random_state = 100 ) model . fit ( inputs , target ) Selanjutnya kita dapat menvisualisasikan dalam bentuk decision tree dengan menggunakan plot_tree dari sklearn. plot_tree ( model . fit ( inputs , target ), max_depth = None , feature_names = [ 'Customer ID' , 'Gender' , 'Car Type' , 'Shirt Size' ,], class_names = [ 'C0' , 'C1' ], label = 'all' , filled = True , impurity = True , node_ids = False , proportion = True , rotate = True , rounded = True , precision = 3 , ax = None , fontsize = None ) Maka akan tampil binary tree seperti berikut. Pada proses encode diatas, kita mendapatkan hasil seperti berikut. Gender Car Type Shirt Size Class Value Encode Value Encode Value Encode Value Encode F 0 Family 1 Small 3 C0 0 M 1 Sport 2 Medium 2 C1 1 Luxury 0 Large 1 Extra Large 0 Jika terdapat data baru yang belum memiliki class, maka kita dapat melakukan prediksi. Contoh : Customer ID Gender Car Type Shirt Size Class 21 F Family Medium ? model . predict ([[ 0 , 1 , 2 ]]) Output : array([1]) Dari prediksi diatas menghasilkan nilai [1] yang artinya data tersebut masuk dalam class C1. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 4"},{"location":"pendat/klasifikasi/#klasifikasi-dengan-decision-tree","text":"Klasifikasi adalah masalah pengidentifikasian sekumpulan kelompok kategori yang termasuk dalam observasi baru, berdasarkan serangkaian data pelatihan yang berisi observasi dan yang kategorinya diketahui keanggotaannya. Ada beberapa model/teknik yang dapat digunakan untuk klasifikasi yaitu : Decision Tree based Methods Rule based Method Neural Networks Naive Bayes and Bayesian Belief Networks Support Vektor Machines Akan tetapi disini hanya akan dibahas tentang pengklasifikasian dengan teknik Decision Tree based Methos ( Metode berbasis pohon keputusan ) .","title":"Klasifikasi dengan Decision Tree"},{"location":"pendat/klasifikasi/#decision-tree-based-model","text":"Decision tree merupakan model prediktif untuk melakukan pengamatan yang diwakili oleh cabang-cabang yang berbentuk seperti pohon untuk mendapatkan kesimpulan tentang target nilai suatu item. Model untuk membangun pohon keputusan disebut ID3 oleh J. R. Quinlan. yang menggunakan pencarian serakah top-down melalui ruang cabang yang mungkin tanpa backtracking. Untuk menentukan akar dari decision tree kita harus menentukan attribut yang memiliki nilai information gain tertinggi.","title":"Decision Tree based Model"},{"location":"pendat/klasifikasi/#entropy","text":"Entropy merupakan sebagai ukuran gangguan atau ketidakmurnian suatu sistem dalam banyak contoh. Kita dapat menghitung entorpy dengan rumus berikut. $$ E(S) = \\sum \\limits_{i=1}^{n} -P_i\\text log_2 \\text P_i $$ Dimana : S = Kemurnian suatu data. P = Probabilitas kelas.","title":"Entropy"},{"location":"pendat/klasifikasi/#information-gain","text":"Information gain (IG) merupakan ukuran informasi yang diberikan oleh fitur kepada kita tentang kelas. Information gain dinyatakan dengan. $$ Gain(S,A) = entropy(S)-\\sum_{i=1}^n \\frac{|s_i|}{|s|} \\times entropy(S_i) $$ Dimana : |S| = Banyaknya data S i = Niliai dari attribut A = Attribut","title":"Information Gain"},{"location":"pendat/klasifikasi/#manual-klasifikasi-decision-tree","text":"Berikut merupakan sebuah data yang akan digunakan sebagai data training dalam klasifikasi ini. Customer ID Gender Car Type Shirt Size Class 1 M Family Small C0 2 M Sports Medium C0 3 M Sports Medium C0 4 M Sports Large C0 5 M Sports Extra Large C0 6 M Sports Extra Large C0 7 F Sports Small C0 8 F Sports Small C0 9 F Sports Medium C0 10 F Luxury Large C0 11 M Family Large C1 12 M Family Extra Large C1 13 M Family Medium C1 14 M Luxury Extra Large C1 15 F Luxury Small C1 16 F Luxury Small C1 17 F Luxury Medium C1 18 F Luxury Medium C1 19 F Luxury Medium C1 20 F Luxury Large C1 Agar mempermudah dalam menghitung entropi dan information gainnya, kita dapat membentuk dan mengumpukan seperti tabel berikut: Node Attibut Value Jumlah Kasus (S) C0 C1 1 Total 20 10 10 Gender F 10 6 4 M 10 4 6 Car Type Family 4 8 0 Sport 8 1 7 Luxury 8 Shirt Size Small 5 3 2 Medium 7 3 4 Large 4 2 2 Extra Large 4 2 2 Dari tabel diatas, pertama-tama kita harus mencari nilai entropy totalnya dengan menggunakan rumus yang telah di nyatakan diatas. $ Entropy(S) = -{10\\over20} \\times ^2log_{10\\over20} + -{10\\over20} \\times ^2log_{10\\over20} $ $ E(S) = 1 $ Setalah mendapatkan nilai entropy totalnya, kita harus mendapatkan information gain dari masing-masing fitur. Fitur yang memiliki nilai information gain tertinggi nantinya akan menjadi root(akar) dari decision tree tersebut. Menghitung information gain dari fitur Gender $ G(S,Gender) = 1 - {10\\over20} \\times E(6,4) + {10\\over20} \\times E(4,6) $ $ = 1 - {10\\over20} \\times 0.97095 + {10\\over20} \\times 0.97095 $ $ = 1 - 0.97095 = 0.02905 $ Menghitung information gain dari fitur Car Type $ G(S,Car Type) = 1 - {4\\over20} \\times E(1,3) + {8\\over20} \\times E(8,0) + {8\\over20} \\times E(1,7) $ $ = 1 - {4\\over20} \\times 0.81128 + {8\\over20} \\times 0 + {8\\over20} \\times 0.54356 $ $ = 1 - 0.37968 = 0.62032 $ Menghitung information gain dari fitur Shirt Size $ G(S,Shirt Size) = 1 - {5\\over20} \\times E(3,2) + {7\\over20} \\times E(3,4) + {4\\over20} \\times E(2,2) + {4\\over20} \\times E(2,2) $ $ = 1 - {5\\over20} \\times 0.97095 + {7\\over20} \\times 0.98523 + {4\\over20} \\times 1 + {8\\over20} \\times 1 $ $ = 1 - 0.98756 = 0.12440 $ Dari perhitungan diatas, fitur Car Type merupakan fitur yang memiliki nilai information gain tertinggi. Maka kita dapat membentuk decision tree dengan Car Type sebagai akar. Selanjutnya, kita dapat mengelompokkan kembali seperti tabel berikut dengan memfilter data dengan rule, seluruh nilai dari fitur car type adalah family. Node Attribut Value Jumlah Kasus (S) C0 C1 2 Car Type=Family 4 1 3 Gender M 4 1 3 Shirt Size Small 1 1 0 Medium 1 0 1 Large 1 0 1 Extra Large 1 0 1 Kemudian kita melakukan cara yang sama seperti yang telah dilakukan sebelumnya, yaitu mendapatkan nilai entopy totalnya. $ Entropy(Family) = -{1\\over4} \\times ^2log_{1\\over4} + -{3\\over4} \\times ^2log_{3\\over4} $ $ E(Family) = 0,811278 $ Dan kita harus mencari nilai information gain dari dari masing fitur yang telah difilter. Nilai fitur tertinggi nantinya akan menjadi akar yang selanjutnya. Menghitung information gain dari fitur Gender $ G(S,M) = 0,811278 - {4\\over4} \\times E(1,3) $ $ = 0,811278 - 1 \\times 0,811278 $ $ = 0,811278 - 0,811278 = 0 $ Menghitung information gain dari fitur Shirt Size $ G(S,M) = 0,811278 - {1\\over4} \\times E(1,0) + {1\\over4} \\times E(0,1) + {1\\over4} \\times E(0,1) + {1\\over4} \\times E(0,1) $ $ = 0,811278 - (({1\\over4} \\times 0) + ({1\\over4} \\times 0) + ({1\\over4} \\times 0) + ({1\\over4} \\times 0)) $ $ = 0,811278 - 0 = 0,811278 $ Maka didapatkan nilai information gain tertinggi yaitu Shirt Size. dan kita dapat membentuk decision tree seperti berikut: Selanjutnya kita harus lakukan hal yang sama seperti diatas, akan tetapi data tersebut kita filter dengan rule, seluruh nilai dari Car Type adalah Sport. Node Attribut Value Jumlah Kasus (S) C0 C1 2 Car Type=Sport 8 8 0 Gender M 5 5 0 F 3 3 0 Shirt Size Small 3 3 0 Medium 2 2 0 Large 1 1 0 Extra Large 2 2 0 Kita dapat menghitung seperti langkah diatas. Karena attribut pada class C1 adalah 0 atau atau attibut tidak memiliki class C1, maka dapat kita buat node setelah sport adalah C0. Selanjutnya kita filter data tersebut dengan rule, seluruh nilai dari Car Type adalah Luxury. Node Attribut Value Jumlah Kasus (S) C0 C1 2 Car Type=Luxury 8 1 7 Gender M 1 0 1 F 7 1 6 Shirt Size Small 2 0 1 Medium 3 0 3 Large 2 1 1 Extra Large 1 0 1 Kemudian kita melakukan cara yang sama seperti yang telah dilakukan sebelumnya, yaitu mendapatkan nilai entopy totalnya pada attribut car type dengan nilai luxury. $ Entropy(Luxury) = -{1\\over8} \\times ^2log_{1\\over8} + -{7\\over8} \\times ^2log_{7\\over8} $ $ E(Luxury) = 0,543564 $ Dan kita harus mencari nilai information gain dari dari masing fitur yang telah difilter. Nilai fitur tertinggi nantinya akan menjadi akar. Menghitung information gain dari fitur gender $ G(S,M) = 0,543564 - {1\\over8} \\times E(0,1) + {7\\over8} \\times E(1,6) $ $ = 0,543564 - ({1\\over8} \\times 0) + ({7\\over8}\\times 0,591673)$ $ = 0,543564 - 0,517714 = 0,025851 $ Menghitung information gain dari fitur shirt size $ G(S,M) = 0,543564 - {2\\over8} \\times E(0,1) + {3\\over8} \\times E(0,3) + {2\\over8} \\times E(1,1) + {1\\over8} \\times E(0,1) $ $ = 0,543564 - (({2\\over8} \\times 0) + ({3\\over8} \\times 0) + ({2\\over8} \\times 1) + ({1\\over8} \\times 0)) $ $ = 0,543564 - 0,25 =0,293564 $ Nilai information gain tertinggi pada perhitung yaitu Shirt Size. dan kita dapat membentuk decision tree seperti berikut: Selanjutnya kita kelompokkan data berdasarkan nilai dari attibut car type dan shirt size. kita dapat membuat table hasil pengelompokan dalam bentuk seperti dibawah. Data yang difilter dengan rule, car type adalah family dan shirt size adalah small. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Small 1 1 0 Gender M 1 1 0 Data yang difilter dengan rule, car type adalah family dan shirt size adalah medium. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Medium 1 0 1 Gender M 1 0 1 Data yang difilter dengan rule, car type adalah family dan shirt size adalah large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Large 1 0 1 Gender M 1 0 1 Data yang difilter dengan rule, car type adalah family dan shirt size adalah extra large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Family, Shirt Size=Extra Large 1 0 1 Gender M 1 0 1 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah small. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Small 2 0 2 Gender F 2 0 2 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah medium. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Medium 3 0 3 Gender F 3 0 3 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Large 2 1 1 Gender F 2 1 1 Data yang difilter dengan rule, car type adalah luxury dan shirt size adalah extra large. Node Attribut Value Jumlah Kasus (S) C0 C1 3 Car Type=Luxury, Shirt Size=Extra Large 1 0 1 Gender F 1 0 1 Dari hasil pengelompokan diatas, karena attibut hanya memiliki satu class saja yaitu, C0 atau C1. maka di dapat decision tree sebagai berikut.","title":"Manual Klasifikasi Decision Tree"},{"location":"pendat/klasifikasi/#penerapan-klasifikasi-decision-tree-menggunakan-python","text":"","title":"Penerapan Klasifikasi Decision Tree Menggunakan Python"},{"location":"pendat/klasifikasi/#alat-dan-bahan","text":"Sebelum melakukan implementasi Klasifikasi decision tree, kita perlu untuk mempersiapkan data training dan juga libarary python yang akan membantu kita untuk menyelesaikan kasus ini. Data training yang digunakan adalah data diatas. Berikut merupakan library yang harus di persiapkan: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika.","title":"Alat dan Bahan"},{"location":"pendat/klasifikasi/#proses","text":"Pertama kita harus memasukkan library yang akan membantu kita untuk melakukan klasifikasi. Selanjutnya kita dapat mamanggil data yang akan digunakan sebagai data training. import pandas as pd from sklearn.preprocessing import LabelEncoder from sklearn.tree import DecisionTreeClassifier , plot_tree data = pd . read_excel ( 'klasifikasi_data.xlsx' ) df = pd . DataFrame ( data ) df . style . hide_index () Maka akan menampilkan data dalam bentuk dataframe sebagai berikut: Customer ID Gender Car Type Shirt Size Class 1 M Family Small C0 2 M Sports Medium C0 3 M Sports Medium C0 4 M Sports Large C0 5 M Sports Extra Large C0 6 M Sports Extra Large C0 7 F Sports Small C0 8 F Sports Small C0 9 F Sports Medium C0 10 F Luxury Large C0 11 M Family Large C1 12 M Family Extra Large C1 13 M Family Medium C1 14 M Luxury Extra Large C1 15 F Luxury Small C1 16 F Luxury Small C1 17 F Luxury Medium C1 18 F Luxury Medium C1 19 F Luxury Medium C1 20 F Luxury Large C1 Sklearn tidak bisa untuk memproses data berbentuk karakter, maka kita harus mengubah seluruh fitur dalam bentuk angka dengan bantuan dari modul sklearn yaitu LabelEncoder() . la = LabelEncoder () df [ 'gender_n' ] = la . fit_transform ( df [ 'Gender' ]) df [ 'car_type_n' ] = la . fit_transform ( df [ 'Car Type' ]) df [ 'shirt_size_n' ] = la . fit_transform ( df [ 'Shirt Size' ]) df [ 'class_n' ] = la . fit_transform ( df [ 'Class' ]) df . style . hide_index () Ketika ditampilkan dalam bentuk dataframe maka akan muncul seperti berikut: Customer ID Gender Car Type Shirt Size Class gender_n car_type_n shirt_size_n class_n 1 M Family Small C0 1 0 3 0 2 M Sports Medium C0 1 2 2 0 3 M Sports Medium C0 1 2 2 0 4 M Sports Large C0 1 2 1 0 5 M Sports Extra Large C0 1 2 0 0 6 M Sports Extra Large C0 1 2 0 0 7 F Sports Small C0 0 2 3 0 8 F Sports Small C0 0 2 3 0 9 F Sports Medium C0 0 2 2 0 10 F Luxury Large C0 0 1 1 0 11 M Family Large C1 1 0 1 1 12 M Family Extra Large C1 1 0 0 1 13 M Family Medium C1 1 0 2 1 14 M Luxury Extra Large C1 1 1 0 1 15 F Luxury Small C1 0 1 3 1 16 F Luxury Small C1 0 1 3 1 17 F Luxury Medium C1 0 1 2 1 18 F Luxury Medium C1 0 1 2 1 19 F Luxury Medium C1 0 1 2 1 20 F Luxury Large C1 0 1 1 1 Selanjutnya kita akan membuang fitur yang masih dalam bentuk string, dan kita akan menggukaan fitur yang telah di ubah dalam bentuk angka untuk digunakan sebagai data training. inputs = df . drop ([ 'Customer ID' , 'Gender' , 'Car Type' , 'Shirt Size' , 'Class' , 'class_n' ], axis = 'columns' ) target = df [ 'class_n' ] Dari training yang telah ambil sebelumya, disini kita lakukan klasifikasi menggunakan modul yang merupakan bawaan dari sklearn dengan kriteria berupa entorpy seperti berikut. model = DecisionTreeClassifier ( criterion = \"entropy\" , random_state = 100 ) model . fit ( inputs , target ) Selanjutnya kita dapat menvisualisasikan dalam bentuk decision tree dengan menggunakan plot_tree dari sklearn. plot_tree ( model . fit ( inputs , target ), max_depth = None , feature_names = [ 'Customer ID' , 'Gender' , 'Car Type' , 'Shirt Size' ,], class_names = [ 'C0' , 'C1' ], label = 'all' , filled = True , impurity = True , node_ids = False , proportion = True , rotate = True , rounded = True , precision = 3 , ax = None , fontsize = None ) Maka akan tampil binary tree seperti berikut. Pada proses encode diatas, kita mendapatkan hasil seperti berikut. Gender Car Type Shirt Size Class Value Encode Value Encode Value Encode Value Encode F 0 Family 1 Small 3 C0 0 M 1 Sport 2 Medium 2 C1 1 Luxury 0 Large 1 Extra Large 0 Jika terdapat data baru yang belum memiliki class, maka kita dapat melakukan prediksi. Contoh : Customer ID Gender Car Type Shirt Size Class 21 F Family Medium ? model . predict ([[ 0 , 1 , 2 ]]) Output : array([1]) Dari prediksi diatas menghasilkan nilai [1] yang artinya data tersebut masuk dalam class C1. MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Proses"},{"location":"pendat/missing knn/","text":"Missing Value dengan Algoritma K-NN \u00b6 Missing Values \u00b6 Missing Values (nilai yang hilang) adalah kejadian umum, dimana nilai yang hilang dapat menandakan sejumlah hal berbeda dalam data. Dan mungkin data tidak tersedia atau tidak berlaku. Missing value biasanya disebabkan oleh orang yang memasukkan data dan tidak tahu nilai yang benar, atau tidak mengisinya. Metode penambangan data bervariasi dalam cara mereka memperlakukan nilai yang hilang. Biasanya, mereka mengabaikan nilai yang hilang, atau mengecualikan catatan yang berisi nilai yang hilang, atau mengganti nilai yang hilang dengan nilai tengah, atau menyimpulkan nilai yang hilang dari nilai yang ada. Algoritma K-NN (k-Nearest Neighbors) \u00b6 Algoritma K-Nearest Naighbors adalah suatu algoritma klasifikasi sederhana yang dapat digunakan untuk memprediksi klasifikasi dan regresi. Algoritma ini memiliki tujuan untuk mengklasifikasi objek baru berdasarkan atribut dan sample-sample data training. langkah penyelesaian yang dilakukan oleh algoritma tersebut adalah: Kita harus menentukan jumlah tetangga terdekat yang nantinya akan kita hitung. Misalnya : kita menentukan 2 tetangga terdekat (k=2). Hitung jarak objek yang dipilih dengan seluruh tetangga yang ada. kemudian urutkan berdasarkan jarak yang diperoleh dari yang terkecil hingga ke terbesar. Ambil 2 tetangga yang paling dekat atau nilai jarak yang terkecil, dan ambil rata-ratanya. Mengatasi Missing Value Menggunakan Algoritma K-NN pada Python \u00b6 Alat dan Bahan \u00b6 Pada kasus kali ini, saya menggunakan dataset dari internet, yang bisa diunduh disini . Pada dataset tersebut terdapat 1 fitur bertipe binary dan 5 fitur bertipe numerikal. Pada fitur age dataset telah saya modif dengan mengubah dalam bentuk .csv dan memberikan missing value pada baris ke-257. Untuk mempermudah dalam penyelesaian kasus ini, perlu di siapkan library python untuk mempermudah dalam pengerjaan. Library ini dapat di unduh secara gratis dari internet. Berikut merupakan library yang harus di persiapkan: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika. Pertama \u00b6 Langkah pertama yang harus dilakukan adalah memasukkan library yang telah diunduh sebelumnya. import pandas as pd import math as mt from sklearn.preprocessing import LabelEncoder Kedua \u00b6 Selanjutnya kita mengambil file csv tersebut. data = pd . read_csv ( 'Wong.csv' , delimiter = ';' , decimal = ',' ) df = pd . DataFrame ( data ) df . style . highlight_null ( null_color = 'red' ) . hide_index () Maka akan tampil sebagai barikut: no id days duration sex age piq viq 1 3358 30 4 Male 20.6708 87 89 2 3535 16 17 Male 55.2882 95 77 3 3547 40 1 Male 55.9151 95 116 4 3592 13 10 Male 61.6646 59 73 5 3728 19 6 Male 30.1273 67 73 6 3790 13 3 Male 57.0623 76 69 7 3807 37 5 Male 24.6762 74 77 8 3808 31 7 Male 28.2683 91 110 9 4253 40 3 Male 22.6037 115 110 10 4356 31 7 Male 21.399 86 83 11 4384 35 8 Male 36.3806 76 90 12 4542 22 11 Female 21.9576 71 89 13 4705 18 1 Female 21.6838 127 109 14 4744 15 25 Male 57.566 82 85 15 4802 36 0 Male 62.475 88 97 16 4941 46 4 Female 19.0144 69 88 17 4983 33 5 Male 38.3929 102 117 18 5129 26 1 Male 25.0459 77 89 19 5154 35 5 Male 22.1903 82 95 20 5162 33 1 Male 25.0185 118 101 21 5174 38 4 Female 37.2704 87 99 22 5208 31 8 Female 21.3771 97 90 23 5253 29 1 Male 33.1335 104 105 24 5298 30 3 Male 22.9569 87 86 25 5640 34 7 Male 25.9986 93 113 26 5668 27 7 Male 40.9227 72 79 27 5680 17 1 Male 27.7563 84 90 28 5699 26 1 Female 34.2231 95 108 29 5713 36 8 Male 16.2683 89 97 30 5736 18 9 Male 16.1478 89 86 31 5754 36 1 Male 16.3368 87 86 32 5776 26 8 Male 17.128 71 88 33 6122 29 1 Male 56.2108 95 103 34 6163 21 1 Male 19.3593 112 106 35 6179 22 2 Male 38.0123 89 95 36 6671 30 7 Female 27.8056 71 82 37 6859 27 1 Male 34.2122 74 79 38 6870 22 0 Male 42.4832 84 95 39 6914 43 0 Male 61.5222 85 90 40 6937 18 0 Female 21.191 94 81 41 6977 30 1 Male 36.2108 97 94 42 7120 39 0 Male 69.7057 84 86 43 7309 31 0 Female 50.6667 85 95 44 7321 23 0 Male 26.0041 84 83 45 7548 31 0 Male 24.3669 108 106 46 2364 41 14 Male 25.8097 84 94 47 2600 3333 9 Male 43.9398 86 80 48 2761 40 3 Female 24.3696 98 112 49 3237 65 9 Male 49.8508 67 67 50 3277 51 1 Male 37.4702 104 96 51 3346 44 18 Female 57.2758 79 85 52 3359 59 9 Female 56.8953 84 91 53 3373 39 28 Female 26.308 87 91 54 3544 32 14 Male 54.5298 81 98 55 3655 57 5 Female 21.9055 90 103 56 3762 48 6 Male 20.3559 85 93 57 3919 58 1 Male 30.3655 99 95 58 4094 50 2 Male 19.7262 79 93 59 4133 34 14 Male 20 70 88 60 4183 42 3 Male 26.2341 98 116 61 4189 69 4 Female 29.462 75 86 62 4315 63 0 Male 38.141 107 130 63 4482 58 14 Female 18.2341 86 103 64 4638 20 17 Male 20.512 82 72 65 4678 63 7 Male 46.6448 96 95 66 4696 54 4 Male 46.9569 101 112 67 4755 24 18 Male 27.5127 105 102 68 4837 42 10 Male 19.6906 83 88 69 4996 51 12 Male 43.0281 77 78 70 5009 50 7 Male 24.3806 61 104 71 5014 46 7 Female 23.7618 75 90 72 5192 60 1 Male 58.6283 87 97 73 5204 71 0 Male 59.0746 97 107 74 5238 44 3 Male 45.1006 99 103 75 5280 83 1 Male 48.6434 78 88 76 5289 52 1 Male 48.5722 84 85 77 5456 48 14 Male 41.1636 80 101 78 5458 44 14 Male 34.4778 84 95 79 5474 65 2 Female 28.6598 95 86 80 5568 64 1 Female 51.9918 75 79 81 5580 56 7 Male 17.7933 86 95 82 5581 65 2 Male 26.3053 85 95 83 5628 51 3 Female 30.2642 81 85 84 6154 43 5 Female 22.6064 74 80 85 6180 59 12 Male 20.7201 67 84 86 6314 58 3 Male 16.6927 80 99 87 6340 71 0 Male 19.3238 76 72 88 6564 69 0 Male 34.4997 67 74 89 6614 57 0 Male 45.1116 80 101 90 6686 44 14 Female 38.3491 90 100 91 6795 55 0 Male 30.7159 87 104 92 7080 64 5 Female 76.6598 76 106 93 7084 54 2 Male 36.5722 87 93 94 7271 55 0 Male 41.7659 100 95 95 7371 55 1 Male 56.7858 80 88 96 2569 49 35 Male 18.7159 50 101 97 3058 56 28 Male 22.2533 65 75 98 3645 43 45 Male 27.4935 72 90 99 3844 73 9 Male 26.1164 79 94 100 4725 124 10 Male 32.9172 93 97 101 4744 65 25 Male 57.566 105 119 102 4807 64 14 Female 47.7974 74 74 103 4892 62 21 Male 22.0397 76 88 104 4962 63 1 Female 25.1964 69 67 105 5125 78 12 Male 17.5387 94 118 106 5222 63 30 Male 22.5298 77 85 107 5253 86 1 Male 33.1335 106 128 108 5386 78 21 Male 20.8761 78 93 109 5534 87 14 Male 29.2621 75 82 110 5712 88 14 Male 22.2697 70 68 111 5837 82 1 Female 33.3087 82 110 112 5879 75 21 Male 25.8453 80 105 113 5893 71 21 Male 22.8118 65 90 114 5916 84 0 Female 26.8556 93 73 115 6410 80 14 Male 32.1725 85 98 116 7173 84 4 Male 24.9801 72 75 117 7221 98 0 Male 63.5044 74 79 118 2453 120 10 Male 37.2758 63 99 119 2653 97 28 Male 30.0068 93 112 120 4218 82 28 Male 25.9904 74 92 121 4542 121 11 Female 21.9576 86 114 122 4902 102 8 Male 16.1424 87 77 123 4933 134 0 Male 18.4559 69 83 124 4941 131 4 Female 19.0144 96 96 125 5085 117 2 Male 49.0267 67 71 126 5111 107 7 Male 21.6947 71 80 127 5154 120 5 Male 22.1903 89 109 128 5222 93 30 Male 22.5298 77 91 129 5298 107 3 Male 22.9569 117 112 130 5339 119 7 Male 21.8152 87 82 131 5387 109 12 Male 21.7988 85 112 132 5414 105 10 Female 40.2765 93 104 133 5494 111 7 Male 54.6913 86 86 134 5896 126 4 Female 26.8775 50 74 135 5901 115 7 Male 22.1739 112 116 136 6135 96 18 Male 26.5626 66 105 137 6173 125 4 Male 35.3046 94 97 138 6214 112 0 Male 60.3176 65 74 139 6253 128 0 Female 46.4038 104 112 140 6433 120 4 Male 23.8604 100 103 141 6665 119 3 Female 23.0171 106 94 142 6834 123 0 Male 30.7488 72 75 143 1176 146 17 Female 19.729 65 98 144 2849 151 0 Male 20.0876 51 86 145 2882 141 18 Male 19.2334 84 85 146 3051 131 13 Male 37.2403 68 79 147 3728 151 6 Male 30.1273 96 105 148 3913 96 42 Female 23.9233 56 80 149 4133 133 14 Male 20 82 94 150 4661 135 17 Female 30.8419 84 93 151 4678 143 7 Male 46.6448 98 107 152 4696 150 4 Male 46.9569 120 120 153 4705 146 1 Female 21.6838 133 111 154 4802 142 0 Male 62.475 101 117 155 4807 139 14 Female 47.7974 80 78 156 4983 146 5 Male 38.3929 107 123 157 5014 151 7 Female 23.7618 97 110 158 5162 144 1 Male 25.0185 130 118 159 5238 150 3 Male 45.1006 117 126 160 5642 162 0 Male 65.87 89 103 161 5699 138 1 Female 34.2231 110 107 162 5713 144 8 Male 16.2683 100 99 163 5804 159 2 Female 28.8515 102 107 164 5818 125 14 Male 34.9268 72 91 165 6314 140 3 Male 16.6927 87 96 166 6664 164 2 Male 24.7337 66 73 167 1048 85 94 Male 20.115 63 82 168 1085 159 11 Male 30.7105 103 97 169 3237 189 9 Male 49.8508 79 82 170 3358 175 4 Male 20.6708 97 97 171 3808 165 7 Male 28.2683 94 111 172 4094 177 2 Male 19.7262 89 102 173 4253 175 3 Male 22.6037 114 118 174 4638 140 17 Male 20.512 89 78 175 4755 128 18 Male 27.5127 105 109 176 4865 142 35 Male 58.3354 84 103 177 4892 148 21 Male 22.0397 106 110 178 5009 174 7 Male 24.3806 77 103 179 5111 177 7 Male 21.6947 72 81 180 5125 173 12 Male 17.5387 106 119 181 5192 179 1 Male 58.6283 93 105 182 5505 171 1 Male 65.4784 95 93 183 5581 176 2 Male 26.3053 96 110 184 5599 148 21 Male 18.7488 72 81 185 5680 184 1 Male 27.7563 84 90 186 5782 108 68 Female 19.6715 69 85 187 6180 177 12 Male 20.7201 81 94 188 6671 184 7 Female 27.8056 91 92 189 2124 173 30 Male 30.7625 76 106 190 2646 187 14 Male 22.9158 97 97 191 2790 211 0 Male 48.8049 89 99 192 4189 202 4 Female 29.462 81 90 193 4775 180 28 Male 53.5551 70 86 194 4933 226 0 Male 18.4559 79 86 195 4962 210 1 Female 25.1964 71 70 196 5208 193 8 Female 21.3771 133 111 197 5456 193 14 Male 41.1636 87 110 198 5668 219 7 Male 40.9227 76 90 199 5712 192 14 Male 22.2697 87 85 200 5893 200 21 Male 22.8118 65 89 201 5916 205 0 Female 26.8556 92 76 202 6122 212 1 Male 56.2108 109 117 203 6136 216 1 Male 32.7912 92 89 204 6175 278 1 Male 51.1704 99 98 205 6228 174 3 Female 31.5537 114 108 206 7173 210 4 Male 24.9801 79 78 207 1176 216 17 Female 19.729 74 100 208 3467 186 42 Male 25.3936 53 69 209 4744 217 25 Male 57.566 108 118 210 5386 241 21 Male 20.8761 80 94 211 5837 242 1 Female 33.3087 93 105 212 6247 228 13 Male 42.3162 77 80 213 1892 276 2 Male 21.7796 87 107 214 2882 262 18 Male 19.2334 94 90 215 3058 236 28 Male 22.2533 85 88 216 4342 263 1 Male 44.063 79 91 217 4865 240 35 Male 58.3354 93 105 218 5085 269 2 Male 49.0267 65 77 219 5222 247 30 Male 22.5298 88 85 220 5339 271 7 Male 21.8152 94 89 221 5474 280 2 Female 28.6598 99 91 222 5600 232 0 Male 48.7885 75 81 223 2826 290 14 Male 23.2334 94 108 224 4725 286 10 Male 32.9172 105 94 225 5204 299 0 Male 59.0746 99 105 226 6498 270 28 Male 24.0767 82 101 227 2081 185 43 Male 17.6975 77 97 228 4678 340 7 Male 46.6448 108 119 229 5397 328 0 Female 62.7981 121 108 230 6214 318 0 Male 60.3176 78 82 231 7034 280 60 Male 23.1376 78 80 232 1493 453 60 Male 17.8042 59 81 233 1836 375 1 Male 47.0554 101 108 234 1939 295 130 Male 28.2738 67 117 235 2646 438 14 Male 22.9158 98 94 236 2653 352 28 Male 30.0068 105 126 237 3226 444 0 Male 27.4552 76 64 238 3467 333 42 Male 25.3936 68 74 239 4342 432 1 Male 44.063 92 107 240 4542 431 11 Female 21.9576 98 114 241 4661 374 17 Female 30.8419 93 95 242 4902 397 8 Male 16.1424 92 86 243 4983 398 5 Male 38.3929 121 132 244 5111 442 7 Male 21.6947 77 86 245 5125 510 12 Male 17.5387 112 125 246 5289 417 1 Male 48.5722 83 83 247 5386 436 21 Male 20.8761 90 103 248 5387 480 12 Male 21.7988 94 116 249 5505 527 1 Male 65.4784 104 87 250 5580 369 7 Male 17.7933 96 107 251 5581 378 2 Male 26.3053 95 95 252 5599 443 21 Male 18.7488 78 80 253 5668 390 7 Male 40.9227 92 92 254 5680 403 1 Male 27.7563 94 93 255 5712 365 14 Male 22.2697 98 86 256 5772 412 35 Male 26.2587 102 104 257 5804 354 2 Female nan 122 105 258 5811 431 25 Male 80.0328 78 80 259 5841 415 8 Male 27.2279 82 83 260 6226 438 0 Male 36.8022 84 92 261 6247 389 13 Male 42.3162 82 80 262 6468 513 60 Male 43.4798 99 94 263 6614 362 0 Male 45.1116 88 106 264 6665 368 3 Female 23.0171 100 92 265 781 714 15 Male 29.8699 85 85 266 1048 576 94 Male 20.115 91 96 267 1157 810 23 Male 17.3881 97 84 268 1493 684 60 Male 17.8042 66 75 269 1611 511 60 Male 23.2799 69 107 270 1624 604 1 Male 19.5619 97 85 271 1939 562 130 Male 28.2738 85 111 272 2498 615 0 Female 17.4292 86 113 273 2826 636 14 Male 23.2334 111 101 274 2849 642 0 Male 20.0876 76 98 275 3032 525 20 Male 16.9391 79 87 276 3226 683 0 Male 27.4552 89 78 277 4218 814 28 Male 25.9904 99 96 278 4807 532 14 Female 47.7974 84 82 279 5014 637 7 Female 23.7618 101 114 280 5222 690 30 Male 22.5298 81 90 281 5253 591 1 Male 33.1335 114 124 282 5628 609 3 Female 30.2642 89 78 283 6059 794 1 Female 16.9801 71 76 284 6228 662 3 Female 31.5537 128 111 285 6247 616 13 Male 42.3162 85 82 286 405 986 0 Male 21.4702 66 116 287 626 870 55 Male 19.7536 80 85 288 1075 907 42 Female 27.2772 63 64 289 2849 1040 0 Male 20.0876 91 103 290 3032 884 20 Male 16.9391 87 93 291 3226 1123 0 Male 27.4552 88 81 292 4864 936 0 Female 53.9767 119 131 293 5474 1100 2 Female 28.6598 94 88 294 5568 1114 1 Female 51.9918 81 82 295 5580 1087 7 Male 17.7933 106 98 296 5581 1113 2 Male 26.3053 99 96 297 5617 1113 17 Male 19.7864 78 87 298 5642 1143 0 Male 65.87 104 109 299 5713 1016 8 Male 16.2683 126 106 300 5837 962 1 Female 33.3087 109 110 301 6140 1077 44 Female 21.4209 65 88 302 7061 923 0 Male 36.8816 74 81 303 651 1491 21 Male 22.0068 71 94 304 2527 1294 0 Male 16.9172 93 104 305 2638 1093 255 Male 16.5613 78 84 306 4865 1363 35 Male 58.3354 88 104 307 5009 1537 7 Male 24.3806 76 112 308 5014 1523 7 Female 23.7618 105 114 309 5085 1512 2 Male 49.0267 75 75 310 1939 1926 130 Male 28.2738 95 108 311 2662 1569 180 Male 28.0821 90 101 312 2826 1809 14 Male 23.2334 104 108 313 2882 1716 18 Male 19.2334 100 103 314 3768 1916 0 Male 19.1102 69 80 315 4356 2000 7 Male 21.399 104 91 316 4638 1779 17 Male 20.512 92 76 317 4696 1769 4 Male 46.9569 105 124 318 4744 1743 25 Male 57.566 97 118 319 6140 1742 44 Female 21.4209 67 87 320 1075 2259 42 Female 27.2772 78 79 321 1939 3111 130 Male 28.2738 88 111 322 2653 2191 28 Male 30.0068 117 129 323 3592 2569 10 Male 61.6646 76 93 324 3808 2434 7 Male 28.2683 105 111 325 651 3412 21 Male 22.0068 68 92 326 1939 3864 130 Male 28.2738 88 105 327 2600 3337 9 Male 43.9398 101 84 328 3835 4933 14 Male 25.9932 91 88 329 2773 7631 42 Male 6.51335 88 103 330 5142 11628 57 Male 16.4326 101 95 331 5964 11038 0 Male 12.8363 71 73 Ketiga \u00b6 Pada langkah ini mengubah nilai dari fitur sex menjadi angak 0 / 1 dengan menggunakan fungsi dari sklearn, yaitu LabelEncode() . #encode fitur tipe biner X = data . iloc [:,:] . values labelEncode_X = LabelEncoder () X [:, 4 ] = labelEncode_X . fit_transform ( X [:, 4 ]) Keempat \u00b6 Selanjutnya kita mengimplementasikan rumus jarak ke dalam bentuk fungsi python. yaitu: eulidianDistance() dengan fungsi jarak tipe binary distanceSimetris (). def Zscore ( x , mean , std ): top = x - mean if top == 0 : return top else : return round ( top / std , 2 ) def normalisasi ( num , col_x ): return Zscore ( num , pd . Series ( data [ col_x ] . values ) . mean (), pd . Series ( data [ col_x ] . values ) . std ()) #menghitung jarak tipe numerikal def euclidianDistance ( x , y ): dis = 0 for i in range ( len ( x )): dis += ( x [ i ] - y [ i ]) ** 2 return round ( mt . sqrt ( dis ), 2 ) #Menghitung jarak tipe binary def distanceSimetris ( x , y ): q = r = s = t = 0 for i in range ( len ( x )): if x [ i ] == 1 and y [ i ] == 1 : q += 1 elif x [ i ] == 1 and y [ i ] == 0 : r += 1 elif x [ i ] == 0 and y [ i ] == 1 : s += 1 elif x [ i ] == 0 and y [ i ] == 0 : t += 1 return (( r + s ) / ( q + r + s + t )) Kelima \u00b6 Kemudian dari dataset tersebut, kita lakukan pengecekan dengan mencari baris yang missing values,. c_j = 0 for j in df [ 'age' ] . isna (): if j == True : col_missing = c_j c_j += 1 Keenam \u00b6 Pada langkah berikut, kita lakukan perhitungan jarak pada data yang missing dengan seluruh tetangganya dan menampungnya pada dapat dictionary yang ada. missing_data = df . iloc [ col_missing , [ 2 , 3 , 6 , 7 ]] . values missing_normal = [ normalisasi ( missing_data [ 0 ], data . columns [ 2 ]), normalisasi ( missing_data [ 1 ], data . columns [ 3 ]), normalisasi ( missing_data [ 2 ], data . columns [ 6 ]), normalisasi ( missing_data [ 3 ], data . columns [ 7 ])] for i in range ( len ( data [ data . columns [ 0 ]])): if i == col_missing : continue ; select_data = df . iloc [ i , [ 2 , 3 , 6 , 7 ]] . values normal_data = [ normalisasi ( select_data [ 0 ], data . columns [ 2 ]), normalisasi ( select_data [ 1 ], data . columns [ 3 ]), normalisasi ( select_data [ 2 ], data . columns [ 6 ]), normalisasi ( select_data [ 3 ], data . columns [ 7 ])] data . loc [ i , 'jarak' ] = euclidianDistance ( missing_normal , normal_data ) + distanceSimetris ([ X [ col_missing , 4 ]],[ X [ i , 4 ]]) Ketujuh \u00b6 Kemudian kita urutkan data tersebut berdasarkan jarak dari yang terkecil sampai ke terbesar. Selanjutnya kita mengisi data yang hilang dengan mengambil rata-rata dari 2 tetangga terdekat. df = pd . DataFrame ( data ) df . sort_values ( by = 'jarak' , axis = 0 , ascending = True , inplace = True ) df . iloc [ - 1 , [ 5 ]] = round ( df . iloc [ 0 : 2 , 5 ] . mean (), 2 ) df . style . hide_index () Berikut merupakan tampilan dari data yang telah di urutkan. pada baris terakhir telihat bahwa kolom age sudah terisi dengan angka 42.24 hasil dari rata-rata 2 tetangga terdekat. no id days duration sex age piq viq jarak 229 5397 328 0 Female 62.7981 121 108 0.25 13 4705 18 1 Female 21.6838 127 109 0.53 205 6228 174 3 Female 31.5537 114 108 0.6 284 6228 662 3 Female 31.5537 128 111 0.64 161 5699 138 1 Female 34.2231 110 107 0.84 153 4705 146 1 Female 21.6838 133 111 0.86 196 5208 193 8 Female 21.3771 133 111 0.88 300 5837 962 1 Female 33.3087 109 110 1.07 139 6253 128 0 Female 46.4038 104 112 1.31 141 6665 119 3 Female 23.0171 106 94 1.33 163 5804 159 2 Female 28.8515 102 107 1.35 20 5162 33 1 Male 25.0185 118 101 1.48 279 5014 637 7 Female 23.7618 101 114 1.56 129 5298 107 3 Male 22.9569 117 112 1.64 9 4253 40 3 Male 22.6037 115 110 1.66 308 5014 1523 7 Female 23.7618 105 114 1.67 299 5713 1016 8 Male 16.2683 126 106 1.68 48 2761 40 3 Female 24.3696 98 112 1.69 157 5014 151 7 Female 23.7618 97 110 1.72 264 6665 368 3 Female 23.0171 100 92 1.73 34 6163 21 1 Male 19.3593 112 106 1.73 240 4542 431 11 Female 21.9576 98 114 1.75 221 5474 280 2 Female 28.6598 99 91 1.82 28 5699 26 1 Female 34.2231 95 108 1.83 124 4941 131 4 Female 19.0144 96 96 1.85 211 5837 242 1 Female 33.3087 93 105 1.92 292 4864 936 0 Female 53.9767 119 131 1.93 273 2826 636 14 Male 23.2334 111 101 1.94 132 5414 105 10 Female 40.2765 93 104 1.96 45 7548 31 0 Male 24.3669 108 106 1.98 22 5208 31 8 Female 21.3771 97 90 2 135 5901 115 7 Male 22.1739 112 116 2.07 173 4253 175 3 Male 22.6037 114 118 2.08 158 5162 144 1 Male 25.0185 130 118 2.09 152 4696 150 4 Male 46.9569 120 120 2.1 241 4661 374 17 Female 30.8419 93 95 2.13 55 3655 57 5 Female 21.9055 90 103 2.14 202 6122 212 1 Male 56.2108 109 117 2.22 90 6686 44 14 Female 38.3491 90 100 2.22 23 5253 29 1 Male 33.1335 104 105 2.23 79 5474 65 2 Female 28.6598 95 86 2.26 188 6671 184 7 Female 27.8056 91 92 2.26 293 5474 1100 2 Female 28.6598 94 88 2.3 67 4755 24 18 Male 27.5127 105 102 2.33 175 4755 128 18 Male 27.5127 105 109 2.33 177 4892 148 21 Male 22.0397 106 110 2.35 295 5580 1087 7 Male 17.7933 106 98 2.35 50 3277 51 1 Male 37.4702 104 96 2.38 21 5174 38 4 Female 37.2704 87 99 2.38 228 4678 340 7 Male 46.6448 108 119 2.38 298 5642 1143 0 Male 65.87 104 109 2.41 224 4725 286 10 Male 32.9172 105 94 2.41 233 1836 375 1 Male 47.0554 101 108 2.41 168 1085 159 11 Male 30.7105 103 97 2.43 63 4482 58 14 Female 18.2341 86 103 2.44 272 2498 615 0 Female 17.4292 86 113 2.46 140 6433 120 4 Male 23.8604 100 103 2.48 281 5253 591 1 Male 33.1335 114 124 2.48 121 4542 121 11 Female 21.9576 86 114 2.5 66 4696 54 4 Male 46.9569 101 112 2.5 180 5125 173 12 Male 17.5387 106 119 2.51 225 5204 299 0 Male 59.0746 99 105 2.52 40 6937 18 0 Female 21.191 94 81 2.53 162 5713 144 8 Male 16.2683 100 99 2.55 159 5238 150 3 Male 45.1006 117 126 2.55 74 5238 44 3 Male 45.1006 99 103 2.55 43 7309 31 0 Female 50.6667 85 95 2.57 209 4744 217 25 Male 57.566 108 118 2.59 204 6175 278 1 Male 51.1704 99 98 2.6 17 4983 33 5 Male 38.3929 102 117 2.61 151 4678 143 7 Male 46.6448 98 107 2.62 245 5125 510 12 Male 17.5387 112 125 2.63 156 4983 146 5 Male 38.3929 107 123 2.64 94 7271 55 0 Male 41.7659 100 95 2.65 154 4802 142 0 Male 62.475 101 117 2.65 111 5837 82 1 Female 33.3087 82 110 2.69 73 5204 71 0 Male 59.0746 97 107 2.69 57 3919 58 1 Male 30.3655 99 95 2.7 150 4661 135 17 Female 30.8419 84 93 2.72 52 3359 59 9 Female 56.8953 84 91 2.72 53 3373 39 28 Female 26.308 87 91 2.73 250 5580 369 7 Male 17.7933 96 107 2.74 147 3728 151 6 Male 30.1273 96 105 2.74 249 5505 527 1 Male 65.4784 104 87 2.75 183 5581 176 2 Male 26.3053 96 110 2.76 170 3358 175 4 Male 20.6708 97 97 2.76 101 4744 65 25 Male 57.566 105 119 2.77 296 5581 1113 2 Male 26.3053 99 96 2.78 60 4183 42 3 Male 26.2341 98 116 2.8 312 2826 1809 14 Male 23.2334 104 108 2.82 190 2646 187 14 Male 22.9158 97 97 2.82 33 6122 29 1 Male 56.2108 95 103 2.82 235 2646 438 14 Male 22.9158 98 94 2.83 256 5772 412 35 Male 26.2587 102 104 2.84 41 6977 30 1 Male 36.2108 97 94 2.86 201 5916 205 0 Female 26.8556 92 76 2.87 65 4678 63 7 Male 46.6448 96 95 2.89 282 5628 609 3 Female 30.2642 89 78 2.91 192 4189 202 4 Female 29.462 81 90 2.91 223 2826 290 14 Male 23.2334 94 108 2.92 171 3808 165 7 Male 28.2683 94 111 2.92 251 5581 378 2 Male 26.3053 95 95 2.93 243 4983 398 5 Male 38.3929 121 132 2.93 181 5192 179 1 Male 58.6283 93 105 2.93 137 6173 125 4 Male 35.3046 94 97 2.95 107 5253 86 1 Male 33.1335 106 128 2.97 277 4218 814 28 Male 25.9904 99 96 2.97 114 5916 84 0 Female 26.8556 93 73 2.98 3 3547 40 1 Male 55.9151 95 116 2.98 313 2882 1716 18 Male 19.2334 100 103 2.99 182 5505 171 1 Male 65.4784 95 93 2.99 239 4342 432 1 Male 44.063 92 107 3 278 4807 532 14 Female 47.7974 84 82 3.03 25 5640 34 7 Male 25.9986 93 113 3.03 100 4725 124 10 Male 32.9172 93 97 3.04 254 5680 403 1 Male 27.7563 94 93 3.04 248 5387 480 12 Male 21.7988 94 116 3.05 62 4315 63 0 Male 38.141 107 130 3.05 92 7080 64 5 Female 76.6598 76 106 3.05 83 5628 51 3 Female 30.2642 81 85 3.07 304 2527 1294 0 Male 16.9172 93 104 3.09 8 3808 31 7 Male 28.2683 91 110 3.11 105 5125 78 12 Male 17.5387 94 118 3.12 236 2653 352 28 Male 30.0068 105 126 3.13 315 4356 2000 7 Male 21.399 104 91 3.13 289 2849 1040 0 Male 20.0876 91 103 3.14 255 5712 365 14 Male 22.2697 98 86 3.14 317 4696 1769 4 Male 46.9569 105 124 3.16 220 5339 271 7 Male 21.8152 94 89 3.18 160 5642 162 0 Male 65.87 89 103 3.19 324 3808 2434 7 Male 28.2683 105 111 3.2 172 4094 177 2 Male 19.7262 89 102 3.2 270 1624 604 1 Male 19.5619 97 85 3.2 253 5668 390 7 Male 40.9227 92 92 3.2 127 5154 120 5 Male 22.1903 89 109 3.21 214 2882 262 18 Male 19.2334 94 90 3.22 119 2653 97 28 Male 30.0068 93 112 3.23 191 2790 211 0 Male 48.8049 89 99 3.23 294 5568 1114 1 Female 51.9918 81 82 3.23 51 3346 44 18 Female 57.2758 79 85 3.25 263 6614 362 0 Male 45.1116 88 106 3.25 207 1176 216 17 Female 19.729 74 100 3.25 247 5386 436 21 Male 20.8761 90 103 3.25 29 5713 36 8 Male 16.2683 89 97 3.28 203 6136 216 1 Male 32.7912 92 89 3.29 217 4865 240 35 Male 58.3354 93 105 3.3 71 5014 46 7 Female 23.7618 75 90 3.3 35 6179 22 2 Male 38.0123 89 95 3.31 213 1892 276 2 Male 21.7796 87 107 3.33 91 6795 55 0 Male 30.7159 87 104 3.34 15 4802 36 0 Male 62.475 88 97 3.34 72 5192 60 1 Male 58.6283 87 97 3.4 61 4189 69 4 Female 29.462 75 86 3.4 267 1157 810 23 Male 17.3881 97 84 3.4 197 5456 193 14 Male 41.1636 87 110 3.4 165 6314 140 3 Male 16.6927 87 96 3.41 242 4902 397 8 Male 16.1424 92 86 3.42 155 4807 139 14 Female 47.7974 80 78 3.42 318 4744 1743 25 Male 57.566 97 118 3.43 93 7084 54 2 Male 36.5722 87 93 3.49 81 5580 56 7 Male 17.7933 86 95 3.5 131 5387 109 12 Male 21.7988 85 112 3.54 115 6410 80 14 Male 32.1725 85 98 3.55 82 5581 65 2 Male 26.3053 85 95 3.56 322 2653 2191 28 Male 30.0068 117 129 3.57 12 4542 22 11 Female 21.9576 71 89 3.58 1 3358 30 4 Male 20.6708 87 89 3.6 30 5736 18 9 Male 16.1478 89 86 3.6 290 3032 884 20 Male 16.9391 87 93 3.61 56 3762 48 6 Male 20.3559 85 93 3.61 80 5568 64 1 Female 51.9918 75 79 3.63 38 6870 22 0 Male 42.4832 84 95 3.63 84 6154 43 5 Female 22.6064 74 80 3.65 78 5458 44 14 Male 34.4778 84 95 3.66 46 2364 41 14 Male 25.8097 84 94 3.68 260 6226 438 0 Male 36.8022 84 92 3.68 39 6914 43 0 Male 61.5222 85 90 3.69 24 5298 30 3 Male 22.9569 87 86 3.7 31 5754 36 1 Male 16.3368 87 86 3.7 16 4941 46 4 Female 19.0144 69 88 3.72 185 5680 184 1 Male 27.7563 84 90 3.73 306 4865 1363 35 Male 58.3354 88 104 3.73 27 5680 17 1 Male 27.7563 84 90 3.74 2 3535 16 17 Male 55.2882 95 77 3.75 133 5494 111 7 Male 54.6913 86 86 3.75 36 6671 30 7 Female 27.8056 71 82 3.76 19 5154 35 5 Male 22.1903 82 95 3.76 199 5712 192 14 Male 22.2697 87 85 3.76 262 6468 513 60 Male 43.4798 99 94 3.81 149 4133 133 14 Male 20 82 94 3.81 89 6614 57 0 Male 45.1116 80 101 3.81 54 3544 32 14 Male 54.5298 81 98 3.81 176 4865 142 35 Male 58.3354 84 103 3.82 86 6314 58 3 Male 16.6927 80 99 3.82 77 5456 48 14 Male 41.1636 80 101 3.84 130 5339 119 7 Male 21.8152 87 82 3.85 187 6180 177 12 Male 20.7201 81 94 3.85 226 6498 270 28 Male 24.0767 82 101 3.85 143 1176 146 17 Female 19.729 65 98 3.85 42 7120 39 0 Male 69.7057 84 86 3.86 219 5222 247 30 Male 22.5298 88 85 3.87 10 4356 31 7 Male 21.399 86 83 3.87 68 4837 42 10 Male 19.6906 83 88 3.88 112 5879 75 21 Male 25.8453 80 105 3.89 265 781 714 15 Male 29.8699 85 85 3.89 76 5289 52 1 Male 48.5722 84 85 3.9 102 4807 64 14 Female 47.7974 74 74 3.9 291 3226 1123 0 Male 27.4552 88 81 3.9 215 3058 236 28 Male 22.2533 85 88 3.91 276 3226 683 0 Male 27.4552 89 78 3.92 145 2882 141 18 Male 19.2334 84 85 3.95 44 7321 23 0 Male 26.0041 84 83 3.97 283 6059 794 1 Female 16.9801 71 76 3.97 174 4638 140 17 Male 20.512 89 78 3.97 210 5386 241 21 Male 20.8761 80 94 3.98 285 6247 616 13 Male 42.3162 85 82 3.98 99 3844 73 9 Male 26.1164 79 94 3.98 178 5009 174 7 Male 24.3806 77 103 3.99 58 4094 50 2 Male 19.7262 79 93 3.99 246 5289 417 1 Male 48.5722 83 83 4.02 216 4342 263 1 Male 44.063 79 91 4.02 95 7371 55 1 Male 56.7858 80 88 4.04 122 4902 102 8 Male 16.1424 87 77 4.07 259 5841 415 8 Male 27.2279 82 83 4.08 274 2849 642 0 Male 20.0876 76 98 4.09 280 5222 690 30 Male 22.5298 81 90 4.11 320 1075 2259 42 Female 27.2772 78 79 4.13 108 5386 78 21 Male 20.8761 78 93 4.13 14 4744 15 25 Male 57.566 82 85 4.15 75 5280 83 1 Male 48.6434 78 88 4.16 194 4933 226 0 Male 18.4559 79 86 4.16 316 4638 1779 17 Male 20.512 92 76 4.18 195 4962 210 1 Female 25.1964 71 70 4.19 18 5129 26 1 Male 25.0459 77 89 4.2 275 3032 525 20 Male 16.9391 79 87 4.2 261 6247 389 13 Male 42.3162 82 80 4.21 189 2124 173 30 Male 30.7625 76 106 4.23 198 5668 219 7 Male 40.9227 76 90 4.23 11 4384 35 8 Male 36.3806 76 90 4.24 307 5009 1537 7 Male 24.3806 76 112 4.26 244 5111 442 7 Male 21.6947 77 86 4.28 169 3237 189 9 Male 49.8508 79 82 4.3 297 5617 1113 17 Male 19.7864 78 87 4.3 301 6140 1077 44 Female 21.4209 65 88 4.32 327 2600 3337 9 Male 43.9398 101 84 4.33 128 5222 93 30 Male 22.5298 77 91 4.33 230 6214 318 0 Male 60.3176 78 82 4.34 103 4892 62 21 Male 22.0397 76 88 4.36 319 6140 1742 44 Female 21.4209 67 87 4.36 227 2081 185 43 Male 17.6975 77 97 4.42 206 7173 210 4 Male 24.9801 79 78 4.44 104 4962 63 1 Female 25.1964 69 67 4.44 120 4218 82 28 Male 25.9904 74 92 4.47 252 5599 443 21 Male 18.7488 78 80 4.48 106 5222 63 30 Male 22.5298 77 85 4.48 164 5818 125 14 Male 34.9268 72 91 4.49 212 6247 228 13 Male 42.3162 77 80 4.49 258 5811 431 25 Male 80.0328 78 80 4.52 222 5600 232 0 Male 48.7885 75 81 4.55 109 5534 87 14 Male 29.2621 75 82 4.55 186 5782 108 68 Female 19.6715 69 85 4.56 69 4996 51 12 Male 43.0281 77 78 4.58 64 4638 20 17 Male 20.512 82 72 4.59 32 5776 26 8 Male 17.128 71 88 4.6 302 7061 923 0 Male 36.8816 74 81 4.64 303 651 1491 21 Male 22.0068 71 94 4.67 59 4133 34 14 Male 20 70 88 4.69 117 7221 98 0 Male 63.5044 74 79 4.69 37 6859 27 1 Male 34.2122 74 79 4.69 323 3592 2569 10 Male 61.6646 76 93 4.72 179 5111 177 7 Male 21.6947 72 81 4.73 287 626 870 55 Male 19.7536 80 85 4.75 7 3807 37 5 Male 24.6762 74 77 4.76 136 6135 96 18 Male 26.5626 66 105 4.76 184 5599 148 21 Male 18.7488 72 81 4.8 26 5668 27 7 Male 40.9227 72 79 4.81 286 405 986 0 Male 21.4702 66 116 4.82 126 5111 107 7 Male 21.6947 71 80 4.82 193 4775 180 28 Male 53.5551 70 86 4.83 123 4933 134 0 Male 18.4559 69 83 4.85 87 6340 71 0 Male 19.3238 76 72 4.85 98 3645 43 45 Male 27.4935 72 90 4.86 309 5085 1512 2 Male 49.0267 75 75 4.91 118 2453 120 10 Male 37.2758 63 99 4.94 116 7173 84 4 Male 24.9801 72 75 4.94 142 6834 123 0 Male 30.7488 72 75 4.94 85 6180 59 12 Male 20.7201 67 84 4.96 148 3913 96 42 Female 23.9233 56 80 4.96 47 2600 3333 9 Male 43.9398 86 80 4.97 6 3790 13 3 Male 57.0623 76 69 4.99 113 5893 71 21 Male 22.8118 65 90 4.99 200 5893 200 21 Male 22.8118 65 89 5.01 70 5009 50 7 Male 24.3806 61 104 5.05 146 3051 131 13 Male 37.2403 68 79 5.05 231 7034 280 60 Male 23.1376 78 80 5.07 288 1075 907 42 Female 27.2772 63 64 5.12 266 1048 576 94 Male 20.115 91 96 5.14 269 1611 511 60 Male 23.2799 69 107 5.16 314 3768 1916 0 Male 19.1102 69 80 5.16 237 3226 444 0 Male 27.4552 76 64 5.21 134 5896 126 4 Female 26.8775 50 74 5.25 88 6564 69 0 Male 34.4997 67 74 5.26 218 5085 269 2 Male 49.0267 65 77 5.26 5 3728 19 6 Male 30.1273 67 73 5.3 166 6664 164 2 Male 24.7337 66 73 5.34 110 5712 88 14 Male 22.2697 70 68 5.36 138 6214 112 0 Male 60.3176 65 74 5.37 125 5085 117 2 Male 49.0267 67 71 5.38 97 3058 56 28 Male 22.2533 65 75 5.45 238 3467 333 42 Male 25.3936 68 74 5.46 49 3237 65 9 Male 49.8508 67 67 5.55 325 651 3412 21 Male 22.0068 68 92 5.62 328 3835 4933 14 Male 25.9932 91 88 5.69 4 3592 13 10 Male 61.6646 59 73 5.77 268 1493 684 60 Male 17.8042 66 75 5.83 144 2849 151 0 Male 20.0876 51 86 5.89 96 2569 49 35 Male 18.7159 50 101 5.94 232 1493 453 60 Male 17.8042 59 81 6.03 310 1939 1926 130 Male 28.2738 95 108 6.41 208 3467 186 42 Male 25.3936 53 69 6.45 167 1048 85 94 Male 20.115 63 82 6.51 271 1939 562 130 Male 28.2738 85 111 6.51 321 1939 3111 130 Male 28.2738 88 111 6.93 234 1939 295 130 Male 28.2738 67 117 7.17 326 1939 3864 130 Male 28.2738 88 105 7.22 329 2773 7631 42 Male 6.51335 88 103 7.96 311 2662 1569 180 Male 28.0821 90 101 8.24 331 5964 11038 0 Male 12.8363 71 73 11.23 330 5142 11628 57 Male 16.4326 101 95 11.25 305 2638 1093 255 Male 16.5613 78 84 11.27 257 5804 354 2 Female 42.24 122 105 nan Seluruh file percobaan diatas dapat diunduh disini Referensi \u00b6 https://www.saedsayad.com/missing_values.htm https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/","title":"Tugas 3"},{"location":"pendat/missing knn/#missing-value-dengan-algoritma-k-nn","text":"","title":"Missing Value dengan Algoritma K-NN"},{"location":"pendat/missing knn/#missing-values","text":"Missing Values (nilai yang hilang) adalah kejadian umum, dimana nilai yang hilang dapat menandakan sejumlah hal berbeda dalam data. Dan mungkin data tidak tersedia atau tidak berlaku. Missing value biasanya disebabkan oleh orang yang memasukkan data dan tidak tahu nilai yang benar, atau tidak mengisinya. Metode penambangan data bervariasi dalam cara mereka memperlakukan nilai yang hilang. Biasanya, mereka mengabaikan nilai yang hilang, atau mengecualikan catatan yang berisi nilai yang hilang, atau mengganti nilai yang hilang dengan nilai tengah, atau menyimpulkan nilai yang hilang dari nilai yang ada.","title":"Missing Values"},{"location":"pendat/missing knn/#algoritma-k-nn-k-nearest-neighbors","text":"Algoritma K-Nearest Naighbors adalah suatu algoritma klasifikasi sederhana yang dapat digunakan untuk memprediksi klasifikasi dan regresi. Algoritma ini memiliki tujuan untuk mengklasifikasi objek baru berdasarkan atribut dan sample-sample data training. langkah penyelesaian yang dilakukan oleh algoritma tersebut adalah: Kita harus menentukan jumlah tetangga terdekat yang nantinya akan kita hitung. Misalnya : kita menentukan 2 tetangga terdekat (k=2). Hitung jarak objek yang dipilih dengan seluruh tetangga yang ada. kemudian urutkan berdasarkan jarak yang diperoleh dari yang terkecil hingga ke terbesar. Ambil 2 tetangga yang paling dekat atau nilai jarak yang terkecil, dan ambil rata-ratanya.","title":"Algoritma K-NN (k-Nearest Neighbors)"},{"location":"pendat/missing knn/#mengatasi-missing-value-menggunakan-algoritma-k-nn-pada-python","text":"","title":"Mengatasi Missing Value Menggunakan Algoritma K-NN pada Python"},{"location":"pendat/missing knn/#alat-dan-bahan","text":"Pada kasus kali ini, saya menggunakan dataset dari internet, yang bisa diunduh disini . Pada dataset tersebut terdapat 1 fitur bertipe binary dan 5 fitur bertipe numerikal. Pada fitur age dataset telah saya modif dengan mengubah dalam bentuk .csv dan memberikan missing value pada baris ke-257. Untuk mempermudah dalam penyelesaian kasus ini, perlu di siapkan library python untuk mempermudah dalam pengerjaan. Library ini dapat di unduh secara gratis dari internet. Berikut merupakan library yang harus di persiapkan: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika.","title":"Alat dan Bahan"},{"location":"pendat/missing knn/#pertama","text":"Langkah pertama yang harus dilakukan adalah memasukkan library yang telah diunduh sebelumnya. import pandas as pd import math as mt from sklearn.preprocessing import LabelEncoder","title":"Pertama"},{"location":"pendat/missing knn/#kedua","text":"Selanjutnya kita mengambil file csv tersebut. data = pd . read_csv ( 'Wong.csv' , delimiter = ';' , decimal = ',' ) df = pd . DataFrame ( data ) df . style . highlight_null ( null_color = 'red' ) . hide_index () Maka akan tampil sebagai barikut: no id days duration sex age piq viq 1 3358 30 4 Male 20.6708 87 89 2 3535 16 17 Male 55.2882 95 77 3 3547 40 1 Male 55.9151 95 116 4 3592 13 10 Male 61.6646 59 73 5 3728 19 6 Male 30.1273 67 73 6 3790 13 3 Male 57.0623 76 69 7 3807 37 5 Male 24.6762 74 77 8 3808 31 7 Male 28.2683 91 110 9 4253 40 3 Male 22.6037 115 110 10 4356 31 7 Male 21.399 86 83 11 4384 35 8 Male 36.3806 76 90 12 4542 22 11 Female 21.9576 71 89 13 4705 18 1 Female 21.6838 127 109 14 4744 15 25 Male 57.566 82 85 15 4802 36 0 Male 62.475 88 97 16 4941 46 4 Female 19.0144 69 88 17 4983 33 5 Male 38.3929 102 117 18 5129 26 1 Male 25.0459 77 89 19 5154 35 5 Male 22.1903 82 95 20 5162 33 1 Male 25.0185 118 101 21 5174 38 4 Female 37.2704 87 99 22 5208 31 8 Female 21.3771 97 90 23 5253 29 1 Male 33.1335 104 105 24 5298 30 3 Male 22.9569 87 86 25 5640 34 7 Male 25.9986 93 113 26 5668 27 7 Male 40.9227 72 79 27 5680 17 1 Male 27.7563 84 90 28 5699 26 1 Female 34.2231 95 108 29 5713 36 8 Male 16.2683 89 97 30 5736 18 9 Male 16.1478 89 86 31 5754 36 1 Male 16.3368 87 86 32 5776 26 8 Male 17.128 71 88 33 6122 29 1 Male 56.2108 95 103 34 6163 21 1 Male 19.3593 112 106 35 6179 22 2 Male 38.0123 89 95 36 6671 30 7 Female 27.8056 71 82 37 6859 27 1 Male 34.2122 74 79 38 6870 22 0 Male 42.4832 84 95 39 6914 43 0 Male 61.5222 85 90 40 6937 18 0 Female 21.191 94 81 41 6977 30 1 Male 36.2108 97 94 42 7120 39 0 Male 69.7057 84 86 43 7309 31 0 Female 50.6667 85 95 44 7321 23 0 Male 26.0041 84 83 45 7548 31 0 Male 24.3669 108 106 46 2364 41 14 Male 25.8097 84 94 47 2600 3333 9 Male 43.9398 86 80 48 2761 40 3 Female 24.3696 98 112 49 3237 65 9 Male 49.8508 67 67 50 3277 51 1 Male 37.4702 104 96 51 3346 44 18 Female 57.2758 79 85 52 3359 59 9 Female 56.8953 84 91 53 3373 39 28 Female 26.308 87 91 54 3544 32 14 Male 54.5298 81 98 55 3655 57 5 Female 21.9055 90 103 56 3762 48 6 Male 20.3559 85 93 57 3919 58 1 Male 30.3655 99 95 58 4094 50 2 Male 19.7262 79 93 59 4133 34 14 Male 20 70 88 60 4183 42 3 Male 26.2341 98 116 61 4189 69 4 Female 29.462 75 86 62 4315 63 0 Male 38.141 107 130 63 4482 58 14 Female 18.2341 86 103 64 4638 20 17 Male 20.512 82 72 65 4678 63 7 Male 46.6448 96 95 66 4696 54 4 Male 46.9569 101 112 67 4755 24 18 Male 27.5127 105 102 68 4837 42 10 Male 19.6906 83 88 69 4996 51 12 Male 43.0281 77 78 70 5009 50 7 Male 24.3806 61 104 71 5014 46 7 Female 23.7618 75 90 72 5192 60 1 Male 58.6283 87 97 73 5204 71 0 Male 59.0746 97 107 74 5238 44 3 Male 45.1006 99 103 75 5280 83 1 Male 48.6434 78 88 76 5289 52 1 Male 48.5722 84 85 77 5456 48 14 Male 41.1636 80 101 78 5458 44 14 Male 34.4778 84 95 79 5474 65 2 Female 28.6598 95 86 80 5568 64 1 Female 51.9918 75 79 81 5580 56 7 Male 17.7933 86 95 82 5581 65 2 Male 26.3053 85 95 83 5628 51 3 Female 30.2642 81 85 84 6154 43 5 Female 22.6064 74 80 85 6180 59 12 Male 20.7201 67 84 86 6314 58 3 Male 16.6927 80 99 87 6340 71 0 Male 19.3238 76 72 88 6564 69 0 Male 34.4997 67 74 89 6614 57 0 Male 45.1116 80 101 90 6686 44 14 Female 38.3491 90 100 91 6795 55 0 Male 30.7159 87 104 92 7080 64 5 Female 76.6598 76 106 93 7084 54 2 Male 36.5722 87 93 94 7271 55 0 Male 41.7659 100 95 95 7371 55 1 Male 56.7858 80 88 96 2569 49 35 Male 18.7159 50 101 97 3058 56 28 Male 22.2533 65 75 98 3645 43 45 Male 27.4935 72 90 99 3844 73 9 Male 26.1164 79 94 100 4725 124 10 Male 32.9172 93 97 101 4744 65 25 Male 57.566 105 119 102 4807 64 14 Female 47.7974 74 74 103 4892 62 21 Male 22.0397 76 88 104 4962 63 1 Female 25.1964 69 67 105 5125 78 12 Male 17.5387 94 118 106 5222 63 30 Male 22.5298 77 85 107 5253 86 1 Male 33.1335 106 128 108 5386 78 21 Male 20.8761 78 93 109 5534 87 14 Male 29.2621 75 82 110 5712 88 14 Male 22.2697 70 68 111 5837 82 1 Female 33.3087 82 110 112 5879 75 21 Male 25.8453 80 105 113 5893 71 21 Male 22.8118 65 90 114 5916 84 0 Female 26.8556 93 73 115 6410 80 14 Male 32.1725 85 98 116 7173 84 4 Male 24.9801 72 75 117 7221 98 0 Male 63.5044 74 79 118 2453 120 10 Male 37.2758 63 99 119 2653 97 28 Male 30.0068 93 112 120 4218 82 28 Male 25.9904 74 92 121 4542 121 11 Female 21.9576 86 114 122 4902 102 8 Male 16.1424 87 77 123 4933 134 0 Male 18.4559 69 83 124 4941 131 4 Female 19.0144 96 96 125 5085 117 2 Male 49.0267 67 71 126 5111 107 7 Male 21.6947 71 80 127 5154 120 5 Male 22.1903 89 109 128 5222 93 30 Male 22.5298 77 91 129 5298 107 3 Male 22.9569 117 112 130 5339 119 7 Male 21.8152 87 82 131 5387 109 12 Male 21.7988 85 112 132 5414 105 10 Female 40.2765 93 104 133 5494 111 7 Male 54.6913 86 86 134 5896 126 4 Female 26.8775 50 74 135 5901 115 7 Male 22.1739 112 116 136 6135 96 18 Male 26.5626 66 105 137 6173 125 4 Male 35.3046 94 97 138 6214 112 0 Male 60.3176 65 74 139 6253 128 0 Female 46.4038 104 112 140 6433 120 4 Male 23.8604 100 103 141 6665 119 3 Female 23.0171 106 94 142 6834 123 0 Male 30.7488 72 75 143 1176 146 17 Female 19.729 65 98 144 2849 151 0 Male 20.0876 51 86 145 2882 141 18 Male 19.2334 84 85 146 3051 131 13 Male 37.2403 68 79 147 3728 151 6 Male 30.1273 96 105 148 3913 96 42 Female 23.9233 56 80 149 4133 133 14 Male 20 82 94 150 4661 135 17 Female 30.8419 84 93 151 4678 143 7 Male 46.6448 98 107 152 4696 150 4 Male 46.9569 120 120 153 4705 146 1 Female 21.6838 133 111 154 4802 142 0 Male 62.475 101 117 155 4807 139 14 Female 47.7974 80 78 156 4983 146 5 Male 38.3929 107 123 157 5014 151 7 Female 23.7618 97 110 158 5162 144 1 Male 25.0185 130 118 159 5238 150 3 Male 45.1006 117 126 160 5642 162 0 Male 65.87 89 103 161 5699 138 1 Female 34.2231 110 107 162 5713 144 8 Male 16.2683 100 99 163 5804 159 2 Female 28.8515 102 107 164 5818 125 14 Male 34.9268 72 91 165 6314 140 3 Male 16.6927 87 96 166 6664 164 2 Male 24.7337 66 73 167 1048 85 94 Male 20.115 63 82 168 1085 159 11 Male 30.7105 103 97 169 3237 189 9 Male 49.8508 79 82 170 3358 175 4 Male 20.6708 97 97 171 3808 165 7 Male 28.2683 94 111 172 4094 177 2 Male 19.7262 89 102 173 4253 175 3 Male 22.6037 114 118 174 4638 140 17 Male 20.512 89 78 175 4755 128 18 Male 27.5127 105 109 176 4865 142 35 Male 58.3354 84 103 177 4892 148 21 Male 22.0397 106 110 178 5009 174 7 Male 24.3806 77 103 179 5111 177 7 Male 21.6947 72 81 180 5125 173 12 Male 17.5387 106 119 181 5192 179 1 Male 58.6283 93 105 182 5505 171 1 Male 65.4784 95 93 183 5581 176 2 Male 26.3053 96 110 184 5599 148 21 Male 18.7488 72 81 185 5680 184 1 Male 27.7563 84 90 186 5782 108 68 Female 19.6715 69 85 187 6180 177 12 Male 20.7201 81 94 188 6671 184 7 Female 27.8056 91 92 189 2124 173 30 Male 30.7625 76 106 190 2646 187 14 Male 22.9158 97 97 191 2790 211 0 Male 48.8049 89 99 192 4189 202 4 Female 29.462 81 90 193 4775 180 28 Male 53.5551 70 86 194 4933 226 0 Male 18.4559 79 86 195 4962 210 1 Female 25.1964 71 70 196 5208 193 8 Female 21.3771 133 111 197 5456 193 14 Male 41.1636 87 110 198 5668 219 7 Male 40.9227 76 90 199 5712 192 14 Male 22.2697 87 85 200 5893 200 21 Male 22.8118 65 89 201 5916 205 0 Female 26.8556 92 76 202 6122 212 1 Male 56.2108 109 117 203 6136 216 1 Male 32.7912 92 89 204 6175 278 1 Male 51.1704 99 98 205 6228 174 3 Female 31.5537 114 108 206 7173 210 4 Male 24.9801 79 78 207 1176 216 17 Female 19.729 74 100 208 3467 186 42 Male 25.3936 53 69 209 4744 217 25 Male 57.566 108 118 210 5386 241 21 Male 20.8761 80 94 211 5837 242 1 Female 33.3087 93 105 212 6247 228 13 Male 42.3162 77 80 213 1892 276 2 Male 21.7796 87 107 214 2882 262 18 Male 19.2334 94 90 215 3058 236 28 Male 22.2533 85 88 216 4342 263 1 Male 44.063 79 91 217 4865 240 35 Male 58.3354 93 105 218 5085 269 2 Male 49.0267 65 77 219 5222 247 30 Male 22.5298 88 85 220 5339 271 7 Male 21.8152 94 89 221 5474 280 2 Female 28.6598 99 91 222 5600 232 0 Male 48.7885 75 81 223 2826 290 14 Male 23.2334 94 108 224 4725 286 10 Male 32.9172 105 94 225 5204 299 0 Male 59.0746 99 105 226 6498 270 28 Male 24.0767 82 101 227 2081 185 43 Male 17.6975 77 97 228 4678 340 7 Male 46.6448 108 119 229 5397 328 0 Female 62.7981 121 108 230 6214 318 0 Male 60.3176 78 82 231 7034 280 60 Male 23.1376 78 80 232 1493 453 60 Male 17.8042 59 81 233 1836 375 1 Male 47.0554 101 108 234 1939 295 130 Male 28.2738 67 117 235 2646 438 14 Male 22.9158 98 94 236 2653 352 28 Male 30.0068 105 126 237 3226 444 0 Male 27.4552 76 64 238 3467 333 42 Male 25.3936 68 74 239 4342 432 1 Male 44.063 92 107 240 4542 431 11 Female 21.9576 98 114 241 4661 374 17 Female 30.8419 93 95 242 4902 397 8 Male 16.1424 92 86 243 4983 398 5 Male 38.3929 121 132 244 5111 442 7 Male 21.6947 77 86 245 5125 510 12 Male 17.5387 112 125 246 5289 417 1 Male 48.5722 83 83 247 5386 436 21 Male 20.8761 90 103 248 5387 480 12 Male 21.7988 94 116 249 5505 527 1 Male 65.4784 104 87 250 5580 369 7 Male 17.7933 96 107 251 5581 378 2 Male 26.3053 95 95 252 5599 443 21 Male 18.7488 78 80 253 5668 390 7 Male 40.9227 92 92 254 5680 403 1 Male 27.7563 94 93 255 5712 365 14 Male 22.2697 98 86 256 5772 412 35 Male 26.2587 102 104 257 5804 354 2 Female nan 122 105 258 5811 431 25 Male 80.0328 78 80 259 5841 415 8 Male 27.2279 82 83 260 6226 438 0 Male 36.8022 84 92 261 6247 389 13 Male 42.3162 82 80 262 6468 513 60 Male 43.4798 99 94 263 6614 362 0 Male 45.1116 88 106 264 6665 368 3 Female 23.0171 100 92 265 781 714 15 Male 29.8699 85 85 266 1048 576 94 Male 20.115 91 96 267 1157 810 23 Male 17.3881 97 84 268 1493 684 60 Male 17.8042 66 75 269 1611 511 60 Male 23.2799 69 107 270 1624 604 1 Male 19.5619 97 85 271 1939 562 130 Male 28.2738 85 111 272 2498 615 0 Female 17.4292 86 113 273 2826 636 14 Male 23.2334 111 101 274 2849 642 0 Male 20.0876 76 98 275 3032 525 20 Male 16.9391 79 87 276 3226 683 0 Male 27.4552 89 78 277 4218 814 28 Male 25.9904 99 96 278 4807 532 14 Female 47.7974 84 82 279 5014 637 7 Female 23.7618 101 114 280 5222 690 30 Male 22.5298 81 90 281 5253 591 1 Male 33.1335 114 124 282 5628 609 3 Female 30.2642 89 78 283 6059 794 1 Female 16.9801 71 76 284 6228 662 3 Female 31.5537 128 111 285 6247 616 13 Male 42.3162 85 82 286 405 986 0 Male 21.4702 66 116 287 626 870 55 Male 19.7536 80 85 288 1075 907 42 Female 27.2772 63 64 289 2849 1040 0 Male 20.0876 91 103 290 3032 884 20 Male 16.9391 87 93 291 3226 1123 0 Male 27.4552 88 81 292 4864 936 0 Female 53.9767 119 131 293 5474 1100 2 Female 28.6598 94 88 294 5568 1114 1 Female 51.9918 81 82 295 5580 1087 7 Male 17.7933 106 98 296 5581 1113 2 Male 26.3053 99 96 297 5617 1113 17 Male 19.7864 78 87 298 5642 1143 0 Male 65.87 104 109 299 5713 1016 8 Male 16.2683 126 106 300 5837 962 1 Female 33.3087 109 110 301 6140 1077 44 Female 21.4209 65 88 302 7061 923 0 Male 36.8816 74 81 303 651 1491 21 Male 22.0068 71 94 304 2527 1294 0 Male 16.9172 93 104 305 2638 1093 255 Male 16.5613 78 84 306 4865 1363 35 Male 58.3354 88 104 307 5009 1537 7 Male 24.3806 76 112 308 5014 1523 7 Female 23.7618 105 114 309 5085 1512 2 Male 49.0267 75 75 310 1939 1926 130 Male 28.2738 95 108 311 2662 1569 180 Male 28.0821 90 101 312 2826 1809 14 Male 23.2334 104 108 313 2882 1716 18 Male 19.2334 100 103 314 3768 1916 0 Male 19.1102 69 80 315 4356 2000 7 Male 21.399 104 91 316 4638 1779 17 Male 20.512 92 76 317 4696 1769 4 Male 46.9569 105 124 318 4744 1743 25 Male 57.566 97 118 319 6140 1742 44 Female 21.4209 67 87 320 1075 2259 42 Female 27.2772 78 79 321 1939 3111 130 Male 28.2738 88 111 322 2653 2191 28 Male 30.0068 117 129 323 3592 2569 10 Male 61.6646 76 93 324 3808 2434 7 Male 28.2683 105 111 325 651 3412 21 Male 22.0068 68 92 326 1939 3864 130 Male 28.2738 88 105 327 2600 3337 9 Male 43.9398 101 84 328 3835 4933 14 Male 25.9932 91 88 329 2773 7631 42 Male 6.51335 88 103 330 5142 11628 57 Male 16.4326 101 95 331 5964 11038 0 Male 12.8363 71 73","title":"Kedua"},{"location":"pendat/missing knn/#ketiga","text":"Pada langkah ini mengubah nilai dari fitur sex menjadi angak 0 / 1 dengan menggunakan fungsi dari sklearn, yaitu LabelEncode() . #encode fitur tipe biner X = data . iloc [:,:] . values labelEncode_X = LabelEncoder () X [:, 4 ] = labelEncode_X . fit_transform ( X [:, 4 ])","title":"Ketiga"},{"location":"pendat/missing knn/#keempat","text":"Selanjutnya kita mengimplementasikan rumus jarak ke dalam bentuk fungsi python. yaitu: eulidianDistance() dengan fungsi jarak tipe binary distanceSimetris (). def Zscore ( x , mean , std ): top = x - mean if top == 0 : return top else : return round ( top / std , 2 ) def normalisasi ( num , col_x ): return Zscore ( num , pd . Series ( data [ col_x ] . values ) . mean (), pd . Series ( data [ col_x ] . values ) . std ()) #menghitung jarak tipe numerikal def euclidianDistance ( x , y ): dis = 0 for i in range ( len ( x )): dis += ( x [ i ] - y [ i ]) ** 2 return round ( mt . sqrt ( dis ), 2 ) #Menghitung jarak tipe binary def distanceSimetris ( x , y ): q = r = s = t = 0 for i in range ( len ( x )): if x [ i ] == 1 and y [ i ] == 1 : q += 1 elif x [ i ] == 1 and y [ i ] == 0 : r += 1 elif x [ i ] == 0 and y [ i ] == 1 : s += 1 elif x [ i ] == 0 and y [ i ] == 0 : t += 1 return (( r + s ) / ( q + r + s + t ))","title":"Keempat"},{"location":"pendat/missing knn/#kelima","text":"Kemudian dari dataset tersebut, kita lakukan pengecekan dengan mencari baris yang missing values,. c_j = 0 for j in df [ 'age' ] . isna (): if j == True : col_missing = c_j c_j += 1","title":"Kelima"},{"location":"pendat/missing knn/#keenam","text":"Pada langkah berikut, kita lakukan perhitungan jarak pada data yang missing dengan seluruh tetangganya dan menampungnya pada dapat dictionary yang ada. missing_data = df . iloc [ col_missing , [ 2 , 3 , 6 , 7 ]] . values missing_normal = [ normalisasi ( missing_data [ 0 ], data . columns [ 2 ]), normalisasi ( missing_data [ 1 ], data . columns [ 3 ]), normalisasi ( missing_data [ 2 ], data . columns [ 6 ]), normalisasi ( missing_data [ 3 ], data . columns [ 7 ])] for i in range ( len ( data [ data . columns [ 0 ]])): if i == col_missing : continue ; select_data = df . iloc [ i , [ 2 , 3 , 6 , 7 ]] . values normal_data = [ normalisasi ( select_data [ 0 ], data . columns [ 2 ]), normalisasi ( select_data [ 1 ], data . columns [ 3 ]), normalisasi ( select_data [ 2 ], data . columns [ 6 ]), normalisasi ( select_data [ 3 ], data . columns [ 7 ])] data . loc [ i , 'jarak' ] = euclidianDistance ( missing_normal , normal_data ) + distanceSimetris ([ X [ col_missing , 4 ]],[ X [ i , 4 ]])","title":"Keenam"},{"location":"pendat/missing knn/#ketujuh","text":"Kemudian kita urutkan data tersebut berdasarkan jarak dari yang terkecil sampai ke terbesar. Selanjutnya kita mengisi data yang hilang dengan mengambil rata-rata dari 2 tetangga terdekat. df = pd . DataFrame ( data ) df . sort_values ( by = 'jarak' , axis = 0 , ascending = True , inplace = True ) df . iloc [ - 1 , [ 5 ]] = round ( df . iloc [ 0 : 2 , 5 ] . mean (), 2 ) df . style . hide_index () Berikut merupakan tampilan dari data yang telah di urutkan. pada baris terakhir telihat bahwa kolom age sudah terisi dengan angka 42.24 hasil dari rata-rata 2 tetangga terdekat. no id days duration sex age piq viq jarak 229 5397 328 0 Female 62.7981 121 108 0.25 13 4705 18 1 Female 21.6838 127 109 0.53 205 6228 174 3 Female 31.5537 114 108 0.6 284 6228 662 3 Female 31.5537 128 111 0.64 161 5699 138 1 Female 34.2231 110 107 0.84 153 4705 146 1 Female 21.6838 133 111 0.86 196 5208 193 8 Female 21.3771 133 111 0.88 300 5837 962 1 Female 33.3087 109 110 1.07 139 6253 128 0 Female 46.4038 104 112 1.31 141 6665 119 3 Female 23.0171 106 94 1.33 163 5804 159 2 Female 28.8515 102 107 1.35 20 5162 33 1 Male 25.0185 118 101 1.48 279 5014 637 7 Female 23.7618 101 114 1.56 129 5298 107 3 Male 22.9569 117 112 1.64 9 4253 40 3 Male 22.6037 115 110 1.66 308 5014 1523 7 Female 23.7618 105 114 1.67 299 5713 1016 8 Male 16.2683 126 106 1.68 48 2761 40 3 Female 24.3696 98 112 1.69 157 5014 151 7 Female 23.7618 97 110 1.72 264 6665 368 3 Female 23.0171 100 92 1.73 34 6163 21 1 Male 19.3593 112 106 1.73 240 4542 431 11 Female 21.9576 98 114 1.75 221 5474 280 2 Female 28.6598 99 91 1.82 28 5699 26 1 Female 34.2231 95 108 1.83 124 4941 131 4 Female 19.0144 96 96 1.85 211 5837 242 1 Female 33.3087 93 105 1.92 292 4864 936 0 Female 53.9767 119 131 1.93 273 2826 636 14 Male 23.2334 111 101 1.94 132 5414 105 10 Female 40.2765 93 104 1.96 45 7548 31 0 Male 24.3669 108 106 1.98 22 5208 31 8 Female 21.3771 97 90 2 135 5901 115 7 Male 22.1739 112 116 2.07 173 4253 175 3 Male 22.6037 114 118 2.08 158 5162 144 1 Male 25.0185 130 118 2.09 152 4696 150 4 Male 46.9569 120 120 2.1 241 4661 374 17 Female 30.8419 93 95 2.13 55 3655 57 5 Female 21.9055 90 103 2.14 202 6122 212 1 Male 56.2108 109 117 2.22 90 6686 44 14 Female 38.3491 90 100 2.22 23 5253 29 1 Male 33.1335 104 105 2.23 79 5474 65 2 Female 28.6598 95 86 2.26 188 6671 184 7 Female 27.8056 91 92 2.26 293 5474 1100 2 Female 28.6598 94 88 2.3 67 4755 24 18 Male 27.5127 105 102 2.33 175 4755 128 18 Male 27.5127 105 109 2.33 177 4892 148 21 Male 22.0397 106 110 2.35 295 5580 1087 7 Male 17.7933 106 98 2.35 50 3277 51 1 Male 37.4702 104 96 2.38 21 5174 38 4 Female 37.2704 87 99 2.38 228 4678 340 7 Male 46.6448 108 119 2.38 298 5642 1143 0 Male 65.87 104 109 2.41 224 4725 286 10 Male 32.9172 105 94 2.41 233 1836 375 1 Male 47.0554 101 108 2.41 168 1085 159 11 Male 30.7105 103 97 2.43 63 4482 58 14 Female 18.2341 86 103 2.44 272 2498 615 0 Female 17.4292 86 113 2.46 140 6433 120 4 Male 23.8604 100 103 2.48 281 5253 591 1 Male 33.1335 114 124 2.48 121 4542 121 11 Female 21.9576 86 114 2.5 66 4696 54 4 Male 46.9569 101 112 2.5 180 5125 173 12 Male 17.5387 106 119 2.51 225 5204 299 0 Male 59.0746 99 105 2.52 40 6937 18 0 Female 21.191 94 81 2.53 162 5713 144 8 Male 16.2683 100 99 2.55 159 5238 150 3 Male 45.1006 117 126 2.55 74 5238 44 3 Male 45.1006 99 103 2.55 43 7309 31 0 Female 50.6667 85 95 2.57 209 4744 217 25 Male 57.566 108 118 2.59 204 6175 278 1 Male 51.1704 99 98 2.6 17 4983 33 5 Male 38.3929 102 117 2.61 151 4678 143 7 Male 46.6448 98 107 2.62 245 5125 510 12 Male 17.5387 112 125 2.63 156 4983 146 5 Male 38.3929 107 123 2.64 94 7271 55 0 Male 41.7659 100 95 2.65 154 4802 142 0 Male 62.475 101 117 2.65 111 5837 82 1 Female 33.3087 82 110 2.69 73 5204 71 0 Male 59.0746 97 107 2.69 57 3919 58 1 Male 30.3655 99 95 2.7 150 4661 135 17 Female 30.8419 84 93 2.72 52 3359 59 9 Female 56.8953 84 91 2.72 53 3373 39 28 Female 26.308 87 91 2.73 250 5580 369 7 Male 17.7933 96 107 2.74 147 3728 151 6 Male 30.1273 96 105 2.74 249 5505 527 1 Male 65.4784 104 87 2.75 183 5581 176 2 Male 26.3053 96 110 2.76 170 3358 175 4 Male 20.6708 97 97 2.76 101 4744 65 25 Male 57.566 105 119 2.77 296 5581 1113 2 Male 26.3053 99 96 2.78 60 4183 42 3 Male 26.2341 98 116 2.8 312 2826 1809 14 Male 23.2334 104 108 2.82 190 2646 187 14 Male 22.9158 97 97 2.82 33 6122 29 1 Male 56.2108 95 103 2.82 235 2646 438 14 Male 22.9158 98 94 2.83 256 5772 412 35 Male 26.2587 102 104 2.84 41 6977 30 1 Male 36.2108 97 94 2.86 201 5916 205 0 Female 26.8556 92 76 2.87 65 4678 63 7 Male 46.6448 96 95 2.89 282 5628 609 3 Female 30.2642 89 78 2.91 192 4189 202 4 Female 29.462 81 90 2.91 223 2826 290 14 Male 23.2334 94 108 2.92 171 3808 165 7 Male 28.2683 94 111 2.92 251 5581 378 2 Male 26.3053 95 95 2.93 243 4983 398 5 Male 38.3929 121 132 2.93 181 5192 179 1 Male 58.6283 93 105 2.93 137 6173 125 4 Male 35.3046 94 97 2.95 107 5253 86 1 Male 33.1335 106 128 2.97 277 4218 814 28 Male 25.9904 99 96 2.97 114 5916 84 0 Female 26.8556 93 73 2.98 3 3547 40 1 Male 55.9151 95 116 2.98 313 2882 1716 18 Male 19.2334 100 103 2.99 182 5505 171 1 Male 65.4784 95 93 2.99 239 4342 432 1 Male 44.063 92 107 3 278 4807 532 14 Female 47.7974 84 82 3.03 25 5640 34 7 Male 25.9986 93 113 3.03 100 4725 124 10 Male 32.9172 93 97 3.04 254 5680 403 1 Male 27.7563 94 93 3.04 248 5387 480 12 Male 21.7988 94 116 3.05 62 4315 63 0 Male 38.141 107 130 3.05 92 7080 64 5 Female 76.6598 76 106 3.05 83 5628 51 3 Female 30.2642 81 85 3.07 304 2527 1294 0 Male 16.9172 93 104 3.09 8 3808 31 7 Male 28.2683 91 110 3.11 105 5125 78 12 Male 17.5387 94 118 3.12 236 2653 352 28 Male 30.0068 105 126 3.13 315 4356 2000 7 Male 21.399 104 91 3.13 289 2849 1040 0 Male 20.0876 91 103 3.14 255 5712 365 14 Male 22.2697 98 86 3.14 317 4696 1769 4 Male 46.9569 105 124 3.16 220 5339 271 7 Male 21.8152 94 89 3.18 160 5642 162 0 Male 65.87 89 103 3.19 324 3808 2434 7 Male 28.2683 105 111 3.2 172 4094 177 2 Male 19.7262 89 102 3.2 270 1624 604 1 Male 19.5619 97 85 3.2 253 5668 390 7 Male 40.9227 92 92 3.2 127 5154 120 5 Male 22.1903 89 109 3.21 214 2882 262 18 Male 19.2334 94 90 3.22 119 2653 97 28 Male 30.0068 93 112 3.23 191 2790 211 0 Male 48.8049 89 99 3.23 294 5568 1114 1 Female 51.9918 81 82 3.23 51 3346 44 18 Female 57.2758 79 85 3.25 263 6614 362 0 Male 45.1116 88 106 3.25 207 1176 216 17 Female 19.729 74 100 3.25 247 5386 436 21 Male 20.8761 90 103 3.25 29 5713 36 8 Male 16.2683 89 97 3.28 203 6136 216 1 Male 32.7912 92 89 3.29 217 4865 240 35 Male 58.3354 93 105 3.3 71 5014 46 7 Female 23.7618 75 90 3.3 35 6179 22 2 Male 38.0123 89 95 3.31 213 1892 276 2 Male 21.7796 87 107 3.33 91 6795 55 0 Male 30.7159 87 104 3.34 15 4802 36 0 Male 62.475 88 97 3.34 72 5192 60 1 Male 58.6283 87 97 3.4 61 4189 69 4 Female 29.462 75 86 3.4 267 1157 810 23 Male 17.3881 97 84 3.4 197 5456 193 14 Male 41.1636 87 110 3.4 165 6314 140 3 Male 16.6927 87 96 3.41 242 4902 397 8 Male 16.1424 92 86 3.42 155 4807 139 14 Female 47.7974 80 78 3.42 318 4744 1743 25 Male 57.566 97 118 3.43 93 7084 54 2 Male 36.5722 87 93 3.49 81 5580 56 7 Male 17.7933 86 95 3.5 131 5387 109 12 Male 21.7988 85 112 3.54 115 6410 80 14 Male 32.1725 85 98 3.55 82 5581 65 2 Male 26.3053 85 95 3.56 322 2653 2191 28 Male 30.0068 117 129 3.57 12 4542 22 11 Female 21.9576 71 89 3.58 1 3358 30 4 Male 20.6708 87 89 3.6 30 5736 18 9 Male 16.1478 89 86 3.6 290 3032 884 20 Male 16.9391 87 93 3.61 56 3762 48 6 Male 20.3559 85 93 3.61 80 5568 64 1 Female 51.9918 75 79 3.63 38 6870 22 0 Male 42.4832 84 95 3.63 84 6154 43 5 Female 22.6064 74 80 3.65 78 5458 44 14 Male 34.4778 84 95 3.66 46 2364 41 14 Male 25.8097 84 94 3.68 260 6226 438 0 Male 36.8022 84 92 3.68 39 6914 43 0 Male 61.5222 85 90 3.69 24 5298 30 3 Male 22.9569 87 86 3.7 31 5754 36 1 Male 16.3368 87 86 3.7 16 4941 46 4 Female 19.0144 69 88 3.72 185 5680 184 1 Male 27.7563 84 90 3.73 306 4865 1363 35 Male 58.3354 88 104 3.73 27 5680 17 1 Male 27.7563 84 90 3.74 2 3535 16 17 Male 55.2882 95 77 3.75 133 5494 111 7 Male 54.6913 86 86 3.75 36 6671 30 7 Female 27.8056 71 82 3.76 19 5154 35 5 Male 22.1903 82 95 3.76 199 5712 192 14 Male 22.2697 87 85 3.76 262 6468 513 60 Male 43.4798 99 94 3.81 149 4133 133 14 Male 20 82 94 3.81 89 6614 57 0 Male 45.1116 80 101 3.81 54 3544 32 14 Male 54.5298 81 98 3.81 176 4865 142 35 Male 58.3354 84 103 3.82 86 6314 58 3 Male 16.6927 80 99 3.82 77 5456 48 14 Male 41.1636 80 101 3.84 130 5339 119 7 Male 21.8152 87 82 3.85 187 6180 177 12 Male 20.7201 81 94 3.85 226 6498 270 28 Male 24.0767 82 101 3.85 143 1176 146 17 Female 19.729 65 98 3.85 42 7120 39 0 Male 69.7057 84 86 3.86 219 5222 247 30 Male 22.5298 88 85 3.87 10 4356 31 7 Male 21.399 86 83 3.87 68 4837 42 10 Male 19.6906 83 88 3.88 112 5879 75 21 Male 25.8453 80 105 3.89 265 781 714 15 Male 29.8699 85 85 3.89 76 5289 52 1 Male 48.5722 84 85 3.9 102 4807 64 14 Female 47.7974 74 74 3.9 291 3226 1123 0 Male 27.4552 88 81 3.9 215 3058 236 28 Male 22.2533 85 88 3.91 276 3226 683 0 Male 27.4552 89 78 3.92 145 2882 141 18 Male 19.2334 84 85 3.95 44 7321 23 0 Male 26.0041 84 83 3.97 283 6059 794 1 Female 16.9801 71 76 3.97 174 4638 140 17 Male 20.512 89 78 3.97 210 5386 241 21 Male 20.8761 80 94 3.98 285 6247 616 13 Male 42.3162 85 82 3.98 99 3844 73 9 Male 26.1164 79 94 3.98 178 5009 174 7 Male 24.3806 77 103 3.99 58 4094 50 2 Male 19.7262 79 93 3.99 246 5289 417 1 Male 48.5722 83 83 4.02 216 4342 263 1 Male 44.063 79 91 4.02 95 7371 55 1 Male 56.7858 80 88 4.04 122 4902 102 8 Male 16.1424 87 77 4.07 259 5841 415 8 Male 27.2279 82 83 4.08 274 2849 642 0 Male 20.0876 76 98 4.09 280 5222 690 30 Male 22.5298 81 90 4.11 320 1075 2259 42 Female 27.2772 78 79 4.13 108 5386 78 21 Male 20.8761 78 93 4.13 14 4744 15 25 Male 57.566 82 85 4.15 75 5280 83 1 Male 48.6434 78 88 4.16 194 4933 226 0 Male 18.4559 79 86 4.16 316 4638 1779 17 Male 20.512 92 76 4.18 195 4962 210 1 Female 25.1964 71 70 4.19 18 5129 26 1 Male 25.0459 77 89 4.2 275 3032 525 20 Male 16.9391 79 87 4.2 261 6247 389 13 Male 42.3162 82 80 4.21 189 2124 173 30 Male 30.7625 76 106 4.23 198 5668 219 7 Male 40.9227 76 90 4.23 11 4384 35 8 Male 36.3806 76 90 4.24 307 5009 1537 7 Male 24.3806 76 112 4.26 244 5111 442 7 Male 21.6947 77 86 4.28 169 3237 189 9 Male 49.8508 79 82 4.3 297 5617 1113 17 Male 19.7864 78 87 4.3 301 6140 1077 44 Female 21.4209 65 88 4.32 327 2600 3337 9 Male 43.9398 101 84 4.33 128 5222 93 30 Male 22.5298 77 91 4.33 230 6214 318 0 Male 60.3176 78 82 4.34 103 4892 62 21 Male 22.0397 76 88 4.36 319 6140 1742 44 Female 21.4209 67 87 4.36 227 2081 185 43 Male 17.6975 77 97 4.42 206 7173 210 4 Male 24.9801 79 78 4.44 104 4962 63 1 Female 25.1964 69 67 4.44 120 4218 82 28 Male 25.9904 74 92 4.47 252 5599 443 21 Male 18.7488 78 80 4.48 106 5222 63 30 Male 22.5298 77 85 4.48 164 5818 125 14 Male 34.9268 72 91 4.49 212 6247 228 13 Male 42.3162 77 80 4.49 258 5811 431 25 Male 80.0328 78 80 4.52 222 5600 232 0 Male 48.7885 75 81 4.55 109 5534 87 14 Male 29.2621 75 82 4.55 186 5782 108 68 Female 19.6715 69 85 4.56 69 4996 51 12 Male 43.0281 77 78 4.58 64 4638 20 17 Male 20.512 82 72 4.59 32 5776 26 8 Male 17.128 71 88 4.6 302 7061 923 0 Male 36.8816 74 81 4.64 303 651 1491 21 Male 22.0068 71 94 4.67 59 4133 34 14 Male 20 70 88 4.69 117 7221 98 0 Male 63.5044 74 79 4.69 37 6859 27 1 Male 34.2122 74 79 4.69 323 3592 2569 10 Male 61.6646 76 93 4.72 179 5111 177 7 Male 21.6947 72 81 4.73 287 626 870 55 Male 19.7536 80 85 4.75 7 3807 37 5 Male 24.6762 74 77 4.76 136 6135 96 18 Male 26.5626 66 105 4.76 184 5599 148 21 Male 18.7488 72 81 4.8 26 5668 27 7 Male 40.9227 72 79 4.81 286 405 986 0 Male 21.4702 66 116 4.82 126 5111 107 7 Male 21.6947 71 80 4.82 193 4775 180 28 Male 53.5551 70 86 4.83 123 4933 134 0 Male 18.4559 69 83 4.85 87 6340 71 0 Male 19.3238 76 72 4.85 98 3645 43 45 Male 27.4935 72 90 4.86 309 5085 1512 2 Male 49.0267 75 75 4.91 118 2453 120 10 Male 37.2758 63 99 4.94 116 7173 84 4 Male 24.9801 72 75 4.94 142 6834 123 0 Male 30.7488 72 75 4.94 85 6180 59 12 Male 20.7201 67 84 4.96 148 3913 96 42 Female 23.9233 56 80 4.96 47 2600 3333 9 Male 43.9398 86 80 4.97 6 3790 13 3 Male 57.0623 76 69 4.99 113 5893 71 21 Male 22.8118 65 90 4.99 200 5893 200 21 Male 22.8118 65 89 5.01 70 5009 50 7 Male 24.3806 61 104 5.05 146 3051 131 13 Male 37.2403 68 79 5.05 231 7034 280 60 Male 23.1376 78 80 5.07 288 1075 907 42 Female 27.2772 63 64 5.12 266 1048 576 94 Male 20.115 91 96 5.14 269 1611 511 60 Male 23.2799 69 107 5.16 314 3768 1916 0 Male 19.1102 69 80 5.16 237 3226 444 0 Male 27.4552 76 64 5.21 134 5896 126 4 Female 26.8775 50 74 5.25 88 6564 69 0 Male 34.4997 67 74 5.26 218 5085 269 2 Male 49.0267 65 77 5.26 5 3728 19 6 Male 30.1273 67 73 5.3 166 6664 164 2 Male 24.7337 66 73 5.34 110 5712 88 14 Male 22.2697 70 68 5.36 138 6214 112 0 Male 60.3176 65 74 5.37 125 5085 117 2 Male 49.0267 67 71 5.38 97 3058 56 28 Male 22.2533 65 75 5.45 238 3467 333 42 Male 25.3936 68 74 5.46 49 3237 65 9 Male 49.8508 67 67 5.55 325 651 3412 21 Male 22.0068 68 92 5.62 328 3835 4933 14 Male 25.9932 91 88 5.69 4 3592 13 10 Male 61.6646 59 73 5.77 268 1493 684 60 Male 17.8042 66 75 5.83 144 2849 151 0 Male 20.0876 51 86 5.89 96 2569 49 35 Male 18.7159 50 101 5.94 232 1493 453 60 Male 17.8042 59 81 6.03 310 1939 1926 130 Male 28.2738 95 108 6.41 208 3467 186 42 Male 25.3936 53 69 6.45 167 1048 85 94 Male 20.115 63 82 6.51 271 1939 562 130 Male 28.2738 85 111 6.51 321 1939 3111 130 Male 28.2738 88 111 6.93 234 1939 295 130 Male 28.2738 67 117 7.17 326 1939 3864 130 Male 28.2738 88 105 7.22 329 2773 7631 42 Male 6.51335 88 103 7.96 311 2662 1569 180 Male 28.0821 90 101 8.24 331 5964 11038 0 Male 12.8363 71 73 11.23 330 5142 11628 57 Male 16.4326 101 95 11.25 305 2638 1093 255 Male 16.5613 78 84 11.27 257 5804 354 2 Female 42.24 122 105 nan Seluruh file percobaan diatas dapat diunduh disini","title":"Ketujuh"},{"location":"pendat/missing knn/#referensi","text":"https://www.saedsayad.com/missing_values.htm https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/","title":"Referensi"},{"location":"pendat/regresi linear/","text":"Penerapan Regresi Linear Berganda \u00b6 Pengertian Regresi Linear Berganda \u00b6 Regresi linear berganda adalah salah satu teknik prediksi yang menggunakan beberapa variabel bebas untuk memprediksi hasil dari variabel terikat. Tujuan dari regresi linear untuk memodelkan hubungan linear antara variable bebas dan variabel terikat. Regresi linear berganda dinyatakan dengan persamaan terbaik berikut. $$ y = x_1b_1 + x_2b_2 + ... +x_nb_n + a $$ dimana: $ y $ = variabel terikat. $ x $ = variable bebas. $ b $ = koefisien estimasi. $ a $ = konstanta. Perhitungan Regresi Linear Berganda \u00b6 Dalam hal ini akan dilakukan perhitungan regresi linear dengan dua fitur variabel bebas, yang mana data seperti berikut. X1 X2 Y 2 3 10 4 2 12 5 3 16 7 1 16 Maka kita dapat menggunakan persamaan $ y = x_1b_1 + x_2b_2 + a $ untuk memprediksi data baru yang diberikan. sebelum menggunakan persamaan tersebut kita perlu untuk mencari koefisien estimasi dari $ b_1 $, $ b_2 $, dan $ a $. yang dapat menggunakan formula berikut. $$ b_1 = {[(\\sum x_2^2 \\sum x_1y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } $$ b_2 = {[(\\sum x_1^2 \\sum x_2y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } b_2 = {[(\\sum x_1^2 \\sum x_2y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } a = {(\\sum y) - (b_1 - \\sum x_1) - (b_2 - \\sum x_2) \\over n} a = {(\\sum y) - (b_1 - \\sum x_1) - (b_2 - \\sum x_2) \\over n} Kita dapat melakukan perhitungan dari formula diatas untuk mendapatkan nilai koefisien estimator, dan konstanta. proses perhitungan seperti berikut, dan baris terakhir merupakan jumlah ($ \\sum $) dari seluruh baris pada kolom tersebut. No X1 X2 Y X1 ^ 2 X2 ^ 2 Y ^ 2 X1 * X2 X1 * Y X2 * Y 1 2 3 10 4 9 100 6 20 30 2 4 2 12 16 4 144 8 48 24 3 5 3 16 25 9 256 15 80 48 4 7 1 16 49 1 256 7 112 16 Total ($ \\sum $) 18 9 54 94 23 756 36 260 118 dari hasil jumlah diatas kita harus normalisasi kembali. $ \\sum x_1^2 = \\sum x_1^2 - {(\\sum x_1)^2 \\over n} = 94 - {324 \\over 4} = 13 $ $ \\sum x_2^2 = \\sum x_2^2 - {(\\sum x_2)^2 \\over n} = 23 - {81 \\over 4} = 2,75 $ $ \\sum y^2 = \\sum y^2 - {(\\sum y)^2 \\over n} = 756 - {2916 \\over 4} = 27 $ $ \\sum x_1y = \\sum x_1y - {(\\sum x_1 \\sum y ) \\over n} = 260 - {972 \\over 4} = 17 $ $ \\sum x_2y = \\sum x_2y - {(\\sum x_2 \\sum y ) \\over n} = 118 - {486 \\over 4} = -3,5 $ $ \\sum x_1x_2 = \\sum x_1x_2 - {(\\sum x_1 \\sum x_2 ) \\over n} = 36 - {162 \\over 4} = -4,5 $ $ b_1 = {[(\\sum x_2^2 \\sum x_1y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } = {[(2,75 * 17)-(-3,5 * -4,5)] \\over [(12 * 2,75 ) - (-20.25)] } = 2 $ $ b_2 = {[(\\sum x_1^2 \\sum x_2y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } = {[(12 * -3,5)-(-3,5 * -4,5)] \\over [(12 * 2,75 ) - (-20.25)] } = 2 $ $ a = {(54) - (2 - 18) - (b_2 - 9) \\over 4} = 0 $ kemudian di dapatkan nilai koefisien estimator $ b_1 = 2 $ dan $ b_2 = 2 $ dan konstanta ($ a = 0 $ ) . dari proses perhitungan diatas, maka di dapatkan persamaan seperti berikut. $ y = x_1 * 2 + x_2 * 2 + 0 $. misalkan kita memiliki data baru dengan $ x_1 = 6 $ dan $ x_2 = 2 $ maka kita dapat menghitungnya seperti berikut. $ y = 6 * 2 + 2 * 2 + 0 = 16 $ Implementasi dengan Sklearn Python \u00b6 Pertama kita dapat memuat data yang akan digunakan sebagai data training dari data yang berbentuk csv. kita dapat menggunakan library pandas untuk memuat data tersebut dan menampilkan dalam bentuk dataframe. import pandas as pd from sklearn.linear_model import LinearRegression data = pd . read_csv ( 'data.csv' , sep = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Maka akan tampil seperti berikut, dimana dalam data tersebut terdapat empat variable bebas, yaitu x1, x2, x3, dan x4 dan satu variabel terikat. X1 X2 X3 X4 Y 2 3 6 2 169 5 2 4 2 169 3 4 2 3 144 5 7 3 3 324 5 6 7 8 676 Kemudian kita dapat mengambil data variable bebas yang di tampung pada variabel X, dan y sebagai variabel terikat. dan kita dapat menggunakan class LinearRegresion() yang merupakan libarary dari sklearn untuk melakukan prediksi menggunakan metode regresi linear. dan data tersebut dimasukkan dengan metode fit(X, y). X = df . iloc [ 0 :, 0 : 4 ] . values y = df . iloc [ 0 :, 4 ] . values reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) 1.0 Untuk dapat mengetahui nilai konstanta kita bisa memanggil attribut intercept_ a = reg . intercept_ a Maka akan tampil nilai konstanta dari perhitungan tersebut. -276.51245551601414 Untuk mendapatkan nilai coefisien dari seluruh fitur dapat dengan menggunakan attribut coef_. nilai kembalian dari attibut ini berupa array sebanyak variabel bebas yang ada. reg . coef_ Maka akan tampil seperti berikut, element pertama dari array berikut merupakan koefisien dari $ b_1 $ sampai ke $ n $ array([31.5480427 , 27.83274021, 33.40569395, 49.24199288]) kita dapat menggunakan persamaan diatas untuk mengetahui prediksi nilai dari y. b1 = reg . coef_ [ 0 ] b2 = reg . coef_ [ 1 ] b3 = reg . coef_ [ 2 ] b4 = reg . coef_ [ 3 ] x1 = 4 x2 = 5 x3 = 2 x4 = 1 y = b1 * x1 + b2 * x2 + b3 * x3 + b4 * x4 + a y maka akan tampil seperti berikut, yang merupakan hasil dari persamaan tersebut. 104.89679715302498 Selain itu kita dapat menggunakan fungsi bawaan dari class LinearRegression() untuk memprediksi data baru yang diberikan. reg . predict ( np . array ([[ 4 , 5 , 2 , 1 ]])) maka akan tampil seperti berikut, yang hasilnya sama seperti hasil dari persamaan diatas. array([104.89679715]) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Tugas 7"},{"location":"pendat/regresi linear/#penerapan-regresi-linear-berganda","text":"","title":"Penerapan Regresi Linear Berganda"},{"location":"pendat/regresi linear/#pengertian-regresi-linear-berganda","text":"Regresi linear berganda adalah salah satu teknik prediksi yang menggunakan beberapa variabel bebas untuk memprediksi hasil dari variabel terikat. Tujuan dari regresi linear untuk memodelkan hubungan linear antara variable bebas dan variabel terikat. Regresi linear berganda dinyatakan dengan persamaan terbaik berikut. $$ y = x_1b_1 + x_2b_2 + ... +x_nb_n + a $$ dimana: $ y $ = variabel terikat. $ x $ = variable bebas. $ b $ = koefisien estimasi. $ a $ = konstanta.","title":"Pengertian Regresi Linear Berganda"},{"location":"pendat/regresi linear/#perhitungan-regresi-linear-berganda","text":"Dalam hal ini akan dilakukan perhitungan regresi linear dengan dua fitur variabel bebas, yang mana data seperti berikut. X1 X2 Y 2 3 10 4 2 12 5 3 16 7 1 16 Maka kita dapat menggunakan persamaan $ y = x_1b_1 + x_2b_2 + a $ untuk memprediksi data baru yang diberikan. sebelum menggunakan persamaan tersebut kita perlu untuk mencari koefisien estimasi dari $ b_1 $, $ b_2 $, dan $ a $. yang dapat menggunakan formula berikut. $$ b_1 = {[(\\sum x_2^2 \\sum x_1y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } $$ b_2 = {[(\\sum x_1^2 \\sum x_2y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } b_2 = {[(\\sum x_1^2 \\sum x_2y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } a = {(\\sum y) - (b_1 - \\sum x_1) - (b_2 - \\sum x_2) \\over n} a = {(\\sum y) - (b_1 - \\sum x_1) - (b_2 - \\sum x_2) \\over n} Kita dapat melakukan perhitungan dari formula diatas untuk mendapatkan nilai koefisien estimator, dan konstanta. proses perhitungan seperti berikut, dan baris terakhir merupakan jumlah ($ \\sum $) dari seluruh baris pada kolom tersebut. No X1 X2 Y X1 ^ 2 X2 ^ 2 Y ^ 2 X1 * X2 X1 * Y X2 * Y 1 2 3 10 4 9 100 6 20 30 2 4 2 12 16 4 144 8 48 24 3 5 3 16 25 9 256 15 80 48 4 7 1 16 49 1 256 7 112 16 Total ($ \\sum $) 18 9 54 94 23 756 36 260 118 dari hasil jumlah diatas kita harus normalisasi kembali. $ \\sum x_1^2 = \\sum x_1^2 - {(\\sum x_1)^2 \\over n} = 94 - {324 \\over 4} = 13 $ $ \\sum x_2^2 = \\sum x_2^2 - {(\\sum x_2)^2 \\over n} = 23 - {81 \\over 4} = 2,75 $ $ \\sum y^2 = \\sum y^2 - {(\\sum y)^2 \\over n} = 756 - {2916 \\over 4} = 27 $ $ \\sum x_1y = \\sum x_1y - {(\\sum x_1 \\sum y ) \\over n} = 260 - {972 \\over 4} = 17 $ $ \\sum x_2y = \\sum x_2y - {(\\sum x_2 \\sum y ) \\over n} = 118 - {486 \\over 4} = -3,5 $ $ \\sum x_1x_2 = \\sum x_1x_2 - {(\\sum x_1 \\sum x_2 ) \\over n} = 36 - {162 \\over 4} = -4,5 $ $ b_1 = {[(\\sum x_2^2 \\sum x_1y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } = {[(2,75 * 17)-(-3,5 * -4,5)] \\over [(12 * 2,75 ) - (-20.25)] } = 2 $ $ b_2 = {[(\\sum x_1^2 \\sum x_2y)-(\\sum x_2y \\sum x_1 x_2)] \\over [(\\sum x_1^2 \\sum x_2^2 ) - (\\sum x_1 x_2)^2] } = {[(12 * -3,5)-(-3,5 * -4,5)] \\over [(12 * 2,75 ) - (-20.25)] } = 2 $ $ a = {(54) - (2 - 18) - (b_2 - 9) \\over 4} = 0 $ kemudian di dapatkan nilai koefisien estimator $ b_1 = 2 $ dan $ b_2 = 2 $ dan konstanta ($ a = 0 $ ) . dari proses perhitungan diatas, maka di dapatkan persamaan seperti berikut. $ y = x_1 * 2 + x_2 * 2 + 0 $. misalkan kita memiliki data baru dengan $ x_1 = 6 $ dan $ x_2 = 2 $ maka kita dapat menghitungnya seperti berikut. $ y = 6 * 2 + 2 * 2 + 0 = 16 $","title":"Perhitungan Regresi Linear Berganda"},{"location":"pendat/regresi linear/#implementasi-dengan-sklearn-python","text":"Pertama kita dapat memuat data yang akan digunakan sebagai data training dari data yang berbentuk csv. kita dapat menggunakan library pandas untuk memuat data tersebut dan menampilkan dalam bentuk dataframe. import pandas as pd from sklearn.linear_model import LinearRegression data = pd . read_csv ( 'data.csv' , sep = ';' ) df = pd . DataFrame ( data ) df . style . hide_index () Maka akan tampil seperti berikut, dimana dalam data tersebut terdapat empat variable bebas, yaitu x1, x2, x3, dan x4 dan satu variabel terikat. X1 X2 X3 X4 Y 2 3 6 2 169 5 2 4 2 169 3 4 2 3 144 5 7 3 3 324 5 6 7 8 676 Kemudian kita dapat mengambil data variable bebas yang di tampung pada variabel X, dan y sebagai variabel terikat. dan kita dapat menggunakan class LinearRegresion() yang merupakan libarary dari sklearn untuk melakukan prediksi menggunakan metode regresi linear. dan data tersebut dimasukkan dengan metode fit(X, y). X = df . iloc [ 0 :, 0 : 4 ] . values y = df . iloc [ 0 :, 4 ] . values reg = LinearRegression () . fit ( X , y ) reg . score ( X , y ) 1.0 Untuk dapat mengetahui nilai konstanta kita bisa memanggil attribut intercept_ a = reg . intercept_ a Maka akan tampil nilai konstanta dari perhitungan tersebut. -276.51245551601414 Untuk mendapatkan nilai coefisien dari seluruh fitur dapat dengan menggunakan attribut coef_. nilai kembalian dari attibut ini berupa array sebanyak variabel bebas yang ada. reg . coef_ Maka akan tampil seperti berikut, element pertama dari array berikut merupakan koefisien dari $ b_1 $ sampai ke $ n $ array([31.5480427 , 27.83274021, 33.40569395, 49.24199288]) kita dapat menggunakan persamaan diatas untuk mengetahui prediksi nilai dari y. b1 = reg . coef_ [ 0 ] b2 = reg . coef_ [ 1 ] b3 = reg . coef_ [ 2 ] b4 = reg . coef_ [ 3 ] x1 = 4 x2 = 5 x3 = 2 x4 = 1 y = b1 * x1 + b2 * x2 + b3 * x3 + b4 * x4 + a y maka akan tampil seperti berikut, yang merupakan hasil dari persamaan tersebut. 104.89679715302498 Selain itu kita dapat menggunakan fungsi bawaan dari class LinearRegression() untuk memprediksi data baru yang diberikan. reg . predict ( np . array ([[ 4 , 5 , 2 , 1 ]])) maka akan tampil seperti berikut, yang hasilnya sama seperti hasil dari persamaan diatas. array([104.89679715]) MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$'],['$','$']]} });","title":"Implementasi dengan Sklearn Python"},{"location":"pendat/statistik deskriptif/","text":"Statistik Dekriptif \u00b6 Pengertian \u00b6 Statistik Deskriptif adalah sebuah representasi keseluruhan himpunan data spesifik dengan memberikan ringkasan pendek tentang sampel dan ukuran data. Statistik deskriptif memberikan ringkasan sederhana tentang sempel dan pengamatan yang telah dilakukan. Ringkasan tersebut dapat berupa kuantitatif, yaitu: statistik yang tersaji dengan ringkas dan rapi yang dapat berupa table, diagram, ataupun grafik sehingga dapat memberikan informasi inti dari kumpulan data yang ada dengan mudah untuk dipahami. dari statistik deskriptif ini dapat memberikan informasi yang dapat berupa: ukuran pemusatan data, ukuran penyebaran data, juga kecenderungan suatu gugus data. Tipe Statistik Deskriptif \u00b6 Mean (rata-rata) \u00b6 Mean merupakan rata-rata dari semua angka. Mean didapat dari hasil penjumlahan dari keseluruhan angka yang dibagi dengan banyaknya angka itu sendiri. Jika kita memiliki N data, kita dapat menghitung mean itu sendiri dengan menggunakan rumus berikut: $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Dimana: x bar = x rata-rata = nilai rata-rata sampel x = data ke n n = banyaknya data Median \u00b6 Median merupakan pusat data atau lebih sering dikatakan nilai tengah dari sebuah urutan data. Median disimbolkan dengan Me . nilai dari median akan sama dengan nilai Quartile 2 ( Q 2 ). Dalam mencari median, banyak( n ) dari data ganjil dan genap memiliki cara perhitungan yang berbeda. Untuk mencari median kita dapat menggunakan rumus sebagai berikut: Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap Dimana : M e = Median dari kelompok data n = banyak data Modus \u00b6 Modus adalah angka yang paling sering ditemukan dalam suatu himpunan angka. Modus didapat dengan mengumpulkan dan mengatur data untuk menghitung setiap frekuensi dari setiap hasil. Dan hasil dengan jumlah tertinggi merupakan modus dari himpunan angka tersebut. Untuk mencari modus dari sebuah himpunan angka dapat menggunakan rumus berikut: $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Dimana: Mo = modus dari kelompok data Tb = tepi bawah dari elemen modus b1 = selisih frekuensi antara elemen modus dengan elemet sebelumnya b2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya p = panjang interval nilai b1 dan b2 \u2013> adalah mutlak (selalu positif) Varians \u00b6 Varian adalah ukuran penyebaran setiap nilai dalam suatu himpunan data dari rata-rata. Dalam proses mendapatkan varian terdapat langkah yaitu yang harus dilakukan, yaitu: dengan mengambil ukuran jarak dari setiap nilai dan mengurangi rata-rata dari setiap nilai dalam data, kemudian hasil dari ukuran jarak tersebut dikuadratkan dan membagi jumlah kuadrat dengan jumlah nilai dalam himpunan data. Untuk menghitung varian terdapat formula yang dapat digunakan yaitu: $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Dimana : x i = titik data x bar = rata-rata dari semua titik data n = banyak dari dari anggota data Standar Deviasi \u00b6 Standar deviasi merupakan ukuran dispersi kumpulan data relatif terhadap rata-rata atau lebih simpelnya adalah akar kuadrat positif dari varian. Standar deviasi dihitung dengan mengakar kuadratkan nilai dari varians. jika titik data lebih dari rata-rata dalam kumpulan data maka, semakin tinggi standar deviasi. Untuk mencari standar deviasi kita dapat menggunakan formula berikut : \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} Skewness \u00b6 Skewness( kemiringan ) adalah ketidaksimetrisan pada suatu distribusi statistik dimana kurva tampak condong ke kiri atau ke kanan. Skewness digunakan untuk menentukan sejauhmana perbedaan suatu distribusi dengan distribusi normal. Dalam distribusi normal grafik muncul seperti kurva berbentuk lonceng. ketika suatu distribusi mengalami kemiringan ke sebelah kanan dan ekor di sisi kanan kurva lebih panjang dari ekor sisi kiri kurva maka situasi ini dikatakan kemiringan positif dan sebaliknya dikatakan kemiringan negative. Skewness bisa dihitung menggunakan rumus sebagai berikut: Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} Dimana : x i = titik data x bar = rata-rata dari distribusi n = jumlah titik dalam distribusi o = standar deviasi Quartile \u00b6 Quartile adalah irisan nilai dari hasil pembagian data menjadi empat bagian yang sama besar. Nilai-nilai dari quartile biasanya dilambangkan dengan Q 1 untuk quartile bawah. Q 1 ini mempunyai nilai 25% dari data. Q 2 atau biasa disebut quartile tengah yang mempunyai nilai sama seperti median yaitu 50% dari data. dan Q 3 sebagai quartile atas yang mempunyai nilai 75% dari data. Dalam mencari quatile kita dapat menggunakan rumus berikut ini: Q_1 = (n + 1) {1\\over 4} Q_1 = (n + 1) {1\\over 4} Q_2 = (n + 1) {1\\over 2} Q_2 = (n + 1) {1\\over 2} Q_3 = (n + 1) {3\\over 4} Q_3 = (n + 1) {3\\over 4} Dimana : Q = Nilai dari quartile n = banyak dari himpunan data Penerapan Statistik Deskriptif Menggunakan Python \u00b6 Alat dan Bahan \u00b6 Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini, library python yang digunakan adalah sebagai berikut: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika. Pertama \u00b6 pada langkah ini kita memasukkan library yang telah disiapkan sebelumya import pandas as pd from scipy import stats Kedua \u00b6 dan selanjutnya memuat data csv yang telah disiapkan df = pd . read_csv ( 'sample_data.csv' , sep = ';' ) Ketiga \u00b6 kemudian membuat data penyimpanan ( dictionary ) yang menampung nilai yang akan ditampilkan. selanjutnya mengambil data dari beberapa kolom pada csv dengan cara diiterasi serta, menghitungnya dengan berbagai metode yang telah disiapkan oleh pandas itu sendiri. kemudian hasil tersebut di disimpan pada penyimpanan tadi data = { \"Stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]] Keempat \u00b6 terakhir adalah menvisualisasikan hasil tersebut dalam bentuk dataframe tes = pd . DataFrame ( data , columns = [ 'Stats' ] + [ x for x in df . columns ]) tes setelah jalankan, program tersebut akan menampilkan seperti berikut: Stats X1 X2 X3 X4 0 Min 30.000 30.000 30.000 30.000 1 Max 80.000 80.000 80.000 80.000 2 Mean 54.608 53.524 54.996 55.046 3 Standard Deviasi 14.720 15.110 14.470 14.560 4 Variasi 216.750 228.440 209.360 211.970 5 Skewnes 0.050 0.110 0.020 -0.020 6 Quartile 1 42.000 40.000 43.000 43.750 7 Quartile 2 54.000 52.000 55.000 54.000 8 Quartile 3 68.000 67.000 67.000 67.000 9 Median 54.000 52.000 55.000 54.000 10 Modus 77.000 38.000 38.000 54.000 Mencari Outlier \u00b6 Outlier merupakan suatu nilai dari pada sekumpulan data yang lain atau berbeda dibandingkan biasanya serta tidak menggambarkan karakteristik data tersebut. Sebuah outlier mungkin karena variabilitas dalam pengukuran atau mungkin menunjukkan kesalahan eksperimental. Standarisasi Data deteksi data dengan standarisasi pada prinsipnya mengubah nilai data menjadi bentuk Z, dengan menggunakan formula dari Z score, yaitu: z = {(X - \\mu) \\over \\sigma} z = {(X - \\mu) \\over \\sigma} Pada data csv tersebut, saya lakukan modifikasi dengan memberikan data sampah( noise ) yang pada sebagian kolom. dan dalam pencarian outlier ini saya menggunakan formula dari z score yang diterapkan pada python, yaitu sebagai berikut: def dekteksi_outlier ( df_in ): outliers = [] threshold = 3 for col_name in df_in : mean = df_in [ col_name ] . mean () std = df_in [ col_name ] . std () i = 1 for y in df_in [ col_name ]: z_score = ( y - mean ) / std if abs ( z_score ) > threshold : outliers . append ([ col_name , y , i ]) i += 1 return outliers for i in dekteksi_outlier ( df ): print ( 'Data sampah' , i [ 1 ], 'dikolom' , i [ 0 ], 'pada baris' , i [ 2 ]) dari fungsi diatas akan mengembalikan outlier dari data csv ditersebut. Data sampah ( 322 ) dikolom X1 pada baris 453 Data sampah ( 600 ) dikolom X1 pada baris 489 Data sampah ( 115 ) dikolom X2 pada baris 449 Data sampah ( 336 ) dikolom X3 pada baris 406 Data sampah ( 145 ) dikolom X4 pada baris 407 Data sampah ( 120 ) dikolom X4 pada baris 413 Source \u00b6 Seluruh file percobaan ada pada link berikut : disini Referensi \u00b6 http://blog.ub.ac.id/adiarsa/2012/03/14/mean-median-modus-dan-standar-deviasi/ http://statutorial.blogspot.com/2008/01/skewness-dan-kurtosis.html https://www.rumusstatistik.com/2013/07/varian-dan-standar-deviasi-simpangan.html https://www.rumusstatistik.com/2016/12/membuat-rumus-matematika-dengan-latex.html https://englishccit.wordpress.com/2012/03/27/pengertian-statistik-deskriptif/#more-1194 https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Tugas 1"},{"location":"pendat/statistik deskriptif/#statistik-dekriptif","text":"","title":"Statistik Dekriptif"},{"location":"pendat/statistik deskriptif/#pengertian","text":"Statistik Deskriptif adalah sebuah representasi keseluruhan himpunan data spesifik dengan memberikan ringkasan pendek tentang sampel dan ukuran data. Statistik deskriptif memberikan ringkasan sederhana tentang sempel dan pengamatan yang telah dilakukan. Ringkasan tersebut dapat berupa kuantitatif, yaitu: statistik yang tersaji dengan ringkas dan rapi yang dapat berupa table, diagram, ataupun grafik sehingga dapat memberikan informasi inti dari kumpulan data yang ada dengan mudah untuk dipahami. dari statistik deskriptif ini dapat memberikan informasi yang dapat berupa: ukuran pemusatan data, ukuran penyebaran data, juga kecenderungan suatu gugus data.","title":"Pengertian"},{"location":"pendat/statistik deskriptif/#tipe-statistik-deskriptif","text":"","title":"Tipe Statistik Deskriptif"},{"location":"pendat/statistik deskriptif/#mean-rata-rata","text":"Mean merupakan rata-rata dari semua angka. Mean didapat dari hasil penjumlahan dari keseluruhan angka yang dibagi dengan banyaknya angka itu sendiri. Jika kita memiliki N data, kita dapat menghitung mean itu sendiri dengan menggunakan rumus berikut: $$ \\bar x ={\\sum \\limits_{i=1}^{n} x_i \\over N} = {x_1 + x_2 + x_3 + ... + x_n \\over N} $$ Dimana: x bar = x rata-rata = nilai rata-rata sampel x = data ke n n = banyaknya data","title":"Mean (rata-rata)"},{"location":"pendat/statistik deskriptif/#median","text":"Median merupakan pusat data atau lebih sering dikatakan nilai tengah dari sebuah urutan data. Median disimbolkan dengan Me . nilai dari median akan sama dengan nilai Quartile 2 ( Q 2 ). Dalam mencari median, banyak( n ) dari data ganjil dan genap memiliki cara perhitungan yang berbeda. Untuk mencari median kita dapat menggunakan rumus sebagai berikut: Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil Me=Q_2 =\\left( \\begin{matrix} n+1 \\over 2 \\end{matrix} \\right), jika\\quad n\\quad ganjil Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap Me=Q_2 =\\left( \\begin{matrix} {xn \\over 2 } {xn+1\\over 2} \\over 2 \\end{matrix} \\right), jika\\quad n\\quad genap Dimana : M e = Median dari kelompok data n = banyak data","title":"Median"},{"location":"pendat/statistik deskriptif/#modus","text":"Modus adalah angka yang paling sering ditemukan dalam suatu himpunan angka. Modus didapat dengan mengumpulkan dan mengatur data untuk menghitung setiap frekuensi dari setiap hasil. Dan hasil dengan jumlah tertinggi merupakan modus dari himpunan angka tersebut. Untuk mencari modus dari sebuah himpunan angka dapat menggunakan rumus berikut: $$ M_o = Tb + p{b_1 \\over b_1 + b_2} $$ Dimana: Mo = modus dari kelompok data Tb = tepi bawah dari elemen modus b1 = selisih frekuensi antara elemen modus dengan elemet sebelumnya b2 = selisih frekuensi antara elemen modus dengan elemen sesudahnya p = panjang interval nilai b1 dan b2 \u2013> adalah mutlak (selalu positif)","title":"Modus"},{"location":"pendat/statistik deskriptif/#varians","text":"Varian adalah ukuran penyebaran setiap nilai dalam suatu himpunan data dari rata-rata. Dalam proses mendapatkan varian terdapat langkah yaitu yang harus dilakukan, yaitu: dengan mengambil ukuran jarak dari setiap nilai dan mengurangi rata-rata dari setiap nilai dalam data, kemudian hasil dari ukuran jarak tersebut dikuadratkan dan membagi jumlah kuadrat dengan jumlah nilai dalam himpunan data. Untuk menghitung varian terdapat formula yang dapat digunakan yaitu: $$ \\sigma^2 = {\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n} $$ Dimana : x i = titik data x bar = rata-rata dari semua titik data n = banyak dari dari anggota data","title":"Varians"},{"location":"pendat/statistik deskriptif/#standar-deviasi","text":"Standar deviasi merupakan ukuran dispersi kumpulan data relatif terhadap rata-rata atau lebih simpelnya adalah akar kuadrat positif dari varian. Standar deviasi dihitung dengan mengakar kuadratkan nilai dari varians. jika titik data lebih dari rata-rata dalam kumpulan data maka, semakin tinggi standar deviasi. Untuk mencari standar deviasi kita dapat menggunakan formula berikut : \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}} \\sigma^ = \\sqrt {{\\sum \\limits_{i=1}^{n} (x_i - \\bar x)^2 \\over n}}","title":"Standar Deviasi"},{"location":"pendat/statistik deskriptif/#skewness","text":"Skewness( kemiringan ) adalah ketidaksimetrisan pada suatu distribusi statistik dimana kurva tampak condong ke kiri atau ke kanan. Skewness digunakan untuk menentukan sejauhmana perbedaan suatu distribusi dengan distribusi normal. Dalam distribusi normal grafik muncul seperti kurva berbentuk lonceng. ketika suatu distribusi mengalami kemiringan ke sebelah kanan dan ekor di sisi kanan kurva lebih panjang dari ekor sisi kiri kurva maka situasi ini dikatakan kemiringan positif dan sebaliknya dikatakan kemiringan negative. Skewness bisa dihitung menggunakan rumus sebagai berikut: Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} Skewness = {\\sum \\limits{i=1}^n (x_i - \\bar x)^i \\over (n- 1) \\sigma^3} Dimana : x i = titik data x bar = rata-rata dari distribusi n = jumlah titik dalam distribusi o = standar deviasi","title":"Skewness"},{"location":"pendat/statistik deskriptif/#quartile","text":"Quartile adalah irisan nilai dari hasil pembagian data menjadi empat bagian yang sama besar. Nilai-nilai dari quartile biasanya dilambangkan dengan Q 1 untuk quartile bawah. Q 1 ini mempunyai nilai 25% dari data. Q 2 atau biasa disebut quartile tengah yang mempunyai nilai sama seperti median yaitu 50% dari data. dan Q 3 sebagai quartile atas yang mempunyai nilai 75% dari data. Dalam mencari quatile kita dapat menggunakan rumus berikut ini: Q_1 = (n + 1) {1\\over 4} Q_1 = (n + 1) {1\\over 4} Q_2 = (n + 1) {1\\over 2} Q_2 = (n + 1) {1\\over 2} Q_3 = (n + 1) {3\\over 4} Q_3 = (n + 1) {3\\over 4} Dimana : Q = Nilai dari quartile n = banyak dari himpunan data","title":"Quartile"},{"location":"pendat/statistik deskriptif/#penerapan-statistik-deskriptif-menggunakan-python","text":"","title":"Penerapan Statistik Deskriptif Menggunakan Python"},{"location":"pendat/statistik deskriptif/#alat-dan-bahan","text":"Pada penerapan ini saya menggunakan 500 data random yang disimpan dalam bentuk .csv dan untuk mempermudah dalam penerapan tersebut, perlu disiapkan library python yang dapat didownload secara gratis. dalam kasus ini, library python yang digunakan adalah sebagai berikut: pandas, digunakan untuk data manajemen dan data analysis. scipy, merupakan library berisi kumpulan algoritma dan fungsi matematika.","title":"Alat dan Bahan"},{"location":"pendat/statistik deskriptif/#pertama","text":"pada langkah ini kita memasukkan library yang telah disiapkan sebelumya import pandas as pd from scipy import stats","title":"Pertama"},{"location":"pendat/statistik deskriptif/#kedua","text":"dan selanjutnya memuat data csv yang telah disiapkan df = pd . read_csv ( 'sample_data.csv' , sep = ';' )","title":"Kedua"},{"location":"pendat/statistik deskriptif/#ketiga","text":"kemudian membuat data penyimpanan ( dictionary ) yang menampung nilai yang akan ditampilkan. selanjutnya mengambil data dari beberapa kolom pada csv dengan cara diiterasi serta, menghitungnya dengan berbagai metode yang telah disiapkan oleh pandas itu sendiri. kemudian hasil tersebut di disimpan pada penyimpanan tadi data = { \"Stats\" : [ 'Min' , 'Max' , 'Mean' , 'Standard Deviasi' , 'Variasi' , 'Skewnes' , 'Quartile 1' , 'Quartile 2' , 'Quartile 3' , 'Median' , 'Modus' ]} for i in df . columns : data [ i ] = [ df [ i ] . min (), df [ i ] . max (), df [ i ] . mean (), round ( df [ i ] . std (), 2 ), round ( df [ i ] . var (), 2 ), round ( df [ i ] . skew (), 2 ), df [ i ] . quantile ( 0.25 ), df [ i ] . quantile ( 0.5 ), df [ i ] . quantile ( 0.75 ), df [ i ] . median (), stats . mode ( df [ i ]) . mode [ 0 ]]","title":"Ketiga"},{"location":"pendat/statistik deskriptif/#keempat","text":"terakhir adalah menvisualisasikan hasil tersebut dalam bentuk dataframe tes = pd . DataFrame ( data , columns = [ 'Stats' ] + [ x for x in df . columns ]) tes setelah jalankan, program tersebut akan menampilkan seperti berikut: Stats X1 X2 X3 X4 0 Min 30.000 30.000 30.000 30.000 1 Max 80.000 80.000 80.000 80.000 2 Mean 54.608 53.524 54.996 55.046 3 Standard Deviasi 14.720 15.110 14.470 14.560 4 Variasi 216.750 228.440 209.360 211.970 5 Skewnes 0.050 0.110 0.020 -0.020 6 Quartile 1 42.000 40.000 43.000 43.750 7 Quartile 2 54.000 52.000 55.000 54.000 8 Quartile 3 68.000 67.000 67.000 67.000 9 Median 54.000 52.000 55.000 54.000 10 Modus 77.000 38.000 38.000 54.000","title":"Keempat"},{"location":"pendat/statistik deskriptif/#mencari-outlier","text":"Outlier merupakan suatu nilai dari pada sekumpulan data yang lain atau berbeda dibandingkan biasanya serta tidak menggambarkan karakteristik data tersebut. Sebuah outlier mungkin karena variabilitas dalam pengukuran atau mungkin menunjukkan kesalahan eksperimental. Standarisasi Data deteksi data dengan standarisasi pada prinsipnya mengubah nilai data menjadi bentuk Z, dengan menggunakan formula dari Z score, yaitu: z = {(X - \\mu) \\over \\sigma} z = {(X - \\mu) \\over \\sigma} Pada data csv tersebut, saya lakukan modifikasi dengan memberikan data sampah( noise ) yang pada sebagian kolom. dan dalam pencarian outlier ini saya menggunakan formula dari z score yang diterapkan pada python, yaitu sebagai berikut: def dekteksi_outlier ( df_in ): outliers = [] threshold = 3 for col_name in df_in : mean = df_in [ col_name ] . mean () std = df_in [ col_name ] . std () i = 1 for y in df_in [ col_name ]: z_score = ( y - mean ) / std if abs ( z_score ) > threshold : outliers . append ([ col_name , y , i ]) i += 1 return outliers for i in dekteksi_outlier ( df ): print ( 'Data sampah' , i [ 1 ], 'dikolom' , i [ 0 ], 'pada baris' , i [ 2 ]) dari fungsi diatas akan mengembalikan outlier dari data csv ditersebut. Data sampah ( 322 ) dikolom X1 pada baris 453 Data sampah ( 600 ) dikolom X1 pada baris 489 Data sampah ( 115 ) dikolom X2 pada baris 449 Data sampah ( 336 ) dikolom X3 pada baris 406 Data sampah ( 145 ) dikolom X4 pada baris 407 Data sampah ( 120 ) dikolom X4 pada baris 413","title":"Mencari Outlier"},{"location":"pendat/statistik deskriptif/#source","text":"Seluruh file percobaan ada pada link berikut : disini","title":"Source"},{"location":"pendat/statistik deskriptif/#referensi","text":"http://blog.ub.ac.id/adiarsa/2012/03/14/mean-median-modus-dan-standar-deviasi/ http://statutorial.blogspot.com/2008/01/skewness-dan-kurtosis.html https://www.rumusstatistik.com/2013/07/varian-dan-standar-deviasi-simpangan.html https://www.rumusstatistik.com/2016/12/membuat-rumus-matematika-dengan-latex.html https://englishccit.wordpress.com/2012/03/27/pengertian-statistik-deskriptif/#more-1194 https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32 MathJax.Hub.Config({ tex2jax: {inlineMath: [['$$','$$']]} });","title":"Referensi"}]}